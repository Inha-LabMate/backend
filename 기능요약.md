# ê³ ê¸‰ ê¸°ëŠ¥ ìš”ì•½ (í•œê¸€)

## ğŸ“‹ ìš”ì²­í•˜ì‹  ê¸°ëŠ¥ë“¤ì´ ëª¨ë‘ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤!

### âœ… 6) í’ˆì§ˆ/ê°€ë“œë ˆì¼

#### í’ˆì§ˆ ì ìˆ˜ (quality_score)
- **íŒŒì¼**: `quality_guard.py` â†’ `QualityScorer` í´ë˜ìŠ¤
- **ì ìˆ˜ ë²”ìœ„**: 0.0 - 1.0
- **êµ¬ì„± ìš”ì†Œ**:
  - ì„¹ì…˜ ì¼ì¹˜ë„ (30%): í…ìŠ¤íŠ¸ê°€ ë¶„ë¥˜ëœ ì„¹ì…˜ê³¼ ë§ëŠ”ê°€?
  - ê¸¸ì´ ì ì ˆì„± (25%): 200-400ìê°€ ìµœì 
  - ì–¸ì–´ ì¼ê´€ì„± (25%): í•œ ì–¸ì–´ë¡œ í†µì¼ë˜ì—ˆëŠ”ê°€?
  - ì¤‘ë³µ ì—¬ë¶€ (20%): MD5 í•´ì‹œë¡œ ì¤‘ë³µ ê°ì§€
- **ê²€ìˆ˜ ëŒ€ìƒ**: 0.5 ë¯¸ë§Œì´ë©´ `needs_review=True`
- **ì´ìœ  ìë™ ìƒì„±**: "ì„¹ì…˜ ë¶ˆì¼ì¹˜", "ê¸¸ì´ ë¶€ì ì ˆ" ë“±

```python
from quality_guard import QualityScorer

scorer = QualityScorer()
report = scorer.calculate_quality(chunk, all_chunks)

print(f"ì ìˆ˜: {report.overall_score:.2f}")
if report.needs_review:
    print(f"ê²€ìˆ˜ í•„ìš”: {report.reason}")
```

#### PII/ë¹„ê³µê°œ ì°¨ë‹¨
- **íŒŒì¼**: `quality_guard.py` â†’ `GuardRail` í´ë˜ìŠ¤
- **ì°¨ë‹¨ ëŒ€ìƒ**:
  - í¬í„¸/ë¡œê·¸ì¸ í˜ì´ì§€: `/login`, `/admin`, `/portal`
  - ê°œì¸ì •ë³´ í‚¤ì›Œë“œ: 'ë¹„ë°€ë²ˆí˜¸', 'password', 'ê°œì¸ì •ë³´'
  - ì…ë ¥ í¼: password/email í•„ë“œ ê°ì§€
- **ìƒ‰ì¸ ì œì™¸ ë¦¬ìŠ¤íŠ¸**: ì •ê·œì‹ íŒ¨í„´ìœ¼ë¡œ URL í•„í„°ë§

```python
from quality_guard import GuardRail

guard = GuardRail()

# URL ì°¨ë‹¨ í™•ì¸
should_exclude, reason = guard.should_exclude_url(url)
if should_exclude:
    print(f"ì°¨ë‹¨: {reason}")

# PII ê°ì§€
has_pii, keywords = guard.detect_pii_in_text(text)
if has_pii:
    print(f"ê°œì¸ì •ë³´ ë°œê²¬: {keywords}")
```

#### robots & ì†ë„
- **íŒŒì¼**: `crawl_manager.py` â†’ `CrawlManager` í´ë˜ìŠ¤
- **User-Agent ëª…ì‹œ**: `INHA-LabSearch-Bot/1.0 (Educational...)`
- **ì†ë„ ì œí•œ**: 0.5-1.0 req/sec (ê¸°ë³¸ê°’ 1.0ì´ˆ)
- **ì¬ì‹œë„**: ìµœëŒ€ 3íšŒ, ì§€ìˆ˜ ë°±ì˜¤í”„ (1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ)

```python
from crawl_manager import CrawlManager

manager = CrawlManager(
    delay=1.0,           # 1ì´ˆ ë”œë ˆì´
    max_retries=3,       # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
    respect_robots=True  # robots.txt ì¤€ìˆ˜
)

result = manager.fetch_url(url)
```

---

### âœ… 7) ì—…ë°ì´íŠ¸ ì „ëµ

#### ì¬í¬ë¡¤ ì£¼ê¸°
- **í…Œì´ë¸” í•„ë“œ**: `labs.last_crawled_at`
- **ì£¼ê¸°**: 2-4ì£¼ ê¶Œì¥
- **ë³€ê²½ ê°ì§€**: ETag/Last-Modified í—¤ë” ì‚¬ìš©
- **ìºì‹±**: HTTP 304 Not Modified ì‘ë‹µ ì²˜ë¦¬

```python
# ìºì‹œ ì‚¬ìš© (ë³€ê²½ë˜ì§€ ì•Šìœ¼ë©´ 304)
result = manager.fetch_url(url)
if result.cached:
    print("ìºì‹œ ì‚¬ìš© - ë³€ê²½ ì—†ìŒ")
```

#### ì†Œí”„íŠ¸ ì‚­ì œ
- **í…Œì´ë¸” í•„ë“œ**: `documents.is_active` (ê¸°ë³¸ê°’ TRUE)
- **ë™ì‘**: ì›ë¬¸ì—ì„œ ì‚¬ë¼ì§„ ë¬¸ì„œ â†’ `is_active=false`
- **íˆìŠ¤í† ë¦¬ ë³´ì¡´**: ì™„ì „ ì‚­ì œí•˜ì§€ ì•ŠìŒ
- **í•¨ìˆ˜ ì œê³µ**: `soft_delete_document(doc_id)`

```sql
-- ë¬¸ì„œ ì†Œí”„íŠ¸ ì‚­ì œ
SELECT soft_delete_document(123);

-- í™œì„± ë¬¸ì„œë§Œ ì¡°íšŒ
SELECT * FROM documents WHERE is_active = TRUE;
```

#### ê°ì‚¬ ê°€ëŠ¥ì„±
- **í…Œì´ë¸”**: `crawl_log`
- **ì €ì¥ ë‚´ìš©**:
  - ìƒíƒœ ì½”ë“œ: `status_code` (200, 404, 500 ë“±)
  - ì‘ë‹µ ì‹œê°„: `response_time_ms`
  - ì—ëŸ¬ ì‚¬ìœ : `error_message`, `error_type`
  - ì²­í¬ í†µê³„: `chunks_created`, `chunks_excluded`
  - ìºì‹œ ì—¬ë¶€: `used_cache`, `etag`, `last_modified`

```sql
-- ìµœê·¼ ì—ëŸ¬ ë¡œê·¸ ì¡°íšŒ
SELECT url, error_message, error_type, request_time
FROM crawl_log
WHERE success = FALSE
ORDER BY request_time DESC
LIMIT 10;
```

#### ì—…ë°ì´íŠ¸ ì´ë ¥
- **í…Œì´ë¸”**: `update_history`
- **ì¶”ì  ë‚´ìš©**:
  - ë³€ê²½ íƒ€ì…: `change_type` (added, modified, deleted)
  - í•„ë“œëª…: `field_name`
  - ì´ì „ ê°’ vs ìƒˆ ê°’: `old_value`, `new_value`
  - ë³€ê²½ ì‹œê°„: `detected_at`

```sql
-- ì—°êµ¬ì‹¤ ë³€ê²½ ì´ë ¥ ì¡°íšŒ
SELECT * FROM update_history 
WHERE lab_id = 1 
ORDER BY detected_at DESC;
```

---

### âœ… 8) PDF/í‘œ/ì´ë¯¸ì§€ ëŒ€ì‘

#### PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
- **íŒŒì¼**: `advanced_extractors.py` â†’ `PDFExtractor` í´ë˜ìŠ¤
- **ì§€ì›**: PyPDF2 ë˜ëŠ” pdfplumber
- **ê¸°ëŠ¥**:
  - í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
  - ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì œëª©, ì €ì, í˜ì´ì§€ ìˆ˜)
- **í‘œê¸°**: `source_type='pdf'`

```python
from advanced_extractors import PDFExtractor

extractor = PDFExtractor(backend='pypdf2')

# í…ìŠ¤íŠ¸ ì¶”ì¶œ
text = extractor.extract_text("paper.pdf")

# ë©”íƒ€ë°ì´í„°
metadata = extractor.extract_metadata("paper.pdf")
print(f"ì œëª©: {metadata['title']}")
print(f"í˜ì´ì§€: {metadata['pages']}")
```

#### í‘œ êµ¬ì¡° ë³´ì¡´
- **íŒŒì¼**: `advanced_extractors.py` â†’ `TableExtractor` í´ë˜ìŠ¤
- **ìë™ ì¸ì‹**:
  - ì»¬ëŸ¼ í—¤ë”: venue, year, title, author
  - ì»¬ëŸ¼ ë§¤í•‘ ìë™ ìƒì„±
- **lab_tag ìƒì„±**: venue + year (ì˜ˆ: "CVPR2024")
- **ì¶œë ¥ í˜•ì‹**: í…ìŠ¤íŠ¸, ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ (JSON ì¹œí™”ì )

```python
from advanced_extractors import TableExtractor

extractor = TableExtractor()
tables = extractor.extract_tables(html)

for table in tables:
    # í…ìŠ¤íŠ¸ í˜•ì‹
    print(table.to_text())
    
    # lab_tag í™•ì¸
    if 'lab_tags' in table.metadata:
        print(f"ë…¼ë¬¸ íƒœê·¸: {table.metadata['lab_tags']}")
        # ['CVPR2024', 'ICCV2023', 'NeurIPS2023']
    
    # JSON ë³€í™˜
    for row in table.to_dict_list():
        print(row)
        # {'Year': '2024', 'Venue': 'CVPR', 'Title': '...'}
```

#### ì´ë¯¸ì§€ OCR (ì„ íƒ)
- **íŒŒì¼**: `advanced_extractors.py` â†’ `ImageOCR` í´ë˜ìŠ¤
- **ì§€ì›**: pytesseract + Pillow
- **ì–¸ì–´**: í•œê¸€+ì˜ë¬¸ ë™ì‹œ ì¸ì‹
- **ë¹„ê¶Œì¥**: ì •í™•ë„ ë‚®ìŒ, í›„ìˆœìœ„

```python
from advanced_extractors import ImageOCR

ocr = ImageOCR()
text = ocr.extract_text("image.png", lang='kor+eng')
```

---

### âœ… 9) ê²€ìƒ‰/ì¶”ì²œ ë©”íƒ€ë°ì´í„°

#### Signals (ì¬ë­í‚¹ ê°€ì )
- **í…Œì´ë¸” í•„ë“œ** (`labs` í…Œì´ë¸”):
  - `recent_papers_count`: ìµœê·¼ 3ë…„ ë…¼ë¬¸ ìˆ˜
  - `has_awards`: ìˆ˜ìƒ ì´ë ¥ ì—¬ë¶€
  - `equipment_gpu`: GPU ì¥ë¹„ ìˆ˜
  - `equipment_robot`: ë¡œë´‡ ì¥ë¹„ ì—¬ë¶€

```sql
-- GPU ë§ì€ ì—°êµ¬ì‹¤ ìš°ì„  ì •ë ¬
SELECT * FROM labs 
WHERE is_active = TRUE 
ORDER BY equipment_gpu DESC, recent_papers_count DESC;
```

#### Constraints (ëª¨ì§‘ ì¡°ê±´)
- **í…Œì´ë¸” í•„ë“œ** (`labs` í…Œì´ë¸”):
  - `min_hours`: ìµœì†Œ ì°¸ì—¬ ì‹œê°„ (ì‹œê°„/ì£¼)
  - `weekend_ok`: ì£¼ë§ ê°€ëŠ¥ ì—¬ë¶€
  - `join_type`: ëª¨ì§‘ ìœ í˜• (í•™ë¶€ì—°êµ¬ìƒ/ëŒ€í•™ì›/ì¸í„´)

```sql
-- ì£¼ë§ ê°€ëŠ¥í•˜ê³  ì£¼ 10ì‹œê°„ ì´í•˜ ì—°êµ¬ì‹¤
SELECT * FROM labs 
WHERE weekend_ok = TRUE 
  AND (min_hours <= 10 OR min_hours IS NULL)
  AND is_active = TRUE;
```

#### Provenance (ì¶”ì²œ ì´ìœ )
- **í…Œì´ë¸” í•„ë“œ**: `documents.matched_snippet`
- **ìš©ë„**: ê²€ìƒ‰ ê²°ê³¼ì— "ì™œ ì´ ì—°êµ¬ì‹¤ì´ ì¶”ì²œë˜ì—ˆëŠ”ì§€" í‘œì‹œ
- **ìºì‹œ**: ìƒìœ„ ë§¤ì¹­ ë¬¸ì¥ì„ ë¯¸ë¦¬ ì €ì¥

```sql
-- ê²€ìƒ‰ ê²°ê³¼ì— ì¶”ì²œ ì´ìœ  í¬í•¨
SELECT 
    l.name,
    d.text,
    d.matched_snippet as "ì¶”ì²œ ì´ìœ ",
    1 - (d.embedding <=> query_emb) as similarity
FROM documents d
JOIN labs l ON d.lab_id = l.id
WHERE d.is_active = TRUE
ORDER BY similarity DESC
LIMIT 10;
```

---

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### ê¸°ë³¸ íŒ¨í‚¤ì§€
```bash
pip install requests beautifulsoup4 numpy sentence-transformers torch
```

### PDF ì§€ì›
```bash
pip install PyPDF2 pdfplumber
```

### OCR ì§€ì› (ì„ íƒ)
```bash
pip install pytesseract Pillow
# + Tesseract OCR ì—”ì§„ ì‹œìŠ¤í…œ ì„¤ì¹˜ í•„ìš”
```

### ì „ì²´ ì„¤ì¹˜
```bash
pip install -r requirements.txt
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ê³ ê¸‰ ê¸°ëŠ¥ ì¢…í•© í…ŒìŠ¤íŠ¸
python test_advanced_features.py
```

**í…ŒìŠ¤íŠ¸ í•­ëª©**:
1. âœ… í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
2. âœ… ê°€ë“œë ˆì¼ (PII ê°ì§€, URL ì°¨ë‹¨)
3. âœ… í¬ë¡¤ë§ ë§¤ë‹ˆì € (ì†ë„ ì œí•œ, ì¬ì‹œë„, ìºì‹±)
4. âœ… í‘œ ì¶”ì¶œ (ì»¬ëŸ¼ ë§¤í•‘, lab_tag ìƒì„±)
5. âš ï¸ PDF ì¶”ì¶œ (PDF íŒŒì¼ í•„ìš”)

---

## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### í–¥ìƒëœ ìŠ¤í‚¤ë§ˆ ì ìš©
```bash
psql -U postgres -d labsearch -f schema_enhanced.sql
```

### ì£¼ìš” í…Œì´ë¸”
- `labs` - ì—°êµ¬ì‹¤ ê¸°ë³¸ ì •ë³´ + ë©”íƒ€ë°ì´í„°
- `documents` - ì²­í¬ + í’ˆì§ˆ ì ìˆ˜ + ë²¡í„°
- `crawl_log` - í¬ë¡¤ë§ ê°ì‚¬ ë¡œê·¸
- `update_history` - ë³€ê²½ ì´ë ¥
- `contact_info` - ì—°ë½ì²˜ (PII ì£¼ì˜)
- `publications` - ë…¼ë¬¸ ë©”íƒ€ë°ì´í„°

### ìœ ìš©í•œ ë·°
- `active_labs_summary` - í™œì„± ì—°êµ¬ì‹¤ ìš”ì•½
- `crawl_statistics` - í¬ë¡¤ë§ í†µê³„

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

1. **ADVANCED_FEATURES.md** - ìƒì„¸ ê°€ì´ë“œ ë° ì½”ë“œ ì˜ˆì‹œ
2. **quality_guard.py** - í’ˆì§ˆ/ê°€ë“œë ˆì¼ êµ¬í˜„
3. **crawl_manager.py** - í¬ë¡¤ë§ ë§¤ë‹ˆì € êµ¬í˜„
4. **advanced_extractors.py** - PDF/í‘œ/OCR êµ¬í˜„
5. **schema_enhanced.sql** - í–¥ìƒëœ DB ìŠ¤í‚¤ë§ˆ

---

## ğŸ‰ ì™„ë£Œ!

ìš”ì²­í•˜ì‹  ëª¨ë“  ê¸°ëŠ¥ì´ êµ¬í˜„ë˜ì—ˆìŠµë‹ˆë‹¤:
- âœ… í’ˆì§ˆ ì ìˆ˜ (0-1)
- âœ… PII/ë¹„ê³µê°œ ì°¨ë‹¨
- âœ… robots.txt & ì†ë„ ì œì–´
- âœ… ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
- âœ… ì¬í¬ë¡¤ ì£¼ê¸° ê´€ë¦¬
- âœ… ì†Œí”„íŠ¸ ì‚­ì œ
- âœ… ê°ì‚¬ ë¡œê·¸
- âœ… PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
- âœ… í‘œ êµ¬ì¡° ë³´ì¡´ (lab_tag)
- âœ… ì´ë¯¸ì§€ OCR (ì„ íƒ)
- âœ… ê²€ìƒ‰/ì¶”ì²œ ë©”íƒ€ë°ì´í„°

ëª¨ë“  ì½”ë“œì— ìƒì„¸í•œ ì£¼ì„ê³¼ ì‚¬ìš© ì˜ˆì‹œê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤!
