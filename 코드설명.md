# 코드 설명서 - 초보자용 🔰

## 📚 목차
1. [전체 시스템 개요](#전체-시스템-개요)
2. [각 파일 상세 설명](#각-파일-상세-설명)
3. [주요 개념 설명](#주요-개념-설명)
4. [실행 흐름](#실행-흐름)

---

## 전체 시스템 개요

### 이 시스템이 하는 일
```
웹사이트 → 텍스트 추출 → 벡터 변환 → 저장 → 검색
```

**구체적으로:**
1. 연구실 홈페이지에 접속
2. "연구 분야", "논문" 등의 내용 추출
3. 텍스트를 768개의 숫자로 변환 (이게 임베딩)
4. JSON 파일에 저장
5. 검색어를 입력하면 유사한 내용 찾기

---

## 각 파일 상세 설명

### 1. `chunking.py` - 텍스트 자르기 도구

**역할:** 웹페이지를 적당한 크기로 자릅니다

**왜 필요한가요?**
- 웹페이지 전체는 너무 깁니다 (수천 글자)
- AI 모델은 짧은 텍스트를 더 잘 이해합니다
- 200-400자씩 잘라서 처리합니다

**주요 클래스:**

#### `Chunk` (청크 데이터)
```python
chunk = Chunk(
    text="우리 연구실은 AI를 연구합니다",  # 실제 텍스트
    section="about",                      # 종류 (소개/연구/논문 등)
    char_count=18,                        # 글자 수
    md5="abc123..."                       # 중복 체크용 ID
)
```

#### `ContentExtractor` (본문 추출기)
- 웹페이지에서 불필요한 부분 제거
  - ❌ 메뉴 (nav)
  - ❌ 푸터 (footer)
  - ❌ 광고 (advertisement)
  - ✅ 본문만 남김

#### `TextChunker` (텍스트 분할기)
```python
# 긴 텍스트를 200-400자로 자르기
long_text = "..." * 1000  # 1000자
chunks = TextChunker.chunk_text(long_text)
# → [chunk1(350자), chunk2(380자), chunk3(270자)]
```

---

### 2. `text_normalization.py` - 텍스트 정리 도구

**역할:** 텍스트를 깨끗하게 만듭니다

**처리 과정:**
```
"연락처: ai@lab.com    Copyright 2024"
         ↓
"연락처: " (이메일 제거, 저작권 제거, 공백 정리)
```

**주요 클래스:**

#### `LanguageDetector` (언어 감지)
```python
detect_language("안녕하세요")           # → 'ko' (한글)
detect_language("Hello world")        # → 'en' (영문)
detect_language("Hello 안녕")          # → 'mixed' (혼합)
```

**어떻게 감지하나요?**
- 한글 문자(가-힣) 개수를 셉니다
- 영문 문자(a-zA-Z) 개수를 셉니다
- 비율로 판단합니다

#### `ContactExtractor` (연락처 추출)
```python
text = "이메일: ai@lab.com, 전화: 032-860-7000"
emails = extract_emails(text)   # → ['ai@lab.com']
phones = extract_phones(text)   # → ['032-860-7000']
```

#### `TextCleaner` (텍스트 정리)
- 연속된 공백 → 하나로
- 저작권 문구 제거
- 특수문자 정리

---

### 3. `embedding.py` - 텍스트 → 숫자 변환 도구

**역할:** 텍스트를 AI가 이해할 수 있는 숫자로 변환합니다

**핵심 개념: 임베딩(Embedding)**
```
"인공지능 연구" → [0.123, -0.456, 0.789, ..., 0.234]
                   └── 768개의 숫자 ──┘
```

**왜 숫자로 변환하나요?**
- 컴퓨터는 텍스트를 직접 비교할 수 없습니다
- 숫자로 바꾸면 유사도를 계산할 수 있습니다
- 비슷한 의미 = 비슷한 숫자 패턴

**예시:**
```python
"AI 연구"     → [0.5, 0.3, 0.1, ...]  ← 이것과
"인공지능"    → [0.4, 0.3, 0.2, ...]  ← 이것은 가까움

"AI 연구"     → [0.5, 0.3, 0.1, ...]  ← 이것과
"요리 레시피"  → [-0.8, 0.9, -0.2, ...] ← 이것은 멀리 떨어짐
```

**주요 클래스:**

#### `EmbeddingPipeline` (임베딩 파이프라인)
```python
# 1. 초기화 (최초 1회, 모델 다운로드 1.1GB)
pipeline = EmbeddingPipeline()

# 2. 텍스트 → 벡터
result = pipeline.embed("컴퓨터 비전 연구")
print(result.embedding.shape)  # (768,) ← 768개 숫자
```

#### `EmbeddingCache` (캐시)
- 같은 텍스트는 다시 계산 안함
- 속도 향상 (10배 이상)

---

### 4. `local_storage.py` - 데이터 저장 도구 (로컬)

**역할:** PostgreSQL 없이 JSON 파일로 저장

**파일 구조:**
```
crawl_data/
├── labs.json          # 연구실 정보
│   {"1": {"name": "AI Lab", ...}}
│
├── documents.json     # 문서 + 임베딩
│   {"1": {"text": "...", "embedding": [0.1, 0.2, ...]}}
│
└── stats.json         # 통계
    {"total_labs": 5, "total_docs": 123}
```

**주요 메서드:**

#### `insert_lab()` - 연구실 추가
```python
lab_id = store.insert_lab({
    'kor_name': 'AI 연구실',
    'professor': '홍길동',
    'homepage': 'http://ailab.com'
})
# → lab_id = 1
```

#### `insert_document()` - 문서 추가
```python
doc_id = store.insert_document(
    lab_id=1,
    doc_data={
        'text': '우리는 AI를 연구합니다',
        'embedding': [0.1, 0.2, ...],  # 768개
        'section': 'about',
        'lang': 'ko'
    }
)
# → doc_id = 1
```

#### `search_vector()` - 검색
```python
# 쿼리를 벡터로 변환
query_emb = pipeline.embed("컴퓨터 비전")

# 검색
results = store.search_vector(
    query_emb.embedding,
    limit=5  # 상위 5개
)

# 결과 출력
for r in results:
    print(f"{r.lab_name}: {r.score:.3f}")
    # AI Lab: 0.823  ← 유사도 점수 (0~1)
```

---

### 5. `main_pipeline.py` - 통합 실행 도구

**역할:** 모든 모듈을 연결하여 실행

**전체 흐름:**
```
1. 연구실 목록 크롤링
   ↓
2. 각 연구실 처리:
   2-1. 홈페이지 접속
   2-2. 본문 추출 (chunking.py)
   2-3. 200-400자로 분할 (chunking.py)
   2-4. 텍스트 정리 (text_normalization.py)
   2-5. 벡터 변환 (embedding.py)
   2-6. 저장 (local_storage.py)
   ↓
3. 결과 요약
```

**중요 설정:**
```python
# 18번째 줄
USE_LOCAL = True   # ← True: JSON 파일
                   #    False: PostgreSQL
```

**주요 클래스:**

#### `CrawlOrchestrator` (크롤링 총괄)
```python
orchestrator = CrawlOrchestrator(
    embedding_model='multilingual-mpnet',  # 임베딩 모델
    device='cpu',                          # CPU 사용
    local_data_dir='./crawl_data'          # 저장 경로
)

# 실행
df_result = orchestrator.crawl_from_url(url)
```

---

### 6. `search_local.py` - 검색 테스트 도구

**역할:** 저장된 데이터에서 검색

**3가지 모드:**

#### 1. 대화형 모드 (추천)
```bash
python search_local.py
# → 프롬프트에서 계속 검색
```

#### 2. 단일 검색
```bash
python search_local.py --mode search --query "컴퓨터 비전"
```

#### 3. 통계 보기
```bash
python search_local.py --mode stats
```

---

## 주요 개념 설명

### 1. 임베딩(Embedding)이란?

**간단 설명:**
- 텍스트를 숫자 리스트로 변환하는 것
- AI가 텍스트의 "의미"를 이해할 수 있게 함

**비유:**
```
텍스트 = 사람 얼굴
임베딩 = 얼굴의 특징 (눈 크기, 코 높이, ...)

비슷한 얼굴 → 비슷한 특징값
비슷한 텍스트 → 비슷한 임베딩
```

### 2. 벡터 검색이란?

**일반 검색 (키워드):**
```
검색어: "AI"
결과: "AI"가 포함된 문서만
```

**벡터 검색 (의미):**
```
검색어: "AI"
결과: "AI", "인공지능", "머신러닝", "딥러닝" 모두 찾음
      (의미가 비슷하면 모두 찾음)
```

### 3. 코사인 유사도란?

**두 벡터가 얼마나 비슷한지 측정**
```
유사도 1.0 = 완전 동일
유사도 0.5 = 50% 비슷
유사도 0.0 = 완전 다름
```

**계산 방법:**
```python
def cosine_similarity(vec1, vec2):
    # 두 벡터의 내적 ÷ (길이1 × 길이2)
    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
```

---

## 실행 흐름

### 크롤링 실행 시

```
1. python main_pipeline.py 실행
   ↓
2. 임베딩 모델 로드 (1.1GB, 최초 1회)
   ↓
3. 연구실 목록 크롤링
   https://inhaece.co.kr/page/labs05
   ↓
4. 각 연구실 처리 (총 N개)
   [1/N] AI 연구실
   ├─ 홈페이지 방문
   ├─ 본문 추출
   ├─ 청킹 (200-400자)
   ├─ 정규화 (언어 감지, 정리)
   ├─ 임베딩 (텍스트 → 벡터)
   └─ JSON 저장
   
   [2/N] 비전 연구실
   ...
   ↓
5. 결과 저장
   ├─ crawl_data/labs.json
   ├─ crawl_data/documents.json
   └─ crawl_results.csv
```

### 검색 실행 시

```
1. python search_local.py 실행
   ↓
2. JSON 파일 로드
   - labs.json
   - documents.json
   ↓
3. 임베딩 모델 로드
   ↓
4. 검색어 입력: "컴퓨터 비전"
   ↓
5. 검색어를 벡터로 변환
   "컴퓨터 비전" → [0.1, 0.2, ..., 0.5]
   ↓
6. 모든 문서와 유사도 계산
   문서1: 0.85 ← 매우 유사
   문서2: 0.42
   문서3: 0.91 ← 가장 유사
   ...
   ↓
7. 유사도 순 정렬 및 출력
   1위: 문서3 (0.91)
   2위: 문서1 (0.85)
   ...
```

---

## 자주 묻는 질문 (FAQ)

### Q1: 임베딩이 정확히 뭔가요?
**A:** 텍스트를 768개의 숫자로 바꾸는 것입니다. 이 숫자들이 텍스트의 "의미"를 나타냅니다.

### Q2: 왜 768개 숫자인가요?
**A:** 사용하는 AI 모델이 768차원으로 설계되었습니다. 다른 모델은 512차원, 1024차원 등 다양합니다.

### Q3: 로컬 모드와 PostgreSQL 모드의 차이?
**A:**
- **로컬 모드**: JSON 파일 사용, 간단, 소규모에 적합
- **PostgreSQL 모드**: 데이터베이스 사용, 복잡, 대규모에 적합

### Q4: 검색이 느린데요?
**A:** 
- 문서가 많으면 느려집니다 (수백 개 이상)
- PostgreSQL 모드를 사용하면 빠릅니다
- GPU를 사용하면 임베딩이 빨라집니다

### Q5: 모델 다운로드가 오래 걸려요
**A:** 
- 최초 1회만 다운로드합니다 (1.1GB)
- 이후에는 캐시에서 바로 로드됩니다
- 인터넷 속도에 따라 5-10분 소요

---

## 코드 읽는 순서 (추천)

초보자라면 이 순서로 읽어보세요:

1. **`chunking.py`의 `Chunk` 클래스** - 데이터 구조 이해
2. **`local_storage.py`의 `LocalDocument` 클래스** - 저장 형식 이해
3. **`search_local.py`의 `search_local()` 함수** - 전체 흐름 이해
4. **`main_pipeline.py`의 `main()` 함수** - 실행 과정 이해
5. 나머지 파일들 - 세부 구현 이해

---

## 마무리

이 시스템의 핵심:
1. **웹 크롤링** - 데이터 수집
2. **임베딩** - 텍스트 → 숫자
3. **벡터 검색** - 의미 기반 검색

모든 코드에 자세한 주석이 추가되어 있으니, 직접 파일을 열어서 읽어보세요! 🚀
