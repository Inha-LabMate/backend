"""
ê°„ë‹¨í•œ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° ëª¨ë“ˆì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
"""

import sys


def test_imports():
    """ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("1. ëª¨ë“ˆ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    modules = [
        'chunking',
        'text_normalization',
        'embedding',
        'vector_db',
        'main_pipeline'
    ]
    
    for module in modules:
        try:
            __import__(module)
            print(f"âœ… {module}")
        except ImportError as e:
            print(f"âŒ {module}: {e}")
            return False
    
    print()
    return True


def test_chunking():
    """ì²­í‚¹ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("2. ì²­í‚¹ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    try:
        from chunking import DocumentProcessor
        
        processor = DocumentProcessor()
        
        sample_html = """
        <html>
        <body>
            <main>
                <h1>í…ŒìŠ¤íŠ¸ ì—°êµ¬ì‹¤</h1>
                <p>ìš°ë¦¬ ì—°êµ¬ì‹¤ì€ ì¸ê³µì§€ëŠ¥ì„ ì—°êµ¬í•©ë‹ˆë‹¤. """ + "AI "* 50 + """</p>
                <p>ì£¼ìš” ì—°êµ¬ ë¶„ì•¼ëŠ” ì»´í“¨í„° ë¹„ì „ì…ë‹ˆë‹¤.</p>
            </main>
        </body>
        </html>
        """
        
        chunks = processor.process_html(
            html=sample_html,
            url="https://example.com/lab"
        )
        
        print(f"  ìƒì„±ëœ ì²­í¬: {len(chunks)}ê°œ")
        
        if chunks:
            print(f"  ì²« ë²ˆì§¸ ì²­í¬:")
            print(f"    - ì„¹ì…˜: {chunks[0].section}")
            print(f"    - ê¸¸ì´: {chunks[0].char_count}ì")
            print(f"    - í† í°: {chunks[0].token_count}")
            print(f"    - MD5: {chunks[0].md5[:16]}...")
        
        print("âœ… ì²­í‚¹ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
    except Exception as e:
        print(f"âŒ ì²­í‚¹ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    print()
    return True


def test_normalization():
    """ì •ê·œí™” ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("3. í…ìŠ¤íŠ¸ ì •ê·œí™” í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    try:
        from text_normalization import TextNormalizer
        
        normalizer = TextNormalizer()
        
        sample_text = """
        ìš°ë¦¬ ì—°êµ¬ì‹¤ì€ AIë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤.
        ì—°ë½ì²˜: test@example.com
        ì „í™”: 032-860-7000
        URL: https://example.com
        
        Copyright Â© 2024
        """
        
        result = normalizer.normalize(sample_text)
        
        print(f"  ì–¸ì–´: {result.language}")
        print(f"  í† í°: {result.tokens}")
        print(f"  ì´ë©”ì¼: {len(result.emails)}ê°œ")
        print(f"  URL: {len(result.urls)}ê°œ")
        print(f"  ì „í™”: {len(result.phones)}ê°œ")
        print(f"  ì •ë¦¬ëœ í…ìŠ¤íŠ¸: {len(result.cleaned_text)}ì")
        
        print("âœ… ì •ê·œí™” í…ŒìŠ¤íŠ¸ í†µê³¼")
        
    except Exception as e:
        print(f"âŒ ì •ê·œí™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    print()
    return True


def test_embedding():
    """ì„ë² ë”© ëª¨ë“ˆ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("4. ì„ë² ë”© ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    try:
        from embedding import EmbeddingPipeline
        import numpy as np
        
        print("  ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        pipeline = EmbeddingPipeline(
            model_name='multilingual-mpnet',
            device='cpu'
        )
        
        texts = [
            "ì¸ê³µì§€ëŠ¥ ì—°êµ¬",
            "ì»´í“¨í„° ë¹„ì „",
            "Artificial Intelligence"
        ]
        
        print(f"  {len(texts)}ê°œ í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘...")
        results = pipeline.embed(texts)
        
        print(f"  ì„ë² ë”© ì™„ë£Œ:")
        for i, result in enumerate(results):
            print(f"    {i+1}. shape={result.embedding.shape}, "
                  f"norm={np.linalg.norm(result.embedding):.3f}")
        
        # ìœ ì‚¬ë„ í…ŒìŠ¤íŠ¸
        from embedding import cosine_similarity
        sim = cosine_similarity(results[0].embedding, results[1].embedding)
        print(f"  ìœ ì‚¬ë„ ('ì¸ê³µì§€ëŠ¥ ì—°êµ¬' vs 'ì»´í“¨í„° ë¹„ì „'): {sim:.3f}")
        
        print("âœ… ì„ë² ë”© í…ŒìŠ¤íŠ¸ í†µê³¼")
        
    except ImportError as e:
        print(f"âš ï¸  ì„ë² ë”© ëª¨ë“ˆ ìŠ¤í‚µ (sentence-transformers ë¯¸ì„¤ì¹˜): {e}")
        return True  # ì„ë² ë”©ì€ ì„ íƒ ì‚¬í•­ìœ¼ë¡œ ì²˜ë¦¬
    except Exception as e:
        print(f"âŒ ì„ë² ë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    print()
    return True


def test_database_schema():
    """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸"""
    print("="*80)
    print("5. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ í™•ì¸")
    print("="*80)
    
    try:
        with open('schema.sql', 'r', encoding='utf-8') as f:
            schema = f.read()
        
        # ì£¼ìš” í…Œì´ë¸” í™•ì¸
        tables = ['lab', 'lab_docs', 'lab_tag', 'lab_link', 'crawl_log', 'search_log']
        
        for table in tables:
            if f"CREATE TABLE IF NOT EXISTS {table}" in schema:
                print(f"  âœ… {table} í…Œì´ë¸” ì •ì˜ ì¡´ì¬")
            else:
                print(f"  âŒ {table} í…Œì´ë¸” ì •ì˜ ì—†ìŒ")
                return False
        
        # í•¨ìˆ˜ í™•ì¸
        functions = ['search_by_vector', 'hybrid_search', 'check_duplicate_chunk']
        
        for func in functions:
            if f"CREATE OR REPLACE FUNCTION {func}" in schema:
                print(f"  âœ… {func} í•¨ìˆ˜ ì •ì˜ ì¡´ì¬")
            else:
                print(f"  âŒ {func} í•¨ìˆ˜ ì •ì˜ ì—†ìŒ")
                return False
        
        print("âœ… ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸ í†µê³¼")
        
    except Exception as e:
        print(f"âŒ ìŠ¤í‚¤ë§ˆ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False
    
    print()
    return True


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "="*80)
    print("ì—°êµ¬ì‹¤ ê²€ìƒ‰ ì‹œìŠ¤í…œ - í†µí•© í…ŒìŠ¤íŠ¸")
    print("="*80)
    print()
    
    tests = [
        ("Import", test_imports),
        ("Chunking", test_chunking),
        ("Normalization", test_normalization),
        ("Embedding", test_embedding),
        ("Database Schema", test_database_schema)
    ]
    
    results = []
    
    for name, test_func in tests:
        try:
            passed = test_func()
            results.append((name, passed))
        except Exception as e:
            print(f"âŒ {name} í…ŒìŠ¤íŠ¸ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
            results.append((name, False))
    
    # ê²°ê³¼ ìš”ì•½
    print("="*80)
    print("í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("="*80)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {status}: {name}")
    
    print()
    print(f"ì´ {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼ ({passed/total*100:.0f}%)")
    
    if passed == total:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼!")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("  1. PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •")
        print("  2. python main_pipeline.py ì‹¤í–‰")
        print("  3. uvicorn search_api:app --reload ì‹¤í–‰")
        return 0
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        print("  ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ë¥¼ í™•ì¸í•˜ê³  í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return 1


if __name__ == "__main__":
    sys.exit(main())
