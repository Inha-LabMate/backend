# ì‹œìŠ¤í…œ êµ¬ì¡° (Architecture)

## ğŸ—ï¸ ì „ì²´ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ì‚¬ìš©ì                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚í¬ë¡¤ë§    â”‚            â”‚ê²€ìƒ‰           â”‚
â”‚ ì‹¤í–‰     â”‚            â”‚(ë¡œì»¬/API)     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚                        â”‚
     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚  â”‚
     â–¼  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         í•µì‹¬ íŒŒì´í”„ë¼ì¸               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 1. í¬ë¡¤ë§ ê´€ë¦¬ì (Playwright)   â”‚ â”‚
â”‚  â”‚    - JavaScript ì™„ì „ ì‹¤í–‰       â”‚ â”‚
â”‚  â”‚    - ë„¤íŠ¸ì›Œí¬ ì™„ë£Œ ëŒ€ê¸°         â”‚ â”‚
â”‚  â”‚    - ì†ë„ ì œì–´ & ì¬ì‹œë„        â”‚ â”‚
â”‚  â”‚    - ìºì‹±                      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 2. ì½˜í…ì¸  ì¶”ì¶œ                  â”‚ â”‚
â”‚  â”‚    - HTML íŒŒì‹±                 â”‚ â”‚
â”‚  â”‚    - ë³¸ë¬¸ ì¶”ì¶œ (ë„¤ë¹„/í‘¸í„° ì œê±°) â”‚ â”‚
â”‚  â”‚    - PDF/í‘œ ì¶”ì¶œ               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 3. í…ìŠ¤íŠ¸ ì²˜ë¦¬                  â”‚ â”‚
â”‚  â”‚    - ì²­í‚¹ (200-400ì)          â”‚ â”‚
â”‚  â”‚    - ì •ê·œí™” (ì–¸ì–´ ê°ì§€, ì •ë¦¬)   â”‚ â”‚
â”‚  â”‚    - í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°            â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 4. ì„ë² ë”© ìƒì„±                  â”‚ â”‚
â”‚  â”‚    - í…ìŠ¤íŠ¸ â†’ 768ì°¨ì› ë²¡í„°      â”‚ â”‚
â”‚  â”‚    - ë°°ì¹˜ ì²˜ë¦¬ & ìºì‹±          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ 5. ì €ì¥                        â”‚ â”‚
â”‚  â”‚    - ë¡œì»¬ JSON                 â”‚ â”‚
â”‚  â”‚    - PostgreSQL + pgvector     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         ë°ì´í„° ì €ì¥ì†Œ                 â”‚
â”‚                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ ë¡œì»¬ JSON    â”‚  â”‚ PostgreSQL   â”‚ â”‚
â”‚  â”‚              â”‚  â”‚ + pgvector   â”‚ â”‚
â”‚  â”‚ crawl_data/  â”‚  â”‚              â”‚ â”‚
â”‚  â”‚ â”œâ”€ labs.json â”‚  â”‚ â”œâ”€ lab       â”‚ â”‚
â”‚  â”‚ â””â”€ docs.json â”‚  â”‚ â”œâ”€ lab_docs  â”‚ â”‚
â”‚  â”‚              â”‚  â”‚ â”œâ”€ lab_tag   â”‚ â”‚
â”‚  â”‚              â”‚  â”‚ â””â”€ lab_link  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
code/
â”œâ”€â”€ src/                      # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ main_pipeline.py      # ğŸ¯ ë©”ì¸ íŒŒì´í”„ë¼ì¸ (í¬ë¡¤ë§ ì‹¤í–‰)
â”‚   â”œâ”€â”€ crawl_manager.py      # ğŸ•·ï¸ í¬ë¡¤ë§ ê´€ë¦¬ì
â”‚   â”œâ”€â”€ quality_guard.py      # ğŸ›¡ï¸ í’ˆì§ˆ ê´€ë¦¬ & ê°€ë“œë ˆì¼
â”‚   â”œâ”€â”€ advanced_extractors.py # ğŸ“„ PDF/í‘œ/OCR ì¶”ì¶œ
â”‚   â”œâ”€â”€ chunking.py           # âœ‚ï¸ í…ìŠ¤íŠ¸ ì²­í‚¹ & ë³¸ë¬¸ ì¶”ì¶œ
â”‚   â”œâ”€â”€ text_normalization.py # ğŸ§¹ í…ìŠ¤íŠ¸ ì •ê·œí™”
â”‚   â”œâ”€â”€ embedding.py          # ğŸ§  ì„ë² ë”© ìƒì„±
â”‚   â”œâ”€â”€ vector_db.py          # ğŸ—„ï¸ PostgreSQL ë²¡í„° DB
â”‚   â”œâ”€â”€ local_storage.py      # ğŸ’¾ ë¡œì»¬ JSON ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ search_api.py         # ğŸŒ REST API ì„œë²„
â”‚   â””â”€â”€ search_local.py       # ğŸ” ë¡œì»¬ ê²€ìƒ‰ ìŠ¤í¬ë¦½íŠ¸
â”‚
â”œâ”€â”€ crawl_data/               # ìµœì¢… ê²°ê³¼ (í”„ë¡œë•ì…˜)
â”‚   â”œâ”€â”€ labs.json
â”‚   â”œâ”€â”€ documents.json
â”‚   â””â”€â”€ stats.json
â”‚
â”œâ”€â”€ temp/                     # ì„ì‹œ/í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚   â”œâ”€â”€ test_embedding_data/
â”‚   â””â”€â”€ test_local_data/
â”‚
â”œâ”€â”€ data/                     # ë²„ì „ ê´€ë¦¬ìš© ë°ì´í„°
â”‚   â”œâ”€â”€ v1.0/
â”‚   â””â”€â”€ latest/
â”‚
â”œâ”€â”€ docs/                     # ë¬¸ì„œ
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ installation.md
â”‚   â”œâ”€â”€ crawling.md
â”‚   â”œâ”€â”€ search.md
â”‚   â””â”€â”€ architecture.md (ì´ íŒŒì¼)
â”‚
â”œâ”€â”€ schema.sql                # PostgreSQL ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ
â”œâ”€â”€ schema_enhanced.sql       # PostgreSQL ê³ ê¸‰ ìŠ¤í‚¤ë§ˆ
â”œâ”€â”€ requirements.txt          # Python íŒ¨í‚¤ì§€
â””â”€â”€ .gitignore               # Git ì œì™¸ ì„¤ì •
```

## ğŸ”„ ë°ì´í„° íë¦„

### í¬ë¡¤ë§ â†’ ì €ì¥

```
[ì›¹í˜ì´ì§€ HTML]
    â†“
[CrawlManager] robots.txt í™•ì¸, ì†ë„ ì œì–´, ì¬ì‹œë„
    â†“
[ContentExtractor] ë³¸ë¬¸ ì¶”ì¶œ (BeautifulSoup)
    â†“
[TextChunker] 200-400ìë¡œ ë¶„í• 
    â†“
[QualityScorer] í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-1)
    â†“
[GuardRail] PII/ë¹„ê³µê°œ ì°¨ë‹¨
    â†“
[TextNormalizer]
    â”œâ”€ ì–¸ì–´ ê°ì§€ (ko/en/mixed)
    â”œâ”€ ì—°ë½ì²˜ ì¶”ì¶œ
    â””â”€ í…ìŠ¤íŠ¸ ì •ë¦¬
    â†“
[EmbeddingPipeline] í…ìŠ¤íŠ¸ â†’ 768ì°¨ì› ë²¡í„°
    â†“
[LocalVectorStore ë˜ëŠ” VectorDatabase]
    â”œâ”€ MD5 í•´ì‹œë¡œ ì¤‘ë³µ ì²´í¬
    â””â”€ ì €ì¥
```

### ê²€ìƒ‰

```
[ê²€ìƒ‰ì–´ "ì»´í“¨í„° ë¹„ì „"]
    â†“
[EmbeddingPipeline] ê²€ìƒ‰ì–´ â†’ 768ì°¨ì› ë²¡í„°
    â†“
[LocalVectorStore ë˜ëŠ” VectorDatabase]
    â”œâ”€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    â”œâ”€ ìœ ì‚¬ë„ ìˆœ ì •ë ¬
    â””â”€ ìƒìœ„ Nê°œ ë°˜í™˜
    â†“
[ê²€ìƒ‰ ê²°ê³¼]
```

## ğŸ§© í•µì‹¬ ëª¨ë“ˆ ìƒì„¸

### 1. main_pipeline.py

**ì—­í• :** ì „ì²´ í¬ë¡¤ë§ í”„ë¡œì„¸ìŠ¤ ì´ê´„

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `LabCrawler`
```python
class LabCrawler:
    """ì—°êµ¬ì‹¤ ëª©ë¡ í¬ë¡¤ë§"""
    
    def crawl_lab_list(url: str) -> List[Dict]:
        """ì—°êµ¬ì‹¤ ëª©ë¡ í˜ì´ì§€ íŒŒì‹±"""
        # https://inhaece.co.kr/page/labs05
        # â†’ ì—°êµ¬ì‹¤ ì´ë¦„, êµìˆ˜, í™ˆí˜ì´ì§€, ìœ„ì¹˜, ì—°ë½ì²˜
```

#### `CrawlOrchestrator`
```python
class CrawlOrchestrator:
    """í¬ë¡¤ë§ ì´ê´„ ê´€ë¦¬ì"""
    
    def __init__(
        self,
        db_config=None,
        embedding_model='multilingual-mpnet',
        device='cpu',
        local_data_dir='./crawl_data'
    )
    
    def crawl_from_url(url: str) -> DataFrame:
        """ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰"""
        # 1. ì—°êµ¬ì‹¤ ëª©ë¡ í¬ë¡¤ë§
        # 2. ê° ì—°êµ¬ì‹¤ í™ˆí˜ì´ì§€ í¬ë¡¤ë§
        # 3. í…ìŠ¤íŠ¸ ì²˜ë¦¬ & ì„ë² ë”©
        # 4. ì €ì¥
        # â†’ DataFrame ë°˜í™˜
```

### 2. crawl_manager.py

**ì—­í• :** Playwright ê¸°ë°˜ JavaScript ë Œë”ë§ í¬ë¡¤ë§

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `CrawlManager`
```python
class CrawlManager:
    """Playwright ê¸°ë°˜ í¬ë¡¤ë§ ê´€ë¦¬ì"""
    
    def __init__(
        self,
        delay=1.0,                 # ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        max_retries=3,             # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        timeout=30000,             # í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ)
        headless=True,             # ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€
        wait_for_network_idle=True, # ë„¤íŠ¸ì›Œí¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        cache_dir='./crawl_cache'
    )
    
    def fetch_url(url: str) -> CrawlResult:
        """URL ê°€ì ¸ì˜¤ê¸° (Playwrightë¡œ JavaScript ì‹¤í–‰)"""
        # 1. ìºì‹œ í™•ì¸
        # 2. ì†ë„ ì œì–´ (ë§ˆì§€ë§‰ ìš”ì²­ í›„ delay ëŒ€ê¸°)
        # 3. Playwrightë¡œ ë¸Œë¼ìš°ì € ì‹¤í–‰
        # 4. JavaScript ì‹¤í–‰ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        # 5. ìµœì¢… HTML ì¶”ì¶œ
        # 6. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (ì§€ìˆ˜ ë°±ì˜¤í”„)
        # 7. ìºì‹±
```

**Playwright í¬ë¡¤ë§ ê³¼ì •:**
```python
with sync_playwright() as p:
    # 1. Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰ (headless)
    browser = p.chromium.launch(headless=True)
    
    # 2. ìƒˆ í˜ì´ì§€ ì—´ê¸°
    context = browser.new_context(user_agent=...)
    page = context.new_page()
    
    # 3. URL ì ‘ì† + JavaScript ì‹¤í–‰
    page.goto(url, wait_until='networkidle')  # ë„¤íŠ¸ì›Œí¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    
    # 4. ì¶”ê°€ ëŒ€ê¸° (ë™ì  ì½˜í…ì¸ )
    page.wait_for_timeout(1000)  # 1ì´ˆ
    
    # 5. ìµœì¢… HTML ì¶”ì¶œ
    html = page.content()
    
    # 6. ë¸Œë¼ìš°ì € ì¢…ë£Œ
    browser.close()
```

**ì™œ Playwright?**
- âœ… Google Sites: JavaScriptë¡œ ì½˜í…ì¸  ìƒì„± â†’ Playwright í•„ìˆ˜
- âœ… Wix: ë™ì  ë Œë”ë§ â†’ Playwright í•„ìˆ˜
- âœ… React/Vue SPA: ì´ˆê¸° HTML ë¹„ì–´ìˆìŒ â†’ Playwright í•„ìˆ˜
- âŒ requests: ì •ì  HTMLë§Œ ê°€ì ¸ì˜´ â†’ ìµœì‹  ì‚¬ì´íŠ¸ ëŒ€ë¶€ë¶„ ì‹¤íŒ¨

**ì¬ì‹œë„ ì „ëµ (ì§€ìˆ˜ ë°±ì˜¤í”„):**
```python
def exponential_backoff(attempt: int) -> float:
    """ì¬ì‹œë„ ëŒ€ê¸° ì‹œê°„ ê³„ì‚°"""
    return min(2 ** attempt, 60)  # 1ì´ˆ â†’ 2ì´ˆ â†’ 4ì´ˆ â†’ ... (ìµœëŒ€ 60ì´ˆ)
```

### 3. quality_guard.py

**ì—­í• :** í’ˆì§ˆ ê´€ë¦¬ & ì•ˆì „ì¥ì¹˜

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `QualityScorer`
```python
class QualityScorer:
    """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
    
    def calculate_quality(
        chunk: Chunk,
        all_chunks: List[Chunk]
    ) -> QualityReport:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-1)"""
        # 1. ì„¹ì…˜ ì¼ì¹˜ë„ (30%)
        # 2. ê¸¸ì´ ì ì ˆì„± (25%)
        # 3. ì–¸ì–´ ì¼ê´€ì„± (25%)
        # 4. ì¤‘ë³µ ì—¬ë¶€ (20%)
        # â†’ overall_score, needs_review, reason
```

**ì ìˆ˜ ê³„ì‚° ë¡œì§:**
```python
# ì„¹ì…˜ ì¼ì¹˜ë„
section_keywords = {
    'about': ['ì†Œê°œ', 'ì—°êµ¬ì‹¤', 'about', 'introduction'],
    'research': ['ì—°êµ¬', 'ë¶„ì•¼', 'research', 'interests'],
    ...
}
section_score = count_keywords(chunk.text, section_keywords[chunk.section])

# ê¸¸ì´ ì ì ˆì„±
optimal_length = 300  # 200-400ì ìµœì 
length_score = 1.0 - abs(chunk.char_count - optimal_length) / optimal_length

# ì–¸ì–´ ì¼ê´€ì„±
if chunk.lang == 'mixed':
    lang_score = 0.5
else:
    lang_score = 1.0

# ì¤‘ë³µ ì—¬ë¶€
if chunk.md5 in existing_hashes:
    duplicate_score = 0.0
else:
    duplicate_score = 1.0

# ìµœì¢… ì ìˆ˜
overall_score = (
    section_score * 0.3 +
    length_score * 0.25 +
    lang_score * 0.25 +
    duplicate_score * 0.2
)
```

#### `GuardRail`
```python
class GuardRail:
    """PII/ë¹„ê³µê°œ ì°¨ë‹¨"""
    
    def should_exclude_url(url: str) -> Tuple[bool, str]:
        """URL ì°¨ë‹¨ ì—¬ë¶€ í™•ì¸"""
        # /login, /admin, /portal ë“±
    
    def detect_pii_in_text(text: str) -> Tuple[bool, List[str]]:
        """ê°œì¸ì •ë³´ ê°ì§€"""
        # 'ë¹„ë°€ë²ˆí˜¸', 'password', 'ê°œì¸ì •ë³´' ë“±
    
    def detect_pii_in_html(html: str) -> Tuple[bool, List[str]]:
        """HTML í¼ í•„ë“œ ê°ì§€"""
        # <input type="password">, <input type="email">
```

### 4. chunking.py

**ì—­í• :** í…ìŠ¤íŠ¸ ë¶„í•  & ë³¸ë¬¸ ì¶”ì¶œ

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `Chunk`
```python
@dataclass
class Chunk:
    text: str               # ë³¸ë¬¸
    section: str            # about, research, publication, ...
    char_count: int         # ê¸€ì ìˆ˜
    token_count: int        # í† í° ìˆ˜ (ì¶”ì •)
    md5: str                # ì¤‘ë³µ ê°ì§€ìš© í•´ì‹œ
    source_url: str         # ì¶œì²˜ URL
    crawl_depth: int        # í¬ë¡¤ë§ ê¹Šì´
    quality_score: float    # í’ˆì§ˆ ì ìˆ˜ (0-1)
    needs_review: bool      # ê²€ìˆ˜ í•„ìš” ì—¬ë¶€
```

#### `ContentExtractor`
```python
class ContentExtractor:
    """ë³¸ë¬¸ ì¶”ì¶œ"""
    
    def clean_html(html: str, url: str) -> str:
        """HTML â†’ ê¹¨ë—í•œ í…ìŠ¤íŠ¸"""
        # 1. BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        # 2. ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (nav, footer, script, style)
        # 3. ë³¸ë¬¸ë§Œ ì¶”ì¶œ (Readability ê³„ì—´ ì•Œê³ ë¦¬ì¦˜)
        # 4. ê³µë°± ì •ë¦¬
```

#### `TextChunker`
```python
class TextChunker:
    """í…ìŠ¤íŠ¸ ë¶„í• """
    
    def chunk_text(
        text: str,
        min_chars=200,
        max_chars=400
    ) -> List[Chunk]:
        """ë¬¸ë‹¨ ê¸°ì¤€ ì²­í‚¹"""
        # 1. ë¬¸ë‹¨ ë¶„ë¦¬ (\n\n)
        # 2. 200-400ì ë²”ìœ„ ìœ ì§€
        # 3. ë„ˆë¬´ ì§§ìœ¼ë©´ ë³‘í•©
        # 4. ë„ˆë¬´ ê¸¸ë©´ ë¶„í• 
```

### 5. text_normalization.py

**ì—­í• :** í…ìŠ¤íŠ¸ ì •ê·œí™”

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `LanguageDetector`
```python
class LanguageDetector:
    """ì–¸ì–´ ê°ì§€"""
    
    def detect_language(text: str) -> str:
        """ko, en, mixed"""
        korean_chars = len(re.findall(r'[ê°€-í£]', text))
        english_chars = len(re.findall(r'[a-zA-Z]', text))
        
        if korean_chars > english_chars * 2:
            return 'ko'
        elif english_chars > korean_chars * 2:
            return 'en'
        else:
            return 'mixed'
```

#### `ContactExtractor`
```python
class ContactExtractor:
    """ì—°ë½ì²˜ ì¶”ì¶œ"""
    
    def extract_emails(text: str) -> List[str]:
        """ì´ë©”ì¼ ì •ê·œì‹"""
        pattern = r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'
    
    def extract_phones(text: str) -> List[str]:
        """ì „í™”ë²ˆí˜¸ ì •ê·œì‹"""
        pattern = r'\d{2,3}-\d{3,4}-\d{4}'
    
    def extract_urls(text: str) -> List[str]:
        """URL ì •ê·œì‹"""
        pattern = r'https?://[^\s]+'
```

#### `TextCleaner`
```python
class TextCleaner:
    """í…ìŠ¤íŠ¸ ì •ë¦¬"""
    
    def clean_text(text: str) -> str:
        """ì •ë¦¬"""
        # 1. ì—°ì† ê³µë°± â†’ í•˜ë‚˜ë¡œ
        # 2. ì €ì‘ê¶Œ ë¬¸êµ¬ ì œê±° (Â© Copyright ...)
        # 3. ë‚´ë¹„ê²Œì´ì…˜ í…ìŠ¤íŠ¸ ì œê±° (Home > About > ...)
        # 4. íŠ¹ìˆ˜ë¬¸ì ì •ë¦¬
```

### 6. embedding.py

**ì—­í• :** í…ìŠ¤íŠ¸ â†’ ë²¡í„° ë³€í™˜

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `EmbeddingPipeline`
```python
class EmbeddingPipeline:
    """ì„ë² ë”© íŒŒì´í”„ë¼ì¸"""
    
    def __init__(
        self,
        model_name='multilingual-mpnet',
        device='cpu',
        cache_enabled=True
    )
    
    def embed(
        texts: Union[str, List[str]],
        batch_size=32
    ) -> Union[EmbeddingResult, List[EmbeddingResult]]:
        """ì„ë² ë”© ìƒì„±"""
        # 1. ìºì‹œ í™•ì¸
        # 2. ëª¨ë¸ ë¡œë“œ
        # 3. ë°°ì¹˜ ì²˜ë¦¬
        # 4. L2 ì •ê·œí™”
        # 5. ìºì‹œ ì €ì¥
```

**ì§€ì› ëª¨ë¸:**
```python
SUPPORTED_MODELS = {
    'multilingual-mpnet': {
        'name': 'sentence-transformers/paraphrase-multilingual-mpnet-base-v2',
        'dimension': 768,
        'description': 'ë‹¤êµ­ì–´ ì§€ì›, ë¹ ë¦„'
    },
    'multilingual-e5-large': {
        'name': 'intfloat/multilingual-e5-large',
        'dimension': 1024,
        'description': 'ê³ í’ˆì§ˆ, ëŠë¦¼'
    },
    'ko-sbert-multitask': {
        'name': 'jhgan/ko-sbert-multitask',
        'dimension': 768,
        'description': 'í•œêµ­ì–´ íŠ¹í™”'
    }
}
```

### 7. local_storage.py

**ì—­í• :** ë¡œì»¬ JSON ì €ì¥ì†Œ

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `LocalVectorStore`
```python
class LocalVectorStore:
    """ë¡œì»¬ JSON ë²¡í„° ì €ì¥ì†Œ"""
    
    def __init__(self, data_dir='./crawl_data')
    
    def insert_lab(lab_data: Dict) -> int:
        """ì—°êµ¬ì‹¤ ì¶”ê°€"""
        # labs.jsonì— ì¶”ê°€
    
    def insert_document(lab_id: int, doc_data: Dict) -> int:
        """ë¬¸ì„œ ì¶”ê°€"""
        # documents.jsonì— ì¶”ê°€
        # embeddingì€ ë¦¬ìŠ¤íŠ¸ë¡œ ì €ì¥
    
    def search_vector(
        query_embedding: np.ndarray,
        limit=5,
        section_filter=None,
        min_quality=0.0
    ) -> List[SearchResult]:
        """ë²¡í„° ê²€ìƒ‰"""
        # 1. ëª¨ë“  ë¬¸ì„œì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        # 2. í•„í„° ì ìš©
        # 3. ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        # 4. ìƒìœ„ Nê°œ ë°˜í™˜
```

**íŒŒì¼ êµ¬ì¡°:**

`crawl_data/labs.json`:
```json
{
  "1": {
    "lab_id": 1,
    "kor_name": "AI ì—°êµ¬ì‹¤",
    "eng_name": "AI Lab",
    "professor": "í™ê¸¸ë™",
    "homepage": "http://ailab.com",
    "location": "7í˜¸ê´€ 701í˜¸",
    "contact_email": "ai@lab.com"
  }
}
```

`crawl_data/documents.json`:
```json
{
  "1": {
    "doc_id": 1,
    "lab_id": 1,
    "section": "research",
    "text": "ìš°ë¦¬ ì—°êµ¬ì‹¤ì€ AIë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤...",
    "lang": "ko",
    "tokens": 150,
    "embedding": [0.123, -0.456, ..., 0.789],
    "quality_score": 0.85,
    "source_url": "http://ailab.com",
    "md5": "abc123..."
  }
}
```

### 8. vector_db.py

**ì—­í• :** PostgreSQL ë²¡í„° DB

**ì£¼ìš” í´ë˜ìŠ¤:**

#### `VectorDatabase`
```python
class VectorDatabase:
    """PostgreSQL + pgvector"""
    
    def __init__(self, db_config: DatabaseConfig)
    
    def insert_document(
        lab_id: int,
        section: str,
        text: str,
        embedding: np.ndarray,
        **kwargs
    ) -> int:
        """ë¬¸ì„œ ì‚½ì…"""
        # 1. MD5 ì¤‘ë³µ ì²´í¬
        # 2. INSERT INTO lab_docs
    
    def search_vector(
        query_embedding: np.ndarray,
        limit=10,
        min_quality=0
    ) -> List[SearchResult]:
        """ë²¡í„° ê²€ìƒ‰ (HNSW ì¸ë±ìŠ¤)"""
        # SELECT ... ORDER BY embedding <=> %s LIMIT %s
    
    def search_hybrid(
        query_text: str,
        query_embedding: np.ndarray,
        vector_weight=0.7,
        keyword_weight=0.3
    ) -> List[SearchResult]:
        """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í‚¤ì›Œë“œ)"""
        # ë²¡í„° ì ìˆ˜ * 0.7 + í‚¤ì›Œë“œ ì ìˆ˜ * 0.3
```

## ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ (schema.sql)

#### `lab` - ì—°êµ¬ì‹¤
```sql
CREATE TABLE lab (
    lab_id SERIAL PRIMARY KEY,
    kor_name TEXT,
    eng_name TEXT,
    professor TEXT,
    homepage TEXT,
    location TEXT,
    contact_email TEXT,
    contact_phone TEXT,
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### `lab_docs` - ë¬¸ì„œ (ë²¡í„°)
```sql
CREATE TABLE lab_docs (
    doc_id SERIAL PRIMARY KEY,
    lab_id INTEGER REFERENCES lab(lab_id),
    section TEXT,  -- about, research, publication, ...
    title TEXT,
    text TEXT,
    lang TEXT,     -- ko, en, mixed
    tokens INTEGER,
    source_url TEXT,
    crawl_depth INTEGER,
    md5 TEXT UNIQUE,
    embedding vector(768),  -- pgvector
    emb_model TEXT,
    emb_ver INTEGER,
    created_at TIMESTAMP DEFAULT NOW()
);

-- HNSW ì¸ë±ìŠ¤
CREATE INDEX idx_docs_embedding ON lab_docs 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 32, ef_construction = 128);
```

#### `lab_tag` - íƒœê·¸
```sql
CREATE TABLE lab_tag (
    tag_id SERIAL PRIMARY KEY,
    lab_id INTEGER REFERENCES lab(lab_id),
    tag_type TEXT,  -- topic, method, equipment, venue, keyword
    value TEXT,
    confidence REAL,
    source TEXT     -- extraction, manual, llm
);
```

### ê³ ê¸‰ ìŠ¤í‚¤ë§ˆ (schema_enhanced.sql)

ì¶”ê°€ í…Œì´ë¸”:

#### `crawl_log` - í¬ë¡¤ë§ ê°ì‚¬ ë¡œê·¸
```sql
CREATE TABLE crawl_log (
    log_id SERIAL PRIMARY KEY,
    url TEXT,
    status_code INTEGER,
    success BOOLEAN,
    response_time_ms INTEGER,
    error_message TEXT,
    error_type TEXT,
    chunks_created INTEGER,
    chunks_excluded INTEGER,
    used_cache BOOLEAN,
    etag TEXT,
    last_modified TEXT,
    request_time TIMESTAMP DEFAULT NOW()
);
```

#### `update_history` - ë³€ê²½ ì´ë ¥
```sql
CREATE TABLE update_history (
    history_id SERIAL PRIMARY KEY,
    lab_id INTEGER,
    change_type TEXT,  -- added, modified, deleted
    field_name TEXT,
    old_value TEXT,
    new_value TEXT,
    detected_at TIMESTAMP DEFAULT NOW(),
    crawl_log_id INTEGER REFERENCES crawl_log(log_id)
);
```

#### `documents` (enhanced)
```sql
-- ì¶”ê°€ í•„ë“œ
quality_score REAL,         -- í’ˆì§ˆ ì ìˆ˜ (0-1)
needs_review BOOLEAN,       -- ê²€ìˆ˜ í•„ìš” ì—¬ë¶€
review_reason TEXT,         -- ê²€ìˆ˜ ì´ìœ 
is_active BOOLEAN,          -- ì†Œí”„íŠ¸ ì‚­ì œ
matched_snippet TEXT,       -- ì¶”ì²œ ì´ìœ  (Provenance)
last_crawled_at TIMESTAMP   -- ë§ˆì§€ë§‰ í¬ë¡¤ë§ ì‹œê°„
```

#### `labs` (enhanced)
```sql
-- Signals (ì¬ë­í‚¹)
recent_papers_count INTEGER,  -- ìµœê·¼ 3ë…„ ë…¼ë¬¸ ìˆ˜
has_awards BOOLEAN,           -- ìˆ˜ìƒ ì´ë ¥
equipment_gpu INTEGER,        -- GPU ìˆ˜
equipment_robot BOOLEAN,      -- ë¡œë´‡ ì¥ë¹„

-- Constraints (ëª¨ì§‘ ì¡°ê±´)
min_hours INTEGER,            -- ìµœì†Œ ì‹œê°„/ì£¼
weekend_ok BOOLEAN,           -- ì£¼ë§ ê°€ëŠ¥
join_type TEXT                -- í•™ë¶€/ëŒ€í•™ì›/ì¸í„´
```

## ğŸ” ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜

### ë²¡í„° ê²€ìƒ‰ (Cosine Similarity)

```python
def cosine_similarity(vec1: np.ndarray, vec2: np.ndarray) -> float:
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    dot_product = np.dot(vec1, vec2)
    norm1 = np.linalg.norm(vec1)
    norm2 = np.linalg.norm(vec2)
    return dot_product / (norm1 * norm2)

# ë˜ëŠ” pgvectorì—ì„œ
# SELECT 1 - (embedding <=> query_vector) as similarity
```

### HNSW ì¸ë±ìŠ¤ (Hierarchical Navigable Small World)

```sql
-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_docs_embedding ON lab_docs 
USING hnsw (embedding vector_cosine_ops)
WITH (
    m = 32,              -- ì—°ê²° ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•, ëŠë¦¼)
    ef_construction = 128 -- ë¹Œë“œ í’ˆì§ˆ (ë†’ì„ìˆ˜ë¡ ì •í™•, ëŠë¦¼)
);

-- ê²€ìƒ‰ ì‹œ ì •í™•ë„ ì¡°ì •
SET hnsw.ef_search = 64;  -- ê²€ìƒ‰ í’ˆì§ˆ (ë†’ì„ìˆ˜ë¡ ì •í™•, ëŠë¦¼)
```

**HNSW íŒŒë¼ë¯¸í„° ê°€ì´ë“œ:**

| íŒŒë¼ë¯¸í„° | ê°’ | ì„¤ëª… |
|---------|-----|------|
| m | 16 | ë¹ ë¦„, ëœ ì •í™• |
| m | 32 | ê· í˜• (ê¶Œì¥) |
| m | 64 | ëŠë¦¼, ë§¤ìš° ì •í™• |
| ef_construction | 64 | ë¹ ë¥¸ ë¹Œë“œ |
| ef_construction | 128 | ê· í˜• (ê¶Œì¥) |
| ef_construction | 256 | ëŠë¦° ë¹Œë“œ, ê³ í’ˆì§ˆ |
| ef_search | 32 | ë¹ ë¥¸ ê²€ìƒ‰ |
| ef_search | 64 | ê· í˜• (ê¶Œì¥) |
| ef_search | 128 | ëŠë¦° ê²€ìƒ‰, ê³ ì •í™•ë„ |

### í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰

ë²¡í„° ê²€ìƒ‰ + í‚¤ì›Œë“œ ê²€ìƒ‰:

```sql
-- PostgreSQL í•¨ìˆ˜
CREATE OR REPLACE FUNCTION hybrid_search(
    query_text TEXT,
    query_embedding vector(768),
    vec_weight REAL DEFAULT 0.7,
    kw_weight REAL DEFAULT 0.3,
    result_limit INTEGER DEFAULT 10
)
RETURNS TABLE(
    doc_id INTEGER,
    lab_name TEXT,
    text TEXT,
    vector_score REAL,
    keyword_score REAL,
    hybrid_score REAL
)
AS $$
BEGIN
    RETURN QUERY
    SELECT 
        d.doc_id,
        l.name,
        d.text,
        (1 - (d.embedding <=> query_embedding)) as vector_score,
        ts_rank(d.text_tsv, plainto_tsquery('korean', query_text)) as keyword_score,
        (
            (1 - (d.embedding <=> query_embedding)) * vec_weight +
            ts_rank(d.text_tsv, plainto_tsquery('korean', query_text)) * kw_weight
        ) as hybrid_score
    FROM lab_docs d
    JOIN lab l ON d.lab_id = l.lab_id
    WHERE d.is_active = TRUE
    ORDER BY hybrid_score DESC
    LIMIT result_limit;
END;
$$ LANGUAGE plpgsql;
```

## ğŸš€ ì„±ëŠ¥ ìµœì í™”

### 1. ì„ë² ë”© ìºì‹±

```python
class EmbeddingCache:
    """ì„ë² ë”© ìºì‹œ"""
    
    def __init__(self):
        self.cache = {}  # {text_hash: embedding}
    
    def get(self, text: str) -> Optional[np.ndarray]:
        text_hash = hashlib.md5(text.encode()).hexdigest()
        return self.cache.get(text_hash)
    
    def set(self, text: str, embedding: np.ndarray):
        text_hash = hashlib.md5(text.encode()).hexdigest()
        self.cache[text_hash] = embedding
```

### 2. ë°°ì¹˜ ì²˜ë¦¬

```python
# ë‹¨ì¼ ì²˜ë¦¬ (ëŠë¦¼)
for text in texts:
    embedding = model.encode(text)

# ë°°ì¹˜ ì²˜ë¦¬ (ë¹ ë¦„)
embeddings = model.encode(texts, batch_size=32)
```

### 3. GPU ì‚¬ìš©

```python
# CPU (ëŠë¦¼)
pipeline = EmbeddingPipeline(device='cpu')

# GPU (10ë°° ë¹ ë¦„)
pipeline = EmbeddingPipeline(device='cuda')
```

### 4. ì¸ë±ìŠ¤ ìµœì í™”

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ (í•„ìˆ˜)
CREATE INDEX idx_docs_embedding ON lab_docs 
USING hnsw (embedding vector_cosine_ops);

-- í•„í„°ë§ìš© ì¸ë±ìŠ¤
CREATE INDEX idx_docs_lab_section ON lab_docs(lab_id, section);
CREATE INDEX idx_docs_quality ON lab_docs(quality_score);
CREATE INDEX idx_docs_lang ON lab_docs(lang);

-- í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìš©)
CREATE INDEX idx_docs_text_tsv ON lab_docs USING gin(text_tsv);
```

## ğŸ”’ ë³´ì•ˆ ë° ë²•ì  ì¤€ìˆ˜

### 1. robots.txt ì¤€ìˆ˜

```python
from urllib.robotparser import RobotFileParser

def check_robots_txt(url: str, user_agent: str) -> bool:
    """robots.txt í™•ì¸"""
    rp = RobotFileParser()
    rp.set_url(f"{url}/robots.txt")
    rp.read()
    return rp.can_fetch(user_agent, url)
```

### 2. User-Agent ëª…ì‹œ

```python
USER_AGENT = "INHA-LabSearch-Bot/1.0 (Educational; Contact: your-email@inha.ac.kr)"

headers = {
    'User-Agent': USER_AGENT
}
```

### 3. ì†ë„ ì œí•œ

```python
import time

class RateLimiter:
    """ìš”ì²­ ì†ë„ ì œí•œ"""
    
    def __init__(self, delay=1.0):
        self.delay = delay
        self.last_request = 0
    
    def wait(self):
        elapsed = time.time() - self.last_request
        if elapsed < self.delay:
            time.sleep(self.delay - elapsed)
        self.last_request = time.time()
```

### 4. PII ë³´í˜¸

```python
# ê°œì¸ì •ë³´ ì°¨ë‹¨
PII_PATTERNS = [
    r'ë¹„ë°€ë²ˆí˜¸',
    r'password',
    r'ê°œì¸ì •ë³´',
    r'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸',
    r'ì¹´ë“œë²ˆí˜¸'
]

# ì°¨ë‹¨ URL íŒ¨í„´
BLOCKED_URLS = [
    r'/login',
    r'/admin',
    r'/portal',
    r'/private'
]
```

## ğŸ“Š ëª¨ë‹ˆí„°ë§ & ë¡œê¹…

### í¬ë¡¤ë§ í†µê³„

```python
@dataclass
class CrawlStats:
    total_requests: int
    successful_requests: int
    failed_requests: int
    cache_hits: int
    retry_count: int
    
    @property
    def success_rate(self) -> float:
        return self.successful_requests / self.total_requests
```

### ê²€ìƒ‰ ë¡œê·¸

```sql
CREATE TABLE search_log (
    log_id SERIAL PRIMARY KEY,
    query TEXT,
    search_type TEXT,  -- vector, hybrid
    result_count INTEGER,
    avg_score REAL,
    searched_at TIMESTAMP DEFAULT NOW()
);
```

## ğŸ¯ í™•ì¥ í¬ì¸íŠ¸

### 1. ìƒˆë¡œìš´ ì„ë² ë”© ëª¨ë¸ ì¶”ê°€

```python
# embedding.pyì— ì¶”ê°€
SUPPORTED_MODELS['custom-model'] = {
    'name': 'your-org/your-model',
    'dimension': 512,
    'description': 'ì»¤ìŠ¤í…€ ëª¨ë¸'
}
```

### 2. ìƒˆë¡œìš´ ì„¹ì…˜ ì¶”ê°€

```python
# chunking.pyì— ì¶”ê°€
SECTION_KEYWORDS = {
    'custom_section': ['í‚¤ì›Œë“œ1', 'í‚¤ì›Œë“œ2', ...]
}
```

### 3. ì»¤ìŠ¤í…€ ê²€ìƒ‰ í•¨ìˆ˜

```python
def custom_search(query: str, filters: Dict) -> List[SearchResult]:
    """ì»¤ìŠ¤í…€ ê²€ìƒ‰ ë¡œì§"""
    # 1. ì¿¼ë¦¬ ì „ì²˜ë¦¬
    # 2. ì„ë² ë”©
    # 3. ê²€ìƒ‰
    # 4. í›„ì²˜ë¦¬ (ì¬ë­í‚¹, í•„í„°ë§)
    # 5. ë°˜í™˜
```

### 4. REST API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€

```python
# search_api.pyì— ì¶”ê°€
@app.get("/custom-endpoint")
def custom_endpoint(param: str):
    # ì»¤ìŠ¤í…€ ë¡œì§
    return {"result": ...}
```

## ğŸ”„ ì‹œìŠ¤í…œ ì—…ê·¸ë ˆì´ë“œ ê²½ë¡œ

### ì†Œê·œëª¨ â†’ ì¤‘ê·œëª¨

```
ë¡œì»¬ JSON â†’ PostgreSQL
- VectorDatabaseë¡œ ì „í™˜
- HNSW ì¸ë±ìŠ¤ í™œìš©
- ë” ë¹ ë¥¸ ê²€ìƒ‰
```

### ì¤‘ê·œëª¨ â†’ ëŒ€ê·œëª¨

```
PostgreSQL â†’ ë¶„ì‚° ì‹œìŠ¤í…œ
- Elasticsearch (í‚¤ì›Œë“œ ê²€ìƒ‰)
- Milvus/Qdrant (ë²¡í„° ê²€ìƒ‰)
- Redis (ìºì‹±)
- ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
```

## âœ… ì•„í‚¤í…ì²˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì „ì²´ ë°ì´í„° íë¦„ ì´í•´
- [ ] í•µì‹¬ ëª¨ë“ˆ ì—­í•  íŒŒì•…
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì´í•´
- [ ] ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ ì´í•´
- [ ] ì„±ëŠ¥ ìµœì í™” ë°©ë²• íŒŒì•…
- [ ] í™•ì¥ í¬ì¸íŠ¸ í™•ì¸

ì‹œìŠ¤í…œ êµ¬ì¡°ë¥¼ ì´í•´í•˜ì…¨ìŠµë‹ˆë‹¤! ğŸ‰
