# ì—°êµ¬ì‹¤ ì¶”ì²œ ì‹œìŠ¤í…œ ìƒì„¸ ë¬¸ì„œ

## ğŸ“Œ ê°œìš”

í•™ìƒì˜ í”„ë¡œí•„ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì ì˜ ì—°êµ¬ì‹¤ì„ ì¶”ì²œí•˜ëŠ” **2ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì‹œìŠ¤í…œ**ì…ë‹ˆë‹¤.

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°

```
                     í•™ìƒ í”„ë¡œí•„ ì…ë ¥
                          â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1ë‹¨ê³„: í›„ë³´êµ° ìƒì„± (Candidate Gen)      â”‚
    â”‚  - BM25 í‚¤ì›Œë“œ ê²€ìƒ‰                      â”‚
    â”‚  - E5-small ì˜ë¯¸ ê²€ìƒ‰                    â”‚
    â”‚  - í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚°                  â”‚
    â”‚  â†’ 86ê°œ â†’ 10~20ê°œ í›„ë³´                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2ë‹¨ê³„: ì •ë°€ ì¬ë­í‚¹ (Re-ranking)         â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ ë¬¸ì¥í˜• (60%)                      â”‚ â”‚
    â”‚  â”‚ - E5-large ì„ë² ë”©                 â”‚ â”‚
    â”‚  â”‚ - Cosine Similarity              â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ í‚¤ì›Œë“œí˜• (30%)                    â”‚ â”‚
    â”‚  â”‚ - Jaccard, TF-IDF                â”‚ â”‚
    â”‚  â”‚ - Rule-based                     â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
    â”‚  â”‚ ì •ëŸ‰í˜• (10%)                      â”‚ â”‚
    â”‚  â”‚ - Min-Max ì •ê·œí™”                  â”‚ â”‚
    â”‚  â”‚ - Ordinal Similarity             â”‚ â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
    â”‚  â†’ 10~20ê°œ â†’ Top 5~10               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
                 ìµœì¢… ì¶”ì²œ ê²°ê³¼
```

## 1ï¸âƒ£ 1ë‹¨ê³„: í›„ë³´êµ° ìƒì„±

### ëª©í‘œ
- **Precision (ì •í™•ì„±)**: í‚¤ì›Œë“œê°€ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ì—°êµ¬ì‹¤
- **Recall (ì¬í˜„ìœ¨)**: ì˜ë¯¸ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì—°êµ¬ì‹¤ë„ íƒì§€

### ì•Œê³ ë¦¬ì¦˜

#### BM25 í‚¤ì›Œë“œ ê²€ìƒ‰
```python
from rank_bm25 import BM25Okapi

# ëª¨ë“  ì—°êµ¬ì‹¤ í…ìŠ¤íŠ¸ í† í°í™”
tokenized_docs = [doc.split() for doc in lab_texts]

# BM25 ì¸ë±ìŠ¤ ìƒì„±
bm25 = BM25Okapi(tokenized_docs)

# ê²€ìƒ‰ì–´ ì ìˆ˜ ê³„ì‚°
query_tokens = "ì»´í“¨í„° ë¹„ì „ ë”¥ëŸ¬ë‹".split()
scores = bm25.get_scores(query_tokens)
```

**íŠ¹ì§•:**
- TF (Term Frequency): ë‹¨ì–´ê°€ ë¬¸ì„œì— ìì£¼ ë“±ì¥í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
- IDF (Inverse Document Frequency): í¬ê·€í•œ ë‹¨ì–´ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
- ë¬¸ì„œ ê¸¸ì´ ì •ê·œí™”

#### E5-small ì˜ë¯¸ ê²€ìƒ‰
```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('intfloat/e5-small-v2')

# ì—°êµ¬ì‹¤ ë²¡í„° ì‚¬ì „ ê³„ì‚°
lab_embeddings = model.encode(lab_texts, normalize_embeddings=True)

# ê²€ìƒ‰ì–´ ë²¡í„°
query = "query: ì»´í“¨í„° ë¹„ì „ ë”¥ëŸ¬ë‹"  # E5ëŠ” prefix í•„ìš”
query_emb = model.encode(query, normalize_embeddings=True)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„
scores = np.dot(lab_embeddings, query_emb)
```

**íŠ¹ì§•:**
- ì˜ë¯¸ì  ìœ ì‚¬ë„: "AI"ì™€ "ì¸ê³µì§€ëŠ¥" ë™ì¼í•˜ê²Œ ì¸ì‹
- 384ì°¨ì› ë²¡í„° (ë¹ ë¥´ê³  íš¨ìœ¨ì )
- ë‹¤êµ­ì–´ ì§€ì›

#### í•˜ì´ë¸Œë¦¬ë“œ ê²°í•©
```python
# ê° ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ 10ê°œ
keyword_top10 = bm25_results[:10]
semantic_top10 = vector_results[:10]

# í•©ì§‘í•© (ì¤‘ë³µ ì œê±°)
candidates = set(keyword_top10) | set(semantic_top10)  # 10~15ê°œ
```

### íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„° | ê¸°ë³¸ê°’ | ì„¤ëª… |
|---------|--------|------|
| `keyword_weight` | 0.5 | í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ |
| `semantic_weight` | 0.5 | ì˜ë¯¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜ |
| `final_top_k` | 15 | ìµœì¢… í›„ë³´ ìˆ˜ |

## 2ï¸âƒ£ 2ë‹¨ê³„: ì •ë°€ ì¬ë­í‚¹

### ì ìˆ˜ êµ¬ì„± (ê¸°ë³¸ ì„¤ì •)

```
ìµœì¢… ì ìˆ˜ = ë¬¸ì¥í˜•(60%) + í‚¤ì›Œë“œí˜•(30%) + ì •ëŸ‰í˜•(10%)
```

### ë¬¸ì¥í˜• ìœ ì‚¬ë„ (60%)

**ììœ  ì„œìˆ í˜• í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ì  ìœ ì‚¬ë„**

#### ì„¸ë¶€ ê°€ì¤‘ì¹˜
```python
ë¬¸ì¥í˜• = (
    ìê¸°ì†Œê°œ1 * 0.30 +  # ê´€ì‹¬ ì—°êµ¬ ë¶„ì•¼
    ìê¸°ì†Œê°œ2 * 0.25 +  # ê¸°ìˆ  ê²½í—˜
    ìê¸°ì†Œê°œ3 * 0.20 +  # ì—°êµ¬ ëª©í‘œ
    í¬íŠ¸í´ë¦¬ì˜¤ * 0.25    # ì „ì²´ ê²½ë ¥
)
```

#### ì•Œê³ ë¦¬ì¦˜

**1. ê¸°ë³¸ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ìê¸°ì†Œê°œ1, 3)**
```python
# E5-large ì„ë² ë”© (1024ì°¨ì›)
model = SentenceTransformer('intfloat/multilingual-e5-large')

# í•™ìƒ í…ìŠ¤íŠ¸
student_emb = model.encode("query: " + intro1, normalize_embeddings=True)

# ì—°êµ¬ì‹¤ í…ìŠ¤íŠ¸
lab_emb = model.encode("passage: " + lab_research, normalize_embeddings=True)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„
similarity = np.dot(student_emb, lab_emb)  # 0~1
```

**2. í‚¤ì›Œë“œ ì˜¤ë²„ë© ê²°í•© (ìê¸°ì†Œê°œ2)**
```python
# ë¬¸ì¥ ìœ ì‚¬ë„
sentence_sim = cosine_similarity(intro2, lab_methods)

# í‚¤ì›Œë“œ ì˜¤ë²„ë©
keywords_student = set(intro2.lower().split())
keywords_lab = set(lab_methods.lower().split())
keyword_overlap = len(keywords_student & keywords_lab) / len(keywords_student | keywords_lab)

# ê°€ì¤‘ í‰ê· 
final = sentence_sim * 0.7 + keyword_overlap * 0.3
```

**3. Mean-pooling (í¬íŠ¸í´ë¦¬ì˜¤)**
```python
# ê¸´ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
chunks = split_text(portfolio, chunk_size=512)

# ê° ì²­í¬ ì„ë² ë”©
chunk_embeddings = model.encode(chunks, normalize_embeddings=True)

# í‰ê·  ì„ë² ë”©
mean_embedding = np.mean(chunk_embeddings, axis=0)
mean_embedding = mean_embedding / np.linalg.norm(mean_embedding)

# ìœ ì‚¬ë„ ê³„ì‚°
similarity = np.dot(mean_embedding, lab_emb)
```

### í‚¤ì›Œë“œí˜• ìœ ì‚¬ë„ (30%)

**ë¼ë²¨/ì¹´í…Œê³ ë¦¬ì˜ ì •í™•í•œ ë§¤ì¹­**

#### ì„¸ë¶€ ê°€ì¤‘ì¹˜
```python
í‚¤ì›Œë“œí˜• = (
    ì „ê³µ * 0.35 +
    ìê²©ì¦ * 0.25 +
    ìˆ˜ìƒê²½ë ¥ * 0.20 +
    ê¸°ìˆ ìŠ¤íƒ * 0.20
)
```

#### ì•Œê³ ë¦¬ì¦˜

**1. ì „ê³µ Rule-based**
```python
def major_similarity(student_major, lab_department):
    # ì™„ì „ ì¼ì¹˜
    if student_major == lab_department:
        return 1.0
    
    # ê°™ì€ ê³„ì—´
    if same_group(student_major, lab_department):
        return 0.8
    
    # ë¶€ë¶„ ë§¤ì¹­
    if student_major in lab_department or lab_department in student_major:
        return 0.6
    
    # ê´€ë ¨ ê³µí•™
    if both_engineering(student_major, lab_department):
        return 0.5
    
    return 0.0
```

**2. ìê²©ì¦ Weighted Jaccard**
```python
# ìê²©ì¦ ê°€ì¤‘ì¹˜
weights = {"ê¸°ì‚¬": 1.0, "ì‚°ì—…ê¸°ì‚¬": 0.7, "ê¸°ëŠ¥ì‚¬": 0.5, "ë¯¼ê°„": 0.3}

# ê°€ì¤‘ ë§¤ì¹­ ì ìˆ˜
for cert_student in student_certs:
    best_match = 0
    for cert_lab in lab_certs:
        # ë¬¸ìì—´ ìœ ì‚¬ë„
        if cert_student == cert_lab:
            match = 1.0
        elif cert_student in cert_lab:
            match = 0.7
        else:
            match = jaccard(cert_student.split(), cert_lab.split())
        
        # ê°€ì¤‘ì¹˜ ì ìš©
        weight = get_weight(cert_student)
        best_match = max(best_match, match * weight)
    
    scores.append(best_match)

final = np.mean(scores)
```

**3. ìˆ˜ìƒê²½ë ¥ TF-IDF / Jaccard**
```python
# ê¸´ í…ìŠ¤íŠ¸: TF-IDF
if len(text) > 20:
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([student_award, lab_award])
    similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]
    
# ì§§ì€ í…ìŠ¤íŠ¸: Jaccard
else:
    words1 = set(student_award.split())
    words2 = set(lab_award.split())
    similarity = len(words1 & words2) / len(words1 | words2)
```

**4. ê¸°ìˆ  ìŠ¤íƒ Jaccard + E5**
```python
# Jaccard
techs_student = set(["python", "pytorch", "tensorflow"])
techs_lab = set(["python", "pytorch", "keras"])
jaccard = len(techs_student & techs_lab) / len(techs_student | techs_lab)

# E5-small ì„ë² ë”©
student_emb = model.encode(list(techs_student), normalize_embeddings=True)
lab_emb = model.encode(list(techs_lab), normalize_embeddings=True)
embedding_sim = np.dot(np.mean(student_emb, axis=0), np.mean(lab_emb, axis=0))

# í•˜ì´ë¸Œë¦¬ë“œ
final = jaccard * 0.6 + embedding_sim * 0.4
```

### ì •ëŸ‰í˜• ìœ ì‚¬ë„ (10%)

**ìˆ˜ì¹˜/ë²”ì£¼ ë°ì´í„°ì˜ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„**

#### ì„¸ë¶€ ê°€ì¤‘ì¹˜
```python
ì •ëŸ‰í˜• = (
    ì–´í•™ì ìˆ˜ * 0.30 +
    êµ¬ì‚¬ëŠ¥ë ¥ * 0.30 +
    í•™ì  * 0.40
)
```

#### ì•Œê³ ë¦¬ì¦˜

**1. ì–´í•™ ì ìˆ˜ (TOEIC) Min-Max + Threshold**
```python
def toeic_similarity(student_score, required_score):
    # ê¸°ì¤€ ì´ìƒ: ë§Œì 
    if student_score >= required_score:
        return 1.0
    
    # ê¸°ì¤€ ë¯¸ë‹¬: ì„ í˜• ê°ì†Œ
    ratio = student_score / required_score
    
    # 70% ë¯¸ë§Œ: 0ì 
    if ratio < 0.7:
        return 0.0
    
    # 70~100%: ì„ í˜• ë§¤í•‘
    return (ratio - 0.7) / 0.3  # 0.7â†’0, 1.0â†’1.0
```

**2. êµ¬ì‚¬ëŠ¥ë ¥ Ordinal Similarity**
```python
# ë ˆë²¨ ì •ì˜
levels = {"ìƒ": 1.0, "ì¤‘ìƒ": 0.85, "ì¤‘": 0.7, "ì¤‘í•˜": 0.55, "í•˜": 0.4}

student_level = levels[student_proficiency]
required_level = levels[required_proficiency]

# ë ˆë²¨ ì´ìƒ: ë§Œì 
if student_level >= required_level:
    return 1.0

# ë ˆë²¨ ì°¨ì´ì— ë”°ë¥¸ ì ìˆ˜
gap = required_level - student_level
if gap <= 0.15:  # ê±°ì˜ ë¹„ìŠ·
    return 0.9
elif gap <= 0.30:  # 1ë‹¨ê³„ ì°¨ì´
    return 0.7
elif gap <= 0.45:  # 2ë‹¨ê³„ ì°¨ì´
    return 0.4
else:  # 3ë‹¨ê³„ ì´ìƒ
    return 0.0
```

**3. í•™ì  Distance-based**
```python
def gpa_similarity(student_gpa, expected_gpa=3.5):
    # ê¸°ëŒ€ ì´ìƒ: ë§Œì 
    if student_gpa >= expected_gpa:
        return 1.0
    
    # ê¸°ëŒ€ ë¯¸ë‹¬: ê±°ë¦¬ ê¸°ë°˜
    gap = expected_gpa - student_gpa
    max_gap = 0.5  # ìµœëŒ€ í—ˆìš© ê²©ì°¨
    
    if gap > max_gap:
        return 0.0
    
    # ì„ í˜• ê°ì†Œ
    return 1.0 - (gap / max_gap)
```

## âš™ï¸ ì„¤ì • ê´€ë¦¬

### ê¸°ë³¸ ì„¤ì • (DEFAULT_CONFIG)
```python
@dataclass
class ScorerConfig:
    sentence_weight: float = 0.6   # 60%
    keyword_weight: float = 0.3    # 30%
    numeric_weight: float = 0.1    # 10%
    
    sentence: SentenceSimilarityConfig = ...
    keyword: KeywordSimilarityConfig = ...
    numeric: NumericSimilarityConfig = ...
```

### í”„ë¡œíŒŒì¼ë³„ ê°€ì¤‘ì¹˜

#### 1. ê¸°ë³¸ ì„¤ì • (Default)
```
ë¬¸ì¥í˜•: 60% (ê· í˜•)
  â”œâ”€ intro1: 30%
  â”œâ”€ intro2: 25%
  â”œâ”€ intro3: 20%
  â””â”€ portfolio: 25%
í‚¤ì›Œë“œí˜•: 30%
  â”œâ”€ major: 35%
  â”œâ”€ certification: 25%
  â”œâ”€ award: 20%
  â””â”€ tech_stack: 20%
ì •ëŸ‰í˜•: 10%
  â”œâ”€ language: 30%
  â”œâ”€ proficiency: 30%
  â””â”€ gpa: 40%
```

#### 2. ì—°êµ¬ ì¤‘ì‹¬ (Research-focused)
```
ë¬¸ì¥í˜•: 50% (ì—°êµ¬ ê´€ì‹¬ â†‘)
  â”œâ”€ intro1: 40% â† ì¦ê°€
  â”œâ”€ intro2: 20%
  â”œâ”€ intro3: 20%
  â””â”€ portfolio: 20%
í‚¤ì›Œë“œí˜•: 30%
ì •ëŸ‰í˜•: 20% (í•™ì  ì¤‘ì‹œ)
```

#### 3. ê¸°ìˆ  ì¤‘ì‹¬ (Skill-focused)
```
ë¬¸ì¥í˜•: 30%
í‚¤ì›Œë“œí˜•: 45% (ê¸°ìˆ  ìŠ¤íƒ â†‘)
  â”œâ”€ major: 25%
  â”œâ”€ certification: 25%
  â”œâ”€ award: 15%
  â””â”€ tech_stack: 35% â† ì¦ê°€
ì •ëŸ‰í˜•: 25%
```

#### 4. í•™ì—… ì¤‘ì‹¬ (Academic-focused)
```
ë¬¸ì¥í˜•: 30%
í‚¤ì›Œë“œí˜•: 30%
ì •ëŸ‰í˜•: 40% (í•™ì  â†‘)
  â”œâ”€ language: 25%
  â”œâ”€ proficiency: 25%
  â””â”€ gpa: 50% â† ì¦ê°€
```

## ğŸ“Š ì„±ëŠ¥ ì§€í‘œ

### ì •í™•ë„ ì¸¡ì •

```python
# í•™ìƒ í”„ë¡œí•„
student = {...}

# í›„ë³´ ìƒì„± (1ë‹¨ê³„)
candidates = generator.get_candidates_with_scores(student)

# ì¬ë­í‚¹ (2ë‹¨ê³„)
results = scorer.rerank_candidates(student, candidates)

# ìƒìœ„ 5ê°œ ê²°ê³¼
for i, result in enumerate(results[:5], 1):
    print(f"{i}ìœ„. {result.lab_name} - {result.final_score:.4f}")
```

### ì˜ˆìƒ ì ìˆ˜ ë²”ìœ„

| ì ìˆ˜ | ì˜ë¯¸ | ì„¤ëª… |
|-----|------|------|
| 0.9~1.0 | ë§¤ìš° ì í•© | ê±°ì˜ ëª¨ë“  í•­ëª© ë§¤ì¹­ |
| 0.7~0.9 | ì í•© | ëŒ€ë¶€ë¶„ í•­ëª© ë§¤ì¹­ |
| 0.5~0.7 | ë³´í†µ | ì¼ë¶€ í•­ëª© ë§¤ì¹­ |
| 0.3~0.5 | ë¶€ì í•© | ìµœì†Œ ìš”ê±´ ë¯¸ë‹¬ |
| 0.0~0.3 | ë§¤ìš° ë¶€ì í•© | ê±°ì˜ ë§¤ì¹­ ì•ˆ ë¨ (í•„í„°ë§) |

## ğŸ”§ ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ê°€ì¤‘ì¹˜ ì¡°ì •
```python
from similarity.config import ScorerConfig

# ì»¤ìŠ¤í…€ ì„¤ì •
custom_config = ScorerConfig()
custom_config.sentence_weight = 0.7  # ë¬¸ì¥í˜• ê°•í™”
custom_config.keyword_weight = 0.2
custom_config.numeric_weight = 0.1

# ì„¸ë¶€ ê°€ì¤‘ì¹˜
custom_config.sentence.intro1_weight = 0.5  # ê´€ì‹¬ ì—°êµ¬ ì¤‘ì‹œ
custom_config.sentence.intro2_weight = 0.2
custom_config.sentence.intro3_weight = 0.15
custom_config.sentence.portfolio_weight = 0.15

# ê²€ì¦ ë° ì ìš©
custom_config.validate()
scorer = RerankingScorer(custom_config)
```

### í•„í„°ë§ ì¡°ê±´ ì¶”ê°€
```python
# ìµœì†Œ ì ìˆ˜ ì„ê³„ê°’
config.min_score_threshold = 0.4  # 0.4 ë¯¸ë§Œì€ ì œì™¸

# ì„¹ì…˜ë³„ ê°€ì¤‘ì¹˜
config.section_weights = {
    "research": 0.4,    # ì—°êµ¬ ë¶„ì•¼ ì¤‘ì‹œ
    "about": 0.2,
    "methods": 0.2,
    "projects": 0.15,
    "publications": 0.05
}
```

## ğŸš€ ìµœì í™” íŒ

### 1. ì„ë² ë”© ìºì‹±
```python
# ì—°êµ¬ì‹¤ ì„ë² ë”©ì€ í•œ ë²ˆë§Œ ê³„ì‚°
lab_embeddings = model.encode(lab_texts)  # ì‚¬ì „ ê³„ì‚°
# â†’ ê²€ìƒ‰í•  ë•Œë§ˆë‹¤ ì¬ì‚¬ìš©
```

### 2. ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ í•™ìƒ ë™ì‹œ ì²˜ë¦¬
student_embeddings = model.encode(student_texts, batch_size=32)
```

### 3. GPU í™œìš©
```python
model = SentenceTransformer('intfloat/multilingual-e5-large', device='cuda')
# CPU: ~2ì´ˆ/í…ìŠ¤íŠ¸
# GPU: ~0.2ì´ˆ/í…ìŠ¤íŠ¸ (10ë°° ë¹ ë¦„)
```

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- **BM25**: Robertson & Zaragoza (2009) - "The Probabilistic Relevance Framework: BM25 and Beyond"
- **E5**: Wang et al. (2022) - "Text Embeddings by Weakly-Supervised Contrastive Pre-training"
- **SBERT**: Reimers & Gurevych (2019) - "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"

### ëª¨ë¸
- **E5-large**: intfloat/multilingual-e5-large (1024ì°¨ì›)
- **E5-small**: intfloat/e5-small-v2 (384ì°¨ì›)
- **BM25**: rank-bm25 ë¼ì´ë¸ŒëŸ¬ë¦¬

### ì•Œê³ ë¦¬ì¦˜
- **Cosine Similarity**: ë²¡í„° ê°„ ê°ë„ ê¸°ë°˜ ìœ ì‚¬ë„
- **Jaccard**: ì§‘í•© ìœ ì‚¬ë„ (êµì§‘í•©/í•©ì§‘í•©)
- **TF-IDF**: ë‹¨ì–´ ì¤‘ìš”ë„ ê¸°ë°˜ ë¬¸ì„œ í‘œí˜„
- **Min-Max**: ì„ í˜• ì •ê·œí™”
- **Ordinal**: ìˆœì„œí˜• ë°ì´í„° ìœ ì‚¬ë„

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] 1ë‹¨ê³„ í›„ë³´êµ° ìƒì„± ì´í•´
- [ ] 2ë‹¨ê³„ ì¬ë­í‚¹ 3ê°€ì§€ ìœ ì‚¬ë„ ì´í•´
- [ ] ì„¤ì • í”„ë¡œíŒŒì¼ 4ê°€ì§€ íŒŒì•…
- [ ] ê°€ì¤‘ì¹˜ ì»¤ìŠ¤í„°ë§ˆì´ì§• ë°©ë²• í™•ì¸
- [ ] ì‹¤ì œ ì‚¬ìš© ì˜ˆì œ í…ŒìŠ¤íŠ¸
