"""
í›„ë³´êµ° ìƒì„± (Candidate Generation) - 1ë‹¨ê³„
í•™ìƒì˜ í¬ë§ ì—°êµ¬ ë¶„ì•¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë©ì‹¤ 10~20ê°œ ì¶”ì¶œ
"""

from typing import List, Dict, Set
from dataclasses import dataclass
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import json
import os
from collections import defaultdict


@dataclass
class Lab:
    """ì—°êµ¬ì‹¤ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    name: str
    professor: str
    description: str  # labs.jsonì˜ description í•„ë“œ
    homepage: str = ""
    location: str = ""
    
    # documents.jsonì—ì„œ ì„¹ì…˜ë³„ë¡œ í†µí•©ëœ í…ìŠ¤íŠ¸
    research_text: str = ""  # section='research' ë¬¸ì„œë“¤
    about_text: str = ""     # section='about' ë¬¸ì„œë“¤
    project_text: str = ""   # section='project' ë¬¸ì„œë“¤
    
    def get_search_text(self) -> str:
        """ê²€ìƒ‰ìš© í…ìŠ¤íŠ¸ í†µí•©"""
        return f"{self.description} {self.about_text} {self.research_text} {self.project_text}"


@dataclass
class Student:
    """í•™ìƒ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    research_interests: str  # í¬ë§ ì—°êµ¬ ë¶„ì•¼ (í•µì‹¬!)
    

class CandidateGenerator:
    """
    í‚¤ì›Œë“œ ê²€ìƒ‰(BM25) + ì˜ë¯¸ ê²€ìƒ‰(E5-small)ì„ ê²°í•©í•˜ì—¬ í›„ë³´ ë©ì‹¤ ì¶”ì¶œ
    """
    
    def __init__(
        self, 
        labs_json_path: str = "./data/crawl_data/labs.json",
        docs_json_path: str = "./data/crawl_data/documents.json",
        embedding_model_name: str = "intfloat/e5-small-v2"
    ):
        """
        Args:
            labs_json_path: labs.json íŒŒì¼ ê²½ë¡œ
            docs_json_path: documents.json íŒŒì¼ ê²½ë¡œ
            embedding_model_name: E5 ì„ë² ë”© ëª¨ë¸ëª…
        """
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        self.labs = self._load_labs_from_json(labs_json_path, docs_json_path)
        print(f"âœ… {len(self.labs)}ê°œ ì—°êµ¬ì‹¤ ë¡œë“œ ì™„ë£Œ")
        
        print("ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # BM25 ì¸ë±ìŠ¤ ì¤€ë¹„
        print("ğŸ” BM25 ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
        self._prepare_bm25_index()
        
        # E5 ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚°
        print("ğŸ§  ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚° ì¤‘...")
        self._prepare_embeddings()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def _load_labs_from_json(self, labs_path: str, docs_path: str) -> List[Lab]:
        """
        labs.jsonê³¼ documents.jsonì„ ì½ì–´ì„œ Lab ê°ì²´ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        """
        # labs.json ë¡œë“œ
        with open(labs_path, 'r', encoding='utf-8') as f:
            labs_data = json.load(f)
        
        # documents.json ë¡œë“œ
        with open(docs_path, 'r', encoding='utf-8') as f:
            docs_data = json.load(f)
        
        # lab_idë³„ë¡œ ë¬¸ì„œë“¤ ê·¸ë£¹í™”
        lab_docs = defaultdict(lambda: {"research": [], "about": [], "project": []})
        
        for doc in docs_data.values():
            lab_id = str(doc['lab_id'])
            section = doc.get('section', 'general')
            text = doc.get('text', '')
            
            if section in ['research', 'about', 'project']:
                lab_docs[lab_id][section].append(text)
        
        # Lab ê°ì²´ ìƒì„±
        labs = []
        for lab_id, lab_info in labs_data.items():
            lab = Lab(
                id=lab_id,
                name=lab_info.get('kor_name', ''),
                professor=lab_info.get('professor', ''),
                description=lab_info.get('description', ''),
                homepage=lab_info.get('homepage', ''),
                location=lab_info.get('location', ''),
                research_text=' '.join(lab_docs[lab_id]['research'][:3]),  # ìƒìœ„ 3ê°œë§Œ
                about_text=' '.join(lab_docs[lab_id]['about'][:2]),        # ìƒìœ„ 2ê°œë§Œ
                project_text=' '.join(lab_docs[lab_id]['project'][:2])     # ìƒìœ„ 2ê°œë§Œ
            )
            labs.append(lab)
        
        return labs
    
    def _prepare_bm25_index(self):
        """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤ ì¤€ë¹„"""
        corpus = [lab.get_search_text() for lab in self.labs]
        tokenized_corpus = [doc.lower().split() for doc in corpus]
        self.bm25 = BM25Okapi(tokenized_corpus)
    
    def _prepare_embeddings(self):
        """E5-small ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚° ë° ì €ì¥"""
        lab_texts = [lab.get_search_text() for lab in self.labs]
        # E5 ëª¨ë¸ì€ "query: " ë˜ëŠ” "passage: " í”„ë¦¬í”½ìŠ¤ í•„ìš”
        lab_texts_with_prefix = [f"passage: {text}" for text in lab_texts]
        self.lab_embeddings = self.embedding_model.encode(
            lab_texts_with_prefix, 
            normalize_embeddings=True,
            show_progress_bar=True
        )
    
    def _keyword_search(self, query: str, top_k: int = 10) -> List[str]:
        """
        í‚¤ì›Œë“œ ë§¤ì¹­ (BM25) - ì •í™•ì„±(Precision) ë‹´ë‹¹
        
        Args:
            query: í•™ìƒì˜ í¬ë§ ì—°êµ¬ ë¶„ì•¼
            top_k: ìƒìœ„ kê°œ ì¶”ì¶œ
            
        Returns:
            ë©ì‹¤ ID ë¦¬ìŠ¤íŠ¸
        """
        tokenized_query = query.lower().split()
        scores = self.bm25.get_scores(tokenized_query)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        top_indices = np.argsort(scores)[-top_k:][::-1]
        
        return [self.labs[idx].id for idx in top_indices]
    
    def _semantic_search(self, query: str, top_k: int = 10) -> List[str]:
        """
        E5-small ì„ë² ë”© ë²¡í„° ê²€ìƒ‰ - ë°œê²¬(Recall) ë‹´ë‹¹
        
        Args:
            query: í•™ìƒì˜ í¬ë§ ì—°êµ¬ ë¶„ì•¼
            top_k: ìƒìœ„ kê°œ ì¶”ì¶œ
            
        Returns:
            ë©ì‹¤ ID ë¦¬ìŠ¤íŠ¸
        """
        # E5 ì¿¼ë¦¬ ì¸ì½”ë”©
        query_with_prefix = f"query: {query}"
        query_embedding = self.embedding_model.encode(
            query_with_prefix,
            normalize_embeddings=True
        )
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ì •ê·œí™”ëœ ë²¡í„°ì´ë¯€ë¡œ ë‚´ì ìœ¼ë¡œ ê³„ì‚° ê°€ëŠ¥)
        similarities = np.dot(self.lab_embeddings, query_embedding)
        
        # ìƒìœ„ kê°œ ì¸ë±ìŠ¤ ì¶”ì¶œ
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        return [self.labs[idx].id for idx in top_indices]
    
    def generate_candidates(
        self, 
        student: Student, 
        keyword_top_k: int = 10,
        semantic_top_k: int = 10
    ) -> List[str]:
        """
        í›„ë³´êµ° ìƒì„± ë©”ì¸ í•¨ìˆ˜
        í‚¤ì›Œë“œ ê²€ìƒ‰ + ì˜ë¯¸ ê²€ìƒ‰ ê²°ê³¼ë¥¼ í•©ì¹¨ (Union)
        
        Args:
            student: í•™ìƒ ì •ë³´
            keyword_top_k: í‚¤ì›Œë“œ ê²€ìƒ‰ ìƒìœ„ kê°œ
            semantic_top_k: ì˜ë¯¸ ê²€ìƒ‰ ìƒìœ„ kê°œ
            
        Returns:
            ìµœì¢… í›„ë³´ ë©ì‹¤ ID ë¦¬ìŠ¤íŠ¸ (10~20ê°œ, ì¤‘ë³µ ì œê±°ë¨)
        """
        query = student.research_interests
        
        # 1. í‚¤ì›Œë“œ ê²€ìƒ‰ Top K
        keyword_results = self._keyword_search(query, keyword_top_k)
        
        # 2. ì˜ë¯¸ ê²€ìƒ‰ Top K
        semantic_results = self._semantic_search(query, semantic_top_k)
        
        # 3. í•©ì§‘í•© (ì¤‘ë³µ ì œê±°)
        candidates = list(set(keyword_results + semantic_results))
        
        print(f"ğŸ” í‚¤ì›Œë“œ ê²€ìƒ‰: {len(keyword_results)}ê°œ")
        print(f"ğŸ” ì˜ë¯¸ ê²€ìƒ‰: {len(semantic_results)}ê°œ")
        print(f"âœ… ìµœì¢… í›„ë³´: {len(candidates)}ê°œ")
        
        return candidates
    
    def get_candidates_with_scores(
        self,
        student: Student,
        keyword_top_k: int = 10,
        semantic_top_k: int = 10
    ) -> Dict[str, Dict]:
        """
        í›„ë³´êµ°ê³¼ í•¨ê»˜ ê° ê²€ìƒ‰ ë°©ì‹ì˜ ì ìˆ˜ë„ ë°˜í™˜
        
        Returns:
            {lab_id: {"keyword_score": float, "semantic_score": float, "sources": List[str]}}
        """
        query = student.research_interests
        
        # í‚¤ì›Œë“œ ê²€ìƒ‰
        tokenized_query = query.lower().split()
        keyword_scores = self.bm25.get_scores(tokenized_query)
        keyword_top_indices = np.argsort(keyword_scores)[-keyword_top_k:][::-1]
        
        # ì˜ë¯¸ ê²€ìƒ‰
        query_with_prefix = f"query: {query}"
        query_embedding = self.embedding_model.encode(query_with_prefix, normalize_embeddings=True)
        semantic_scores = np.dot(self.lab_embeddings, query_embedding)
        semantic_top_indices = np.argsort(semantic_scores)[-semantic_top_k:][::-1]
        
        # ê²°ê³¼ í†µí•©
        results = {}
        
        for idx in keyword_top_indices:
            lab_id = self.labs[idx].id
            results[lab_id] = {
                "keyword_score": float(keyword_scores[idx]),
                "semantic_score": 0.0,
                "sources": ["keyword"]
            }
        
        for idx in semantic_top_indices:
            lab_id = self.labs[idx].id
            if lab_id in results:
                results[lab_id]["semantic_score"] = float(semantic_scores[idx])
                results[lab_id]["sources"].append("semantic")
            else:
                results[lab_id] = {
                    "keyword_score": 0.0,
                    "semantic_score": float(semantic_scores[idx]),
                    "sources": ["semantic"]
                }
        
        return results


if __name__ == "__main__":
    # ì‹¤ì œ ë°ì´í„° ì‚¬ìš© í…ŒìŠ¤íŠ¸
    print("="*80)
    print("ğŸ¯ ì—°êµ¬ì‹¤ í›„ë³´êµ° ìƒì„± ì‹œìŠ¤í…œ")
    print("="*80)
    print()
    
    # CandidateGenerator ì´ˆê¸°í™” (ì‹¤ì œ ë°ì´í„° ë¡œë“œ)
    generator = CandidateGenerator(
        labs_json_path="./data/crawl_data/labs.json",
        docs_json_path="./data/crawl_data/documents.json"
    )
    
    # í…ŒìŠ¤íŠ¸ í•™ìƒ ì •ë³´
    test_queries = [
        "ì»´í“¨í„° ë¹„ì „ê³¼ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ì´ë¯¸ì§€ ì¸ì‹ ì—°êµ¬",
        "ìì—°ì–´ì²˜ë¦¬ì™€ ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ ê°œë°œ",
        "ë¡œë´‡ ì œì–´ ë° ììœ¨ì£¼í–‰ ê¸°ìˆ ",
        "ì „ë ¥ ì‹œìŠ¤í…œê³¼ ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ",
        "ë¬´ì„  í†µì‹  ë° 5G ë„¤íŠ¸ì›Œí¬"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print("\n" + "="*80)
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {query}")
        print("="*80)
        
        student = Student(research_interests=query)
        
        # í›„ë³´êµ° ìƒì„± (ì ìˆ˜ í¬í•¨)
        candidates_with_scores = generator.get_candidates_with_scores(
            student,
            keyword_top_k=10,
            semantic_top_k=10
        )
        
        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        sorted_candidates = sorted(
            candidates_with_scores.items(),
            key=lambda x: x[1]['keyword_score'] + x[1]['semantic_score'],
            reverse=True
        )
        
        # ìƒìœ„ 5ê°œ ì¶œë ¥
        print(f"\nğŸ† ìƒìœ„ 5ê°œ í›„ë³´ ì—°êµ¬ì‹¤:\n")
        for rank, (lab_id, scores) in enumerate(sorted_candidates[:5], 1):
            lab = next(lab for lab in generator.labs if lab.id == lab_id)
            total_score = scores['keyword_score'] + scores['semantic_score']
            sources = ', '.join(scores['sources'])
            
            print(f"{rank}. [{lab.professor}] {lab.name}")
            print(f"   ì´ì : {total_score:.4f} (í‚¤ì›Œë“œ: {scores['keyword_score']:.4f}, ì˜ë¯¸: {scores['semantic_score']:.4f})")
            print(f"   ë§¤ì¹­: {sources}")
            print(f"   ì„¤ëª…: {lab.description[:100]}...")
            print()
    
    print("="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)