"""
í›„ë³´êµ° ìƒì„± (Candidate Generation) - ìµœì¢… ê°œì„  ë²„ì „ v2
ë¶ˆìš©ì–´ ì œê±° + ë¶€ì • í•„í„°ë§ ì¶”ê°€
"""

from typing import List, Dict, Set, Tuple
from dataclasses import dataclass
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import json
import re
from collections import defaultdict

# ğŸ”§ í•œêµ­ì–´/ì˜ì–´ ë¶ˆìš©ì–´
STOPWORDS = {
    # í•œêµ­ì–´ ì¼ë°˜ ë‹¨ì–´
    'ì—°êµ¬', 'ê°œë°œ', 'ì‹œìŠ¤í…œ', 'ê¸°ìˆ ', 'ì‘ìš©', 'ë¶„ì„', 'ì„¤ê³„', 'êµ¬í˜„',
    'ì´ë¡ ', 'ê¸°ë°˜', 'ê´€ë ¨', 'ë“±', 'ë°', 'ë¥¼', 'ì„', 'ëŠ”', 'ì€', 'ì´', 'ê°€',
    'ì˜', 'ì—', 'ì™€', 'ê³¼', 'ë„', 'ë¡œ', 'ìœ¼ë¡œ', 'ë¶€í„°', 'ê¹Œì§€', 'ì—°êµ¬ì‹¤',
    'ë©', 'lab', 'ê·¸ë£¹', 'group',
    
    # ì˜ì–´ ì¼ë°˜ ë‹¨ì–´
    'research', 'development', 'system', 'systems', 'technology', 
    'application', 'applications', 'analysis', 'design', 'implementation',
    'theory', 'based', 'and', 'or', 'the', 'a', 'an', 'of', 'for', 
    'in', 'on', 'at', 'to', 'from', 'with', 'laboratory'
}

# ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „
RESEARCH_KEYWORDS = {
    'AI/ML': {
        'terms': ['ai', 'ì¸ê³µì§€ëŠ¥', 'artificial intelligence', 
                  'machine learning', 'ë¨¸ì‹ ëŸ¬ë‹', 'ê¸°ê³„í•™ìŠµ', 'ml',
                  'deep learning', 'ë”¥ëŸ¬ë‹', 'ì‹¬ì¸µí•™ìŠµ', 'dl',
                  'neural network', 'ì‹ ê²½ë§', 'deep neural'],
        'weight': 1.0
    },
    'ì»´í“¨í„°ë¹„ì „': {
        'terms': ['computer vision', 'ì»´í“¨í„° ë¹„ì „', 'ì»´í“¨í„°ë¹„ì „',
                  'cv', 'ì˜ìƒì²˜ë¦¬', 'image processing', 'ì´ë¯¸ì§€ ì²˜ë¦¬',
                  'object detection', 'ê°ì²´ íƒì§€', 'ê°ì²´ ê²€ì¶œ',
                  'image recognition', 'ì´ë¯¸ì§€ ì¸ì‹', 'ì˜ìƒ ì¸ì‹',
                  'visual', 'ë¹„ì „'],
        'weight': 1.0
    },
    'ë¡œë´‡/ììœ¨ì£¼í–‰': {
        'terms': ['robot', 'ë¡œë´‡', 'robotics', 'ë¡œë³´í‹±ìŠ¤',
                  'autonomous', 'ììœ¨ì£¼í–‰', 'self-driving', 'ììœ¨ ì£¼í–‰',
                  'slam', 'navigation', 'ë‚´ë¹„ê²Œì´ì…˜', 'spatial'],
        'weight': 1.0
    },
    'NLP/ëŒ€í™”': {
        'terms': ['nlp', 'natural language', 'ìì—°ì–´', 'ìì—°ì–´ì²˜ë¦¬',
                  'language model', 'ì–¸ì–´ ëª¨ë¸', 'text', 'í…ìŠ¤íŠ¸',
                  'chatbot', 'ì±—ë´‡', 'dialogue', 'ëŒ€í™”', 'ëŒ€í™”í˜•',
                  'conversational', 'speech', 'ìŒì„±'],
        'weight': 1.0
    },
    'ì œì–´': {
        'terms': ['control', 'ì œì–´', 'control system', 'ì œì–´ì‹œìŠ¤í…œ',
                  'optimization', 'ìµœì í™”', 'fuzzy'],
        'weight': 0.9
    },
    'ì „ë ¥/ì—ë„ˆì§€': {
        'terms': ['power', 'ì „ë ¥', 'energy', 'ì—ë„ˆì§€',
                  'smart grid', 'ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ', 'ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ',
                  'power system', 'ì „ë ¥ ì‹œìŠ¤í…œ', 'ì „ë ¥ë§',
                  'microgrid', 'ë§ˆì´í¬ë¡œê·¸ë¦¬ë“œ'],
        'weight': 1.0
    },
    'ë°˜ë„ì²´': {
        'terms': ['semiconductor', 'ë°˜ë„ì²´', 'device', 'ì†Œì',
                  'vlsi', 'ic', 'integrated circuit', 'ì§‘ì íšŒë¡œ',
                  'transistor', 'íŠ¸ëœì§€ìŠ¤í„°'],
        'weight': 0.9
    },
    'í†µì‹ /ë„¤íŠ¸ì›Œí¬': {
        'terms': ['communication', 'í†µì‹ ', 'network', 'ë„¤íŠ¸ì›Œí¬',
                  '5g', '6g', 'wireless', 'ë¬´ì„ ', 'iot'],
        'weight': 1.0
    },
    'ì‹ í˜¸ì²˜ë¦¬': {
        'terms': ['signal processing', 'ì‹ í˜¸ì²˜ë¦¬', 'ì‹ í˜¸ ì²˜ë¦¬',
                  'dsp', 'filtering', 'í•„í„°ë§'],
        'weight': 0.8
    }
}


def tokenize_with_stopwords(text: str) -> List[str]:
    """ë¶ˆìš©ì–´ë¥¼ ì œê±°í•œ í† í°í™”"""
    tokens = text.lower().split()
    # ë¶ˆìš©ì–´ ì œê±°
    filtered_tokens = [t for t in tokens if t not in STOPWORDS]
    return filtered_tokens


def keyword_match_score(query: str, lab_text: str) -> float:
    """ë„ë©”ì¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ ì ìˆ˜"""
    query_lower = query.lower()
    lab_lower = lab_text.lower()
    
    total_score = 0.0
    matched_categories = []
    
    for category, data in RESEARCH_KEYWORDS.items():
        query_matches = [term for term in data['terms'] if term in query_lower]
        
        if query_matches:
            lab_matches = [term for term in data['terms'] if term in lab_lower]
            
            if lab_matches:
                match_ratio = len(lab_matches) / len(data['terms'])
                category_score = min(match_ratio * 3, 1.0) * data['weight']
                total_score += category_score
                matched_categories.append(category)
    
    if matched_categories:
        return min(total_score / len(matched_categories), 1.0)
    return 0.0


def get_query_categories(query: str) -> Set[str]:
    """ì¿¼ë¦¬ì˜ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
    query_lower = query.lower()
    categories = set()
    
    for category, data in RESEARCH_KEYWORDS.items():
        if any(term in query_lower for term in data['terms']):
            categories.add(category)
    
    return categories


def get_lab_categories(lab_text: str) -> Set[str]:
    """ë©ì‹¤ì˜ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
    lab_lower = lab_text.lower()
    categories = set()
    
    for category, data in RESEARCH_KEYWORDS.items():
        if any(term in lab_lower for term in data['terms']):
            categories.add(category)
    
    return categories


@dataclass
class Lab:
    """ì—°êµ¬ì‹¤ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    name: str
    professor: str
    description: str
    homepage: str = ""
    location: str = ""
    
    def get_search_text(self) -> str:
        """name + descriptionë§Œ ì‚¬ìš©"""
        return f"{self.name} {self.description}"


@dataclass
class Student:
    """í•™ìƒ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    research_interests: str


class CandidateGenerator:
    """
    í‚¤ì›Œë“œ ê²€ìƒ‰ + ì˜ë¯¸ ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ í›„ë³´ ë©ì‹¤ ì¶”ì¶œ
    [ìµœì¢… ê°œì„  ë²„ì „ v2: ë¶ˆìš©ì–´ ì œê±° + ë¶€ì • í•„í„°ë§]
    """
    
    def __init__(
        self, 
        labs_json_path: str = "./data/crawl_data/labs.json",
        embedding_model_name: str = "intfloat/e5-small-v2",
        keyword_weight: float = 0.5,
        semantic_weight: float = 0.5,
        use_domain_keywords: bool = True,
        use_negative_filtering: bool = True  # ğŸ”§ ë¶€ì • í•„í„°ë§
    ):
        """
        Args:
            labs_json_path: labs.json íŒŒì¼ ê²½ë¡œ
            embedding_model_name: E5 ì„ë² ë”© ëª¨ë¸ëª…
            keyword_weight: í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            semantic_weight: ì˜ë¯¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            use_domain_keywords: ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ìš© ì—¬ë¶€
            use_negative_filtering: ë¶€ì • í•„í„°ë§ ì‚¬ìš© ì—¬ë¶€
        """
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        self.labs = self._load_labs_from_json(labs_json_path)
        print(f"âœ… {len(self.labs)}ê°œ ì—°êµ¬ì‹¤ ë¡œë“œ ì™„ë£Œ")
        
        print("ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ì„¤ì •
        self.keyword_weight = keyword_weight
        self.semantic_weight = semantic_weight
        self.use_domain_keywords = use_domain_keywords
        self.use_negative_filtering = use_negative_filtering
        print(f"âš–ï¸  ê°€ì¤‘ì¹˜ ì„¤ì • - í‚¤ì›Œë“œ: {keyword_weight:.1f}, ì˜ë¯¸: {semantic_weight:.1f}")
        
        if use_domain_keywords:
            print("ğŸ¯ ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „ í™œì„±í™”")
        if use_negative_filtering:
            print("ğŸš« ë¶€ì • í•„í„°ë§ í™œì„±í™”")
        
        # BM25 ì¸ë±ìŠ¤ ì¤€ë¹„ (ë¶ˆìš©ì–´ ì œê±° ì ìš©)
        print("ğŸ” BM25 ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘ (ë¶ˆìš©ì–´ ì œê±°)...")
        self._prepare_bm25_index()
        
        # E5 ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚°
        print("ğŸ§  ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚° ì¤‘...")
        self._prepare_embeddings()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def _load_labs_from_json(self, labs_path: str) -> List[Lab]:
        """labs.jsonë§Œ ë¡œë“œ"""
        with open(labs_path, 'r', encoding='utf-8') as f:
            labs_data = json.load(f)
        
        labs = []
        for lab_id, lab_info in labs_data.items():
            lab = Lab(
                id=lab_id,
                name=lab_info.get('kor_name', ''),
                professor=lab_info.get('professor', ''),
                description=lab_info.get('description', ''),
                homepage=lab_info.get('homepage', ''),
                location=lab_info.get('location', '')
            )
            labs.append(lab)
        
        return labs
    
    def _prepare_bm25_index(self):
        """ğŸ”§ BM25 ì¸ë±ìŠ¤ ì¤€ë¹„ (ë¶ˆìš©ì–´ ì œê±° ì ìš©)"""
        corpus = [lab.get_search_text() for lab in self.labs]
        tokenized_corpus = [tokenize_with_stopwords(doc) for doc in corpus]
        self.bm25 = BM25Okapi(tokenized_corpus)
    
    def _prepare_embeddings(self):
        """E5-small ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚°"""
        lab_texts = [lab.get_search_text() for lab in self.labs]
        lab_texts_with_prefix = [f"passage: {text}" for text in lab_texts]
        self.lab_embeddings = self.embedding_model.encode(
            lab_texts_with_prefix, 
            normalize_embeddings=True,
            show_progress_bar=True
        )
    
    def _normalize_keyword_scores(self, scores: np.ndarray) -> np.ndarray:
        """í‚¤ì›Œë“œ ì ìˆ˜ ì •ê·œí™” (0~1)"""
        log_scores = np.log1p(scores)
        min_score = np.min(log_scores)
        max_score = np.max(log_scores)
        
        if max_score - min_score < 1e-8:
            return np.zeros_like(scores)
        
        normalized = (log_scores - min_score) / (max_score - min_score)
        return normalized
    
    def _rescale_semantic_scores(self, scores: np.ndarray, threshold: float = 0.70) -> np.ndarray:
        """
        ğŸ”§ ì˜ë¯¸ ì ìˆ˜ ì¬ì¡°ì • (threshold ìƒí–¥: 0.65 â†’ 0.70)
        """
        scores_filtered = np.where(scores >= threshold, scores, 0.0)
        
        nonzero_mask = scores_filtered > 0
        if not np.any(nonzero_mask):
            return scores_filtered
        
        min_score = np.min(scores_filtered[nonzero_mask])
        max_score = np.max(scores_filtered[nonzero_mask])
        
        if max_score - min_score < 1e-8:
            scores_filtered[nonzero_mask] = 0.5
        else:
            scores_filtered[nonzero_mask] = (
                (scores_filtered[nonzero_mask] - min_score) / (max_score - min_score)
            )
        
        return scores_filtered
    
    def _filter_irrelevant_labs(self, query: str, lab: Lab, combined_score: float) -> bool:
        """
        ğŸ”§ [NEW] ëª…ë°±íˆ ê´€ë ¨ ì—†ëŠ” ì—°êµ¬ì‹¤ í•„í„°ë§
        """
        if not self.use_negative_filtering:
            return True
        
        # 1. ì¿¼ë¦¬ì™€ ë©ì‹¤ì˜ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
        query_categories = get_query_categories(query)
        lab_text = lab.get_search_text()
        lab_categories = get_lab_categories(lab_text)
        
        # 2. ì¹´í…Œê³ ë¦¬ ê²¹ì¹¨ í™•ì¸
        if query_categories and lab_categories:
            overlap = query_categories & lab_categories
            if not overlap:
                # ì¹´í…Œê³ ë¦¬ê°€ ì „í˜€ ì•ˆ ê²¹ì¹¨
                # ë‹¨, ì ìˆ˜ê°€ ë§¤ìš° ë†’ìœ¼ë©´ (0.8 ì´ìƒ) í†µê³¼
                if combined_score < 0.8:
                    return False
        
        return True
    
    def get_candidates_with_scores(
        self,
        student: Student,
        final_top_k: int = 15
    ) -> Dict[str, Dict]:
        """
        í›„ë³´êµ° ìƒì„± (ë¶ˆìš©ì–´ ì œê±° + ë¶€ì • í•„í„°ë§ ì ìš©)
        """
        query = student.research_interests
        
        # ===== 1. BM25 í‚¤ì›Œë“œ ì ìˆ˜ (ë¶ˆìš©ì–´ ì œê±° ì ìš©) =====
        tokenized_query = tokenize_with_stopwords(query)
        keyword_scores_raw = self.bm25.get_scores(tokenized_query)
        keyword_scores_norm = self._normalize_keyword_scores(keyword_scores_raw)
        
        # ===== 2. ì˜ë¯¸ ì ìˆ˜ (threshold ìƒí–¥) =====
        query_with_prefix = f"query: {query}"
        query_embedding = self.embedding_model.encode(
            query_with_prefix, normalize_embeddings=True
        )
        semantic_scores_raw = np.dot(self.lab_embeddings, query_embedding)
        semantic_scores_rescaled = self._rescale_semantic_scores(semantic_scores_raw)
        
        # ===== 3. ë„ë©”ì¸ í‚¤ì›Œë“œ ì ìˆ˜ =====
        domain_scores = np.zeros(len(self.labs))
        if self.use_domain_keywords:
            for idx, lab in enumerate(self.labs):
                lab_text = lab.get_search_text()
                domain_scores[idx] = keyword_match_score(query, lab_text)
        
        # ===== 4. Combined score ê³„ì‚° =====
        results = {}
        for idx, lab in enumerate(self.labs):
            keyword_score = float(keyword_scores_norm[idx])
            semantic_score = float(semantic_scores_rescaled[idx])
            domain_score = float(domain_scores[idx])
            
            # ğŸ”§ ë„ë©”ì¸ ì ìˆ˜ ìš°ì„  ë°˜ì˜
            if self.use_domain_keywords and domain_score > 0.3:
                # ë„ë©”ì¸ ë§¤ì¹­ì´ ìˆìœ¼ë©´ ë„ë©”ì¸ ìš°ì„ 
                effective_keyword = domain_score * 0.7 + keyword_score * 0.3
            else:
                # ë„ë©”ì¸ ë§¤ì¹­ ì—†ìœ¼ë©´ BM25
                effective_keyword = keyword_score
            
            combined_score = (
                effective_keyword * self.keyword_weight +
                semantic_score * self.semantic_weight
            )
            
            # ğŸ”§ ë¶€ì • í•„í„°ë§ ì ìš©
            if not self._filter_irrelevant_labs(query, lab, combined_score):
                continue
            
            # ìµœì†Œ ì„ê³„ê°’
            if combined_score > 0.05:
                results[lab.id] = {
                    "keyword_score": keyword_score,
                    "semantic_score": semantic_score,
                    "domain_score": domain_score,
                    "combined_score": combined_score,
                    "sources": []
                }
                
                if effective_keyword > 0.1:
                    results[lab.id]["sources"].append("keyword")
                if semantic_score > 0.1:
                    results[lab.id]["sources"].append("semantic")
        
        # ===== 5. Combined score ê¸°ì¤€ Top-K ì„ íƒ =====
        sorted_results = sorted(
            results.items(),
            key=lambda x: x[1]['combined_score'],
            reverse=True
        )
        
        return dict(sorted_results[:final_top_k])


if __name__ == "__main__":
    print("="*80)
    print("ğŸ¯ ì—°êµ¬ì‹¤ í›„ë³´êµ° ìƒì„± ì‹œìŠ¤í…œ")
    print("   - ë¶ˆìš©ì–´ ì œê±°")
    print("   - ë¶€ì • í•„í„°ë§")
    print("   - ë„ë©”ì¸ í‚¤ì›Œë“œ ìš°ì„ ")
    print("="*80)
    print()
    
    # CandidateGenerator ì´ˆê¸°í™”
    generator = CandidateGenerator(
        labs_json_path="./data/crawl_data/labs.json",
        keyword_weight=0.5,
        semantic_weight=0.5,
        use_domain_keywords=True,
        use_negative_filtering=True  # ë¶€ì • í•„í„°ë§ í™œì„±í™”
    )
    
    # í…ŒìŠ¤íŠ¸ í•™ìƒ ì •ë³´
    test_queries = [
        "ì»´í“¨í„° ë¹„ì „ê³¼ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ì´ë¯¸ì§€ ì¸ì‹ ì—°êµ¬",
        "ìì—°ì–´ì²˜ë¦¬ì™€ ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ ê°œë°œ",
        "ë¡œë´‡ ì œì–´ ë° ììœ¨ì£¼í–‰ ê¸°ìˆ ",
        "ì „ë ¥ ì‹œìŠ¤í…œê³¼ ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ",
        "ë¬´ì„  í†µì‹  ë° 5G ë„¤íŠ¸ì›Œí¬"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print("\n" + "="*80)
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {query}")
        print("="*80)
        
        student = Student(research_interests=query)
        
        # í›„ë³´êµ° ìƒì„±
        candidates_with_scores = generator.get_candidates_with_scores(
            student,
            final_top_k=10
        )
        
        # ì¶œë ¥
        print(f"\nğŸ† ìƒìœ„ 10ê°œ í›„ë³´ ì—°êµ¬ì‹¤:\n")
        for rank, (lab_id, scores) in enumerate(candidates_with_scores.items(), 1):
            lab = next(lab for lab in generator.labs if lab.id == lab_id)
            sources = ', '.join(scores['sources']) if scores['sources'] else 'combined'
            
            print(f"{rank}. [{lab.professor}] {lab.name}")
            # print(f"   ì´ì : {scores['combined_score']:.4f}")
            # print(f"   ì„¸ë¶€: í‚¤ì›Œë“œ={scores['keyword_score']:.4f}, "
            #       f"ì˜ë¯¸={scores['semantic_score']:.4f}, "
            #       f"ë„ë©”ì¸={scores['domain_score']:.4f}")
            # print(f"   ë§¤ì¹­: {sources}")
            # print(f"   ì„¤ëª…: {lab.description[:80]}...")
            print()
    
    print("="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)