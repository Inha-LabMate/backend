"""
í›„ë³´êµ° ìƒì„± (Candidate Generation) - 1ë‹¨ê³„ [ìµœì¢… ê°œì„  ë²„ì „]
name + descriptionë§Œ ì‚¬ìš©í•˜ì—¬ ì •í™•ë„ í–¥ìƒ

ì£¼ìš” ê°œì„ ì‚¬í•­:
1. name + descriptionë§Œ ì‚¬ìš© (ë…¸ì´ì¦ˆ ì œê±°)
2. ëª¨ë“  ë©ì‹¤ ì ìˆ˜ ê³„ì‚° (Top-K ì„ íƒ ë¬¸ì œ í•´ê²°)
3. ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „ ì¶”ê°€
4. ì ìˆ˜ ì •ê·œí™” ë° ê°€ì¤‘ì¹˜ ì ìš©
"""

from typing import List, Dict, Set, Tuple
from dataclasses import dataclass
import numpy as np
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
import json
import re
from collections import defaultdict

# ğŸ”§ ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „
RESEARCH_KEYWORDS = {
    'AI/ML': {
        'terms': ['ai', 'ì¸ê³µì§€ëŠ¥', 'artificial intelligence', 
                  'machine learning', 'ë¨¸ì‹ ëŸ¬ë‹', 'ê¸°ê³„í•™ìŠµ',
                  'deep learning', 'ë”¥ëŸ¬ë‹', 'ì‹¬ì¸µí•™ìŠµ',
                  'neural network', 'ì‹ ê²½ë§', 'deep neural'],
        'weight': 0.5
    },
    'ì»´í“¨í„°ë¹„ì „': {
        'terms': ['computer vision', 'ì»´í“¨í„° ë¹„ì „', 'ì»´í“¨í„°ë¹„ì „',
                  'cv', 'ì˜ìƒì²˜ë¦¬', 'image processing', 'ì´ë¯¸ì§€ ì²˜ë¦¬',
                  'object detection', 'ê°ì²´ íƒì§€', 'ê°ì²´ ê²€ì¶œ',
                  'image recognition', 'ì´ë¯¸ì§€ ì¸ì‹', 'ì˜ìƒ ì¸ì‹',
                  'visual', 'ë¹„ì „'],
        'weight': 0.5
    },
    'ë¡œë´‡/ììœ¨ì£¼í–‰': {
        'terms': ['robot', 'ë¡œë´‡', 'robotics', 'ë¡œë³´í‹±ìŠ¤',
                  'autonomous', 'ììœ¨ì£¼í–‰', 'self-driving', 'ììœ¨ ì£¼í–‰',
                  'slam', 'navigation', 'ë‚´ë¹„ê²Œì´ì…˜', 'spatial'],
        'weight': 0.5
    },
    'NLP': {
        'terms': ['nlp', 'natural language', 'ìì—°ì–´', 'ìì—°ì–´ì²˜ë¦¬',
                  'language model', 'ì–¸ì–´ ëª¨ë¸', 'text', 'í…ìŠ¤íŠ¸',
                  'chatbot', 'ì±—ë´‡', 'dialogue', 'ëŒ€í™”'],
        'weight': 0.5
    },
    'ì œì–´': {
        'terms': ['control', 'ì œì–´', 'control system', 'ì œì–´ì‹œìŠ¤í…œ',
                  'optimization', 'ìµœì í™”', 'fuzzy'],
        'weight': 0.5
    },
    'ì „ë ¥/ì—ë„ˆì§€': {
        'terms': ['power', 'ì „ë ¥', 'energy', 'ì—ë„ˆì§€',
                  'smart grid', 'ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ', 'ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ',
                  'power system', 'ì „ë ¥ ì‹œìŠ¤í…œ', 'ì „ë ¥ë§',
                  'microgrid', 'ë§ˆì´í¬ë¡œê·¸ë¦¬ë“œ'],
        'weight': 0.5
    },
    'ë°˜ë„ì²´': {
        'terms': ['semiconductor', 'ë°˜ë„ì²´', 'device', 'ì†Œì',
                  'vlsi', 'ic', 'integrated circuit', 'ì§‘ì íšŒë¡œ',
                  'transistor', 'íŠ¸ëœì§€ìŠ¤í„°'],
        'weight': 0.5
    },
    'í†µì‹ /ë„¤íŠ¸ì›Œí¬': {
        'terms': ['communication', 'í†µì‹ ', 'network', 'ë„¤íŠ¸ì›Œí¬',
                  '5g', '6g', 'wireless', 'ë¬´ì„ ', 'iot'],
        'weight': 0.5
    },
    'ì‹ í˜¸ì²˜ë¦¬': {
        'terms': ['signal processing', 'ì‹ í˜¸ì²˜ë¦¬', 'ì‹ í˜¸ ì²˜ë¦¬',
                  'dsp', 'filtering', 'í•„í„°ë§'],
        'weight': 0.5
    }
}


@dataclass
class Lab:
    """ì—°êµ¬ì‹¤ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    id: str
    name: str
    professor: str
    description: str
    homepage: str = ""
    location: str = ""
    
    def get_search_text(self) -> str:
        """ğŸ”§ [NEW] name + descriptionë§Œ ì‚¬ìš©"""
        return f"{self.name} {self.description}"


@dataclass
class Student:
    """í•™ìƒ ì •ë³´ ë°ì´í„° í´ë˜ìŠ¤"""
    research_interests: str


def keyword_match_score(query: str, lab_text: str) -> float:
    """
    ğŸ”§ [NEW] ë„ë©”ì¸ í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ ì ìˆ˜
    
    Returns:
        0.0 ~ 1.0 ì ìˆ˜
    """
    query_lower = query.lower()
    lab_lower = lab_text.lower()
    
    total_score = 0.0
    matched_categories = []
    
    for category, data in RESEARCH_KEYWORDS.items():
        # ì¿¼ë¦¬ì—ì„œ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ í™•ì¸
        query_matches = [term for term in data['terms'] if term in query_lower]
        
        if query_matches:
            # ë©ì‹¤ì—ì„œë„ ê°™ì€ ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œ í™•ì¸
            lab_matches = [term for term in data['terms'] if term in lab_lower]
            
            if lab_matches:
                # ë§¤ì¹­ ê°•ë„ ê³„ì‚°
                match_ratio = len(lab_matches) / len(data['terms'])
                category_score = min(match_ratio * 3, 1.0) * data['weight']
                total_score += category_score
                matched_categories.append(category)
    
    # ì •ê·œí™”
    if matched_categories:
        return min(total_score / len(matched_categories), 1.0)
    return 0.0


class CandidateGenerator:
    """
    í‚¤ì›Œë“œ ê²€ìƒ‰ + ì˜ë¯¸ ê²€ìƒ‰ì„ ê²°í•©í•˜ì—¬ í›„ë³´ ë©ì‹¤ ì¶”ì¶œ
    [ìµœì¢… ê°œì„  ë²„ì „]
    """
    
    def __init__(
        self, 
        labs_json_path: str = "./data/crawl_data/labs.json",
        embedding_model_name: str = "intfloat/e5-small-v2",
        keyword_weight: float = 0.6,  # í‚¤ì›Œë“œ ë¹„ì¤‘ ë†’ì„
        semantic_weight: float = 0.4,
        use_domain_keywords: bool = True  # ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ìš© ì—¬ë¶€
    ):
        """
        Args:
            labs_json_path: labs.json íŒŒì¼ ê²½ë¡œ
            embedding_model_name: E5 ì„ë² ë”© ëª¨ë¸ëª…
            keyword_weight: í‚¤ì›Œë“œ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            semantic_weight: ì˜ë¯¸ ê²€ìƒ‰ ê°€ì¤‘ì¹˜
            use_domain_keywords: ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ìš© ì—¬ë¶€
        """
        print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")
        self.labs = self._load_labs_from_json(labs_json_path)
        print(f"âœ… {len(self.labs)}ê°œ ì—°êµ¬ì‹¤ ë¡œë“œ ì™„ë£Œ")
        
        print("ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.embedding_model = SentenceTransformer(embedding_model_name)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        
        # ì„¤ì •
        self.keyword_weight = keyword_weight
        self.semantic_weight = semantic_weight
        self.use_domain_keywords = use_domain_keywords
        print(f"âš–ï¸  ê°€ì¤‘ì¹˜ ì„¤ì • - í‚¤ì›Œë“œ: {keyword_weight:.1f}, ì˜ë¯¸: {semantic_weight:.1f}")
        
        if use_domain_keywords:
            print("ğŸ¯ ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „ í™œì„±í™”")
        
        # BM25 ì¸ë±ìŠ¤ ì¤€ë¹„
        print("ğŸ” BM25 ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘...")
        self._prepare_bm25_index()
        
        # E5 ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚°
        print("ğŸ§  ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚° ì¤‘...")
        self._prepare_embeddings()
        print("âœ… ì´ˆê¸°í™” ì™„ë£Œ!\n")
    
    def _load_labs_from_json(self, labs_path: str) -> List[Lab]:
        """
        ğŸ”§ [SIMPLIFIED] labs.jsonë§Œ ë¡œë“œ (documents.json ë¶ˆí•„ìš”)
        """
        with open(labs_path, 'r', encoding='utf-8') as f:
            labs_data = json.load(f)
        
        labs = []
        for lab_id, lab_info in labs_data.items():
            lab = Lab(
                id=lab_id,
                name=lab_info.get('kor_name', ''),
                professor=lab_info.get('professor', ''),
                description=lab_info.get('description', ''),
                homepage=lab_info.get('homepage', ''),
                location=lab_info.get('location', '')
            )
            labs.append(lab)
        
        return labs
    
    def _prepare_bm25_index(self):
        """BM25 í‚¤ì›Œë“œ ê²€ìƒ‰ì„ ìœ„í•œ ì¸ë±ìŠ¤ ì¤€ë¹„"""
        corpus = [lab.get_search_text() for lab in self.labs]
        tokenized_corpus = [doc.lower().split() for doc in corpus]
        self.bm25 = BM25Okapi(tokenized_corpus)
    
    def _prepare_embeddings(self):
        """E5-small ì„ë² ë”© ë²¡í„° ì‚¬ì „ ê³„ì‚°"""
        lab_texts = [lab.get_search_text() for lab in self.labs]
        lab_texts_with_prefix = [f"passage: {text}" for text in lab_texts]
        self.lab_embeddings = self.embedding_model.encode(
            lab_texts_with_prefix, 
            normalize_embeddings=True,
            show_progress_bar=True
        )
    
    def _normalize_keyword_scores(self, scores: np.ndarray) -> np.ndarray:
        """í‚¤ì›Œë“œ ì ìˆ˜ ì •ê·œí™” (0~1)"""
        log_scores = np.log1p(scores)
        min_score = np.min(log_scores)
        max_score = np.max(log_scores)
        
        if max_score - min_score < 1e-8:
            return np.zeros_like(scores)
        
        normalized = (log_scores - min_score) / (max_score - min_score)
        return normalized
    
    def _rescale_semantic_scores(self, scores: np.ndarray, threshold: float = 0.65) -> np.ndarray:
        """
        ğŸ”§ [ADJUSTED] ì˜ë¯¸ ì ìˆ˜ ì¬ì¡°ì • (threshold ë‚®ì¶¤: 0.7 â†’ 0.65)
        """
        scores_filtered = np.where(scores >= threshold, scores, 0.0)
        
        nonzero_mask = scores_filtered > 0
        if not np.any(nonzero_mask):
            return scores_filtered
        
        min_score = np.min(scores_filtered[nonzero_mask])
        max_score = np.max(scores_filtered[nonzero_mask])
        
        if max_score - min_score < 1e-8:
            scores_filtered[nonzero_mask] = 0.5
        else:
            scores_filtered[nonzero_mask] = (
                (scores_filtered[nonzero_mask] - min_score) / (max_score - min_score)
            )
        
        return scores_filtered
    
    def get_candidates_with_scores(
        self,
        student: Student,
        final_top_k: int = 15
    ) -> Dict[str, Dict]:
        """
        ğŸ”§ [IMPROVED] ëª¨ë“  ë©ì‹¤ ì ìˆ˜ ê³„ì‚° í›„ Top-K ì„ íƒ
        
        Returns:
            {lab_id: {
                "keyword_score": float,
                "semantic_score": float,
                "domain_score": float (ë„ë©”ì¸ í‚¤ì›Œë“œ ì ìˆ˜),
                "combined_score": float,
                "sources": List[str]
            }}
        """
        query = student.research_interests
        
        # ===== 1. BM25 í‚¤ì›Œë“œ ì ìˆ˜ (ëª¨ë“  ë©ì‹¤) =====
        tokenized_query = query.lower().split()
        keyword_scores_raw = self.bm25.get_scores(tokenized_query)
        keyword_scores_norm = self._normalize_keyword_scores(keyword_scores_raw)
        
        # ===== 2. ì˜ë¯¸ ì ìˆ˜ (ëª¨ë“  ë©ì‹¤) =====
        query_with_prefix = f"query: {query}"
        query_embedding = self.embedding_model.encode(
            query_with_prefix, normalize_embeddings=True
        )
        semantic_scores_raw = np.dot(self.lab_embeddings, query_embedding)
        semantic_scores_rescaled = self._rescale_semantic_scores(semantic_scores_raw)
        
        # ===== 3. ë„ë©”ì¸ í‚¤ì›Œë“œ ì ìˆ˜ (ì„ íƒì ) =====
        domain_scores = np.zeros(len(self.labs))
        if self.use_domain_keywords:
            for idx, lab in enumerate(self.labs):
                lab_text = lab.get_search_text()
                domain_scores[idx] = keyword_match_score(query, lab_text)
        
        # ===== 4. Combined score ê³„ì‚° =====
        results = {}
        for idx, lab in enumerate(self.labs):
            keyword_score = float(keyword_scores_norm[idx])
            semantic_score = float(semantic_scores_rescaled[idx])
            domain_score = float(domain_scores[idx])
            
            # ê°€ì¤‘ì¹˜ ì ìš©
            if self.use_domain_keywords:
                # ë„ë©”ì¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ BM25 ëŒ€ì‹  ì‚¬ìš©
                effective_keyword = max(keyword_score, domain_score)
            else:
                effective_keyword = keyword_score
            
            combined_score = (
                effective_keyword * self.keyword_weight +
                semantic_score * self.semantic_weight
            )
            
            # ìµœì†Œ ì„ê³„ê°’ (ì™„ì „íˆ ë¬´ê´€í•œ ë©ì‹¤ ì œì™¸)
            if combined_score > 0.05:
                results[lab.id] = {
                    "keyword_score": keyword_score,
                    "semantic_score": semantic_score,
                    "domain_score": domain_score,
                    "combined_score": combined_score,
                    "sources": []
                }
                
                if effective_keyword > 0.1:
                    results[lab.id]["sources"].append("keyword")
                if semantic_score > 0.1:
                    results[lab.id]["sources"].append("semantic")
        
        # ===== 5. Combined score ê¸°ì¤€ Top-K ì„ íƒ =====
        sorted_results = sorted(
            results.items(),
            key=lambda x: x[1]['combined_score'],
            reverse=True
        )
        
        return dict(sorted_results[:final_top_k])


if __name__ == "__main__":
    print("="*80)
    print("ğŸ¯ ì—°êµ¬ì‹¤ í›„ë³´êµ° ìƒì„± ì‹œìŠ¤í…œ [ìµœì¢… ê°œì„  ë²„ì „]")
    print("   - name + descriptionë§Œ ì‚¬ìš©")
    print("   - ë„ë©”ì¸ í‚¤ì›Œë“œ ì‚¬ì „ ì¶”ê°€")
    print("   - ëª¨ë“  ë©ì‹¤ ì ìˆ˜ ê³„ì‚°")
    print("="*80)
    print()
    
    # CandidateGenerator ì´ˆê¸°í™”
    generator = CandidateGenerator(
        labs_json_path="./data/crawl_data/labs.json",
        keyword_weight=0.6,
        semantic_weight=0.4,
        use_domain_keywords=True
    )
    
    # í…ŒìŠ¤íŠ¸ í•™ìƒ ì •ë³´
    test_queries = [
        "ì»´í“¨í„° ë¹„ì „ê³¼ ë”¥ëŸ¬ë‹ì„ í™œìš©í•œ ì´ë¯¸ì§€ ì¸ì‹ ì—°êµ¬",
        "ìì—°ì–´ì²˜ë¦¬ì™€ ëŒ€í™”í˜• AI ì‹œìŠ¤í…œ ê°œë°œ",
        "ë¡œë´‡ ì œì–´ ë° ììœ¨ì£¼í–‰ ê¸°ìˆ ",
        "ì „ë ¥ ì‹œìŠ¤í…œê³¼ ìŠ¤ë§ˆíŠ¸ ê·¸ë¦¬ë“œ",
        "ë¬´ì„  í†µì‹  ë° 5G ë„¤íŠ¸ì›Œí¬"
    ]
    
    for i, query in enumerate(test_queries, 1):
        print("\n" + "="*80)
        print(f"ğŸ“ í…ŒìŠ¤íŠ¸ {i}: {query}")
        print("="*80)
        
        student = Student(research_interests=query)
        
        # í›„ë³´êµ° ìƒì„±
        candidates_with_scores = generator.get_candidates_with_scores(
            student,
            final_top_k=5  # ìƒìœ„ 5ê°œë§Œ
        )
        
        # ì¶œë ¥
        print(f"\nğŸ† ìƒìœ„ 5ê°œ í›„ë³´ ì—°êµ¬ì‹¤:\n")
        for rank, (lab_id, scores) in enumerate(candidates_with_scores.items(), 1):
            lab = next(lab for lab in generator.labs if lab.id == lab_id)
            sources = ', '.join(scores['sources']) if scores['sources'] else 'combined'
            
            print(f"{rank}. [{lab.professor}] {lab.name}")
            print(f"   ì´ì : {scores['combined_score']:.4f}")
            print(f"   ì„¸ë¶€: í‚¤ì›Œë“œ={scores['keyword_score']:.4f}, "
                  f"ì˜ë¯¸={scores['semantic_score']:.4f}, "
                  f"ë„ë©”ì¸={scores['domain_score']:.4f}")
            print(f"   ë§¤ì¹­: {sources}")
            print(f"   ì„¤ëª…: {lab.description[:80]}...")
            print()
    
    print("="*80)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)