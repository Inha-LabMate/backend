"""
í¬ë¡¤ë§ ë§¤ë‹ˆì €: Playwright ê¸°ë°˜ JavaScript ë Œë”ë§ ì§€ì›

ì´ ëª¨ë“ˆì€ Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬ JavaScriptê°€ í¬í•¨ëœ ëª¨ë“  ì›¹ì‚¬ì´íŠ¸ë¥¼ í¬ë¡¤ë§í•©ë‹ˆë‹¤:
    1. JavaScript ì™„ì „ ì‹¤í–‰ (Google Sites, Wix, SPA ë“± ëª¨ë‘ ì§€ì›)
    2. ìë™ ëŒ€ê¸° (AJAX, ë™ì  ì½˜í…ì¸  ë¡œë”© ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë¦¼)
    3. ì†ë„ ì œì–´ (ì„œë²„ ë¶€ë‹´ ìµœì†Œí™”)
    4. ì¬ì‹œë„ ë¡œì§ (ì¼ì‹œì  ì˜¤ë¥˜ ëŒ€ì‘)
    5. Headless ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€)

ì‚¬ìš©ë²•:
    manager = CrawlManager(delay=1.0)  # 1ì´ˆ ë”œë ˆì´
    result = manager.fetch_url("https://example.com")
    print(result.html)  # JavaScript ë Œë”ë§ëœ ìµœì¢… HTML
"""

import time
from urllib.parse import urljoin, urlparse
from typing import Optional, Dict
from dataclasses import dataclass
import json
import os
from datetime import datetime, timedelta
from playwright.sync_api import sync_playwright, Browser, Page, TimeoutError as PlaywrightTimeout


@dataclass
class CrawlResult:
    """
    í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë‹´ëŠ” ë°ì´í„° í´ë˜ìŠ¤
    
    ì†ì„±:
        success (bool): í¬ë¡¤ë§ ì„±ê³µ ì—¬ë¶€
        status_code (int): HTTP ìƒíƒœ ì½”ë“œ (200=ì„±ê³µ, 404=ì—†ìŒ, 500=ì„œë²„ì˜¤ë¥˜ ë“±)
        html (str): JavaScriptê¹Œì§€ ëª¨ë‘ ì‹¤í–‰ëœ ìµœì¢… HTML ì½˜í…ì¸ 
        error (str): ì—ëŸ¬ ë°œìƒ ì‹œ ì—ëŸ¬ ë©”ì‹œì§€
        cached (bool): ìºì‹œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í–ˆëŠ”ì§€ ì—¬ë¶€
    
    ì˜ˆì‹œ:
        result = CrawlResult(success=True, status_code=200, html="<html>...")
        if result.success:
            print(result.html)  # ì‹¤ì œ HTML ì¶œë ¥
    """
    success: bool          # ì„±ê³µ/ì‹¤íŒ¨ ì—¬ë¶€
    status_code: int = 0   # HTTP ìƒíƒœ ì½”ë“œ
    html: str = ""         # ë Œë”ë§ëœ HTML
    error: str = ""        # ì—ëŸ¬ ë©”ì‹œì§€
    cached: bool = False   # ìºì‹œ ì‚¬ìš© ì—¬ë¶€


@dataclass
class CrawlStats:
    """
    í¬ë¡¤ë§ í†µê³„ë¥¼ ì¶”ì í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤
    
    ì†ì„±:
        total_requests (int): ì´ ì‹œë„í•œ ìš”ì²­ ìˆ˜
        successful (int): ì„±ê³µí•œ ìš”ì²­ ìˆ˜
        failed (int): ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜
        cached (int): ìºì‹œì—ì„œ ê°€ì ¸ì˜¨ ìˆ˜ (ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì•ˆí•¨)
        retry_count (int): ì¬ì‹œë„í•œ ì´ íšŸìˆ˜
        js_rendered (int): JavaScript ë Œë”ë§ì´ í•„ìš”í–ˆë˜ í˜ì´ì§€ ìˆ˜
    
    ì˜ˆì‹œ:
        stats.total_requests = 10
        stats.successful = 8
        ì„±ê³µë¥  = 8/10 = 80%
    """
    total_requests: int = 0   # ì´ ìš”ì²­
    successful: int = 0       # ì„±ê³µ
    failed: int = 0           # ì‹¤íŒ¨
    cached: int = 0           # ìºì‹œ ì‚¬ìš©
    retry_count: int = 0      # ì¬ì‹œë„
    js_rendered: int = 0      # JS ë Œë”ë§ í˜ì´ì§€


class CrawlManager:
    """
    Playwright ê¸°ë°˜ í¬ë¡¤ë§ ê´€ë¦¬ì
    
    âœ¨ í•µì‹¬ ê¸°ëŠ¥:
        1. JavaScript ì™„ì „ ì‹¤í–‰ - Google Sites, Wix, React ë“± ëª¨ë“  ì‚¬ì´íŠ¸ ì§€ì›
        2. ìë™ ëŒ€ê¸° - í˜ì´ì§€ ë¡œë”©, AJAX ì™„ë£Œê¹Œì§€ ìë™ ëŒ€ê¸°
        3. ì†ë„ ì œì–´ - ì„œë²„ì— ë¶€ë‹´ ì£¼ì§€ ì•Šë„ë¡ ìš”ì²­ ê°„ê²© ì¡°ì ˆ
        4. ì¬ì‹œë„ ë¡œì§ - ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ ì‹œ ìë™ ì¬ì‹œë„
        5. ìºì‹± - ê°™ì€ í˜ì´ì§€ ì¬ë°©ë¬¸ ì‹œ ìºì‹œ ì‚¬ìš© (ì†ë„ í–¥ìƒ)
    
    ğŸ’¡ ì‚¬ìš©ë²•:
        # 1. ê¸°ë³¸ ì‚¬ìš© (1ì´ˆ ê°„ê²©)
        manager = CrawlManager()
        result = manager.fetch_url("https://example.com")
        
        # 2. ë¹ ë¥´ê²Œ í¬ë¡¤ë§ (0.5ì´ˆ ê°„ê²©)
        manager = CrawlManager(delay=0.5)
        
        # 3. ì¬ì‹œë„ ë§ì´ (ìµœëŒ€ 5íšŒ)
        manager = CrawlManager(max_retries=5)
        
        # 4. ìºì‹œ ì‚¬ìš©
        result = manager.fetch_url("https://example.com")  # ë„¤íŠ¸ì›Œí¬ ìš”ì²­
        result = manager.fetch_url("https://example.com")  # ìºì‹œ ì‚¬ìš© (ë¹ ë¦„!)
    
    ğŸ”§ ë‚´ë¶€ ë™ì‘:
        fetch_url() í˜¸ì¶œ
        â†’ ìºì‹œ í™•ì¸ (ìˆìœ¼ë©´ ë°”ë¡œ ë°˜í™˜)
        â†’ ì†ë„ ì œí•œ ì ìš© (ë„ˆë¬´ ë¹ ë¥´ë©´ ëŒ€ê¸°)
        â†’ Playwrightë¡œ ë¸Œë¼ìš°ì € ì‹¤í–‰
        â†’ í˜ì´ì§€ ë¡œë”© + JavaScript ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
        â†’ HTML ì¶”ì¶œ
        â†’ ìºì‹œ ì €ì¥
        â†’ ê²°ê³¼ ë°˜í™˜
    """
    
    # ê¸°ë³¸ User-Agent (ìš°ë¦¬ê°€ ëˆ„êµ¬ì¸ì§€ ëª…ì‹œ)
    DEFAULT_USER_AGENT = (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "INHA-LabSearch-Bot/2.0 (Educational Research)"
    )
    
    def __init__(
        self,
        delay: float = 1.0,              # ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
        max_retries: int = 3,            # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        timeout: int = 30000,            # í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ) - 30ì´ˆ
        user_agent: Optional[str] = None,  # ì»¤ìŠ¤í…€ User-Agent
        cache_dir: str = './crawl_cache',  # ìºì‹œ ì €ì¥ ë””ë ‰í† ë¦¬
        headless: bool = True,           # Headless ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€)
        wait_for_network_idle: bool = True  # ë„¤íŠ¸ì›Œí¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    ):
        """
        Playwright ê¸°ë°˜ í¬ë¡¤ë§ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        
        ë§¤ê°œë³€ìˆ˜ ì„¤ëª…:
            delay (float): ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„ (ì´ˆ)
                - 0.5 = ë¹ ë¦„ (ì„œë²„ ë¶€ë‹´ ì•½ê°„ í¼)
                - 1.0 = ê¶Œì¥ (ì•ˆì „í•˜ê³  ë¹ ë¦„)
                - 2.0 = ëŠë¦¼ (ë§¤ìš° ì•ˆì „)
            
            max_retries (int): ì‹¤íŒ¨ ì‹œ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
                - 3 = ê¶Œì¥ (ëŒ€ë¶€ë¶„ ì¶©ë¶„)
                - 5 = ë¶ˆì•ˆì •í•œ ì„œë²„ìš©
            
            timeout (int): í˜ì´ì§€ ë¡œë”© íƒ€ì„ì•„ì›ƒ (ë°€ë¦¬ì´ˆ)
                - 30000 = 30ì´ˆ (ê¶Œì¥)
                - ëŠë¦° ì‚¬ì´íŠ¸ëŠ” ë” ëŠ˜ë ¤ë„ ë¨
            
            user_agent (str): ì»¤ìŠ¤í…€ User-Agent
                - Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
            
            cache_dir (str): HTML ìºì‹œ ì €ì¥ ë””ë ‰í† ë¦¬
                - ê°™ì€ í˜ì´ì§€ ì¬ë°©ë¬¸ ì‹œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì•ˆí•¨
            
            headless (bool): Headless ëª¨ë“œ
                - True = ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë³´ì„ (ê¶Œì¥)
                - False = ë¸Œë¼ìš°ì € ì°½ ë³´ì„ (ë””ë²„ê¹…ìš©)
            
            wait_for_network_idle (bool): ë„¤íŠ¸ì›Œí¬ ì™„ë£Œ ëŒ€ê¸°
                - True = AJAX ë“± ëª¨ë“  ìš”ì²­ ì™„ë£Œê¹Œì§€ ê¸°ë‹¤ë¦¼ (ê¶Œì¥)
                - False = í˜ì´ì§€ë§Œ ë¡œë“œë˜ë©´ ë°”ë¡œ ì§„í–‰ (ë¹ ë¥´ì§€ë§Œ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŒ)
        
        ì´ˆê¸°í™” ê³¼ì •:
            1. ì„¤ì • ì €ì¥
            2. í†µê³„ ê°ì²´ ìƒì„±
            3. ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            4. ê¸°ì¡´ ìºì‹œ ë¡œë“œ
            5. Playwright ë¸Œë¼ìš°ì €ëŠ” í•„ìš”í•  ë•Œë§ˆë‹¤ ì‹¤í–‰ (íš¨ìœ¨ì )
        """
        # ===== ì„¤ì • ì €ì¥ =====
        self.delay = delay
        self.max_retries = max_retries
        self.timeout = timeout
        self.user_agent = user_agent or self.DEFAULT_USER_AGENT
        self.cache_dir = cache_dir
        self.headless = headless
        self.wait_for_network_idle = wait_for_network_idle
        
        # ===== ìƒíƒœ ì¶”ì  =====
        self.last_request_time = 0.0  # ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ (ì†ë„ ì œí•œìš©)
        self.stats = CrawlStats()      # í†µê³„ ê°ì²´
        
        # ===== ìºì‹œ ê´€ë¦¬ =====
        self.http_cache: Dict[str, dict] = {}  # URL -> {html, timestamp} ë§¤í•‘
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„± (ì—†ìœ¼ë©´)
        if not os.path.exists(cache_dir):
            os.makedirs(cache_dir)
        
        # ê¸°ì¡´ ìºì‹œ ë¡œë“œ (ì´ì „ì— í¬ë¡¤ë§í•œ ë°ì´í„° ì¬ì‚¬ìš©)
        self._load_cache()
    
    def fetch_url(
        self, 
        url: str,
        force_refresh: bool = False
    ) -> CrawlResult:
        """
        URLì—ì„œ HTML ê°€ì ¸ì˜¤ê¸° (Playwright ì‚¬ìš© - JavaScript ì™„ì „ ì‹¤í–‰)
        
        ë§¤ê°œë³€ìˆ˜:
            url (str): í¬ë¡¤ë§í•  URL
                ì˜ˆ: "https://sites.google.com/view/inha-aif-lab"
            
            force_refresh (bool): ìºì‹œ ë¬´ì‹œ ì—¬ë¶€
                - False (ê¸°ë³¸ê°’): ìºì‹œ ìˆìœ¼ë©´ ì‚¬ìš© (ë¹ ë¦„)
                - True: ë¬´ì¡°ê±´ ìƒˆë¡œ í¬ë¡¤ë§ (ìµœì‹  ë°ì´í„°)
        
        ë°˜í™˜ê°’:
            CrawlResult: í¬ë¡¤ë§ ê²°ê³¼ ê°ì²´
                - result.success: ì„±ê³µ ì—¬ë¶€ (True/False)
                - result.html: JavaScript ë Œë”ë§ëœ ìµœì¢… HTML
                - result.error: ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        
        ë™ì‘ ìˆœì„œ:
            1. í†µê³„ ì—…ë°ì´íŠ¸ (total_requests += 1)
            2. ìºì‹œ í™•ì¸ (ìˆê³  force_refresh=Falseë©´ ë°”ë¡œ ë°˜í™˜)
            3. ì†ë„ ì œí•œ ì ìš© (ë„ˆë¬´ ë¹ ë¥´ë©´ ëŒ€ê¸°)
            4. Playwrightë¡œ HTML ê°€ì ¸ì˜¤ê¸° (ì¬ì‹œë„ í¬í•¨)
            5. ì„±ê³µ ì‹œ ìºì‹œ ì €ì¥
            6. ê²°ê³¼ ë°˜í™˜
        
        ì˜ˆì‹œ:
            # ê¸°ë³¸ ì‚¬ìš©
            result = manager.fetch_url("https://example.com")
            if result.success:
                print(result.html)  # JavaScript ì‹¤í–‰ëœ HTML
            
            # ìºì‹œ ë¬´ì‹œí•˜ê³  ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            result = manager.fetch_url("https://example.com", force_refresh=True)
        """
        # ===== 1ë‹¨ê³„: í†µê³„ ì—…ë°ì´íŠ¸ =====
        self.stats.total_requests += 1
        
        # ===== 2ë‹¨ê³„: ìºì‹œ í™•ì¸ =====
        if not force_refresh:
            cached_result = self._check_cache(url)
            if cached_result:
                self.stats.cached += 1
                return cached_result
        
        # ===== 3ë‹¨ê³„: ì†ë„ ì œí•œ ì ìš© =====
        # (ë§ˆì§€ë§‰ ìš”ì²­ í›„ delayì´ˆ ë§Œí¼ ëŒ€ê¸°)
        self._apply_rate_limit()
        
        # ===== 4ë‹¨ê³„: Playwrightë¡œ í¬ë¡¤ë§ (ì¬ì‹œë„ í¬í•¨) =====
        result = self._fetch_with_playwright(url)
        
        # ===== 5ë‹¨ê³„: ê²°ê³¼ ì²˜ë¦¬ =====
        if result.success:
            # ì„±ê³µ: ìºì‹œ ì €ì¥ + ì„±ê³µ í†µê³„ ì¦ê°€
            self._save_to_cache(url, result)
            self.stats.successful += 1
            self.stats.js_rendered += 1  # JavaScript ë Œë”ë§ íšŸìˆ˜
        else:
            # ì‹¤íŒ¨: ì‹¤íŒ¨ í†µê³„ ì¦ê°€
            self.stats.failed += 1
        
        return result
    
    def _apply_rate_limit(self):
        """
        ì†ë„ ì œí•œ ì ìš© - ì„œë²„ì— ë¶€ë‹´ ì£¼ì§€ ì•Šê¸°
        
        ë™ì‘ ì›ë¦¬:
            - ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ì„ ê¸°ë¡
            - í˜„ì¬ ì‹œê°„ê³¼ ë¹„êµ
            - delayì´ˆê°€ ì•ˆ ì§€ë‚¬ìœ¼ë©´ ëŒ€ê¸°
        
        ì˜ˆì‹œ:
            delay = 1.0ì´ˆ ì„¤ì • ì‹œ
            - 0ì´ˆ: ì²« ìš”ì²­ (ì¦‰ì‹œ ì‹¤í–‰)
            - 0.5ì´ˆ: ë‘ ë²ˆì§¸ ìš”ì²­ ì‹œë„ â†’ 0.5ì´ˆ ëŒ€ê¸° í›„ ì‹¤í–‰
            - 2ì´ˆ: ì„¸ ë²ˆì§¸ ìš”ì²­ (1ì´ˆ ì§€ë‚¬ìœ¼ë¯€ë¡œ ì¦‰ì‹œ ì‹¤í–‰)
        
        ì™œ í•„ìš”í•œê°€?:
            - ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€
            - IP ì°¨ë‹¨ ë°©ì§€
            - ì˜ˆì˜ ë°”ë¥¸ í¬ë¡¤ë§
        """
        current_time = time.time()  # í˜„ì¬ ì‹œê°„ (ì´ˆ ë‹¨ìœ„)
        time_since_last = current_time - self.last_request_time  # ë§ˆì§€ë§‰ ìš”ì²­ í›„ ê²½ê³¼ ì‹œê°„
        
        # delayì´ˆê°€ ì•ˆ ì§€ë‚¬ìœ¼ë©´ ëŒ€ê¸°
        if time_since_last < self.delay:
            sleep_time = self.delay - time_since_last  # ë‚¨ì€ ëŒ€ê¸° ì‹œê°„
            time.sleep(sleep_time)  # ì‹¤ì œ ëŒ€ê¸°
        
        # í˜„ì¬ ì‹œê°„ì„ ë§ˆì§€ë§‰ ìš”ì²­ ì‹œê°„ìœ¼ë¡œ ì—…ë°ì´íŠ¸
        self.last_request_time = time.time()
    
    def _fetch_with_playwright(self, url: str) -> CrawlResult:
        """
        Playwrightë¡œ HTML ê°€ì ¸ì˜¤ê¸° (JavaScript ì™„ì „ ì‹¤í–‰)
        
        ë§¤ê°œë³€ìˆ˜:
            url (str): í¬ë¡¤ë§í•  URL
        
        ë°˜í™˜ê°’:
            CrawlResult: í¬ë¡¤ë§ ê²°ê³¼
        
        ë™ì‘ ê³¼ì •:
            1. Playwright ì‹œì‘ (ë¸Œë¼ìš°ì € ì‹¤í–‰)
            2. ìƒˆ í˜ì´ì§€ ì—´ê¸°
            3. URL ì ‘ì†
            4. JavaScript ì‹¤í–‰ ì™„ë£Œ ëŒ€ê¸°
            5. ìµœì¢… HTML ì¶”ì¶œ
            6. ë¸Œë¼ìš°ì € ì¢…ë£Œ
            7. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (ìµœëŒ€ max_retriesíšŒ)
        
        ì¬ì‹œë„ ë¡œì§ (ì§€ìˆ˜ ë°±ì˜¤í”„):
            - 1íšŒ ì‹¤íŒ¨: 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
            - 2íšŒ ì‹¤íŒ¨: 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
            - 3íšŒ ì‹¤íŒ¨: 4ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
            - ì¼ì‹œì  ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ëŒ€ì‘
        
        ì™œ Playwrightì¸ê°€?:
            - Google Sites: JavaScriptë¡œ ì½˜í…ì¸  ë¡œë”© â†’ Playwrightë§Œ ê°€ëŠ¥
            - Wix: ë™ì  ë Œë”ë§ â†’ Playwrightë§Œ ê°€ëŠ¥
            - React/Vue SPA: ì´ˆê¸° HTML ê±°ì˜ ë¹„ì–´ìˆìŒ â†’ Playwright í•„ìˆ˜
        """
        last_error = ""  # ë§ˆì§€ë§‰ ì—ëŸ¬ ë©”ì‹œì§€ ì €ì¥ìš©
        
        # ===== ì¬ì‹œë„ ë£¨í”„ =====
        for attempt in range(self.max_retries + 1):
            try:
                # ===== Playwright ì‹¤í–‰ =====
                with sync_playwright() as p:
                    # 1. ë¸Œë¼ìš°ì € ì‹¤í–‰
                    #    headless=True: ì°½ ì•ˆ ë„ì›€ (ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰)
                    browser = p.chromium.launch(headless=self.headless)
                    
                    # 2. ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì¿ í‚¤, ë¡œì»¬ìŠ¤í† ë¦¬ì§€ ë“± ê²©ë¦¬)
                    context = browser.new_context(
                        user_agent=self.user_agent,  # User-Agent ì„¤ì •
                        viewport={'width': 1920, 'height': 1080}  # í™”ë©´ í¬ê¸° (ë°˜ì‘í˜• ëŒ€ì‘)
                    )
                    
                    # 3. ìƒˆ í˜ì´ì§€ ì—´ê¸°
                    page = context.new_page()
                    
                    # 4. URL ì ‘ì† + JavaScript ì‹¤í–‰ ëŒ€ê¸°
                    #    wait_until='networkidle': ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‘ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                    #    timeout: ìµœëŒ€ ëŒ€ê¸° ì‹œê°„ (ë°€ë¦¬ì´ˆ)
                    if self.wait_for_network_idle:
                        # ëŠë¦¬ì§€ë§Œ ì™„ë²½: AJAX, ì´ë¯¸ì§€ ë“± ëª¨ë“  ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                        page.goto(url, wait_until='networkidle', timeout=self.timeout)
                    else:
                        # ë¹ ë¥´ì§€ë§Œ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìŒ: DOM ë¡œë”©ë§Œ ì™„ë£Œ
                        page.goto(url, wait_until='domcontentloaded', timeout=self.timeout)
                    
                    # ì¶”ê°€ ëŒ€ê¸°: ë™ì  ì½˜í…ì¸ ê°€ ë Œë”ë§ë˜ë„ë¡ 1ì´ˆ ë” ëŒ€ê¸°
                    page.wait_for_timeout(1000)  # 1ì´ˆ = 1000ë°€ë¦¬ì´ˆ
                    
                    # 5. ìµœì¢… HTML ì¶”ì¶œ
                    #    ì´ ì‹œì ì—ì„œ JavaScriptê°€ ëª¨ë‘ ì‹¤í–‰ëœ ì™„ì „í•œ HTML
                    html = page.content()
                    
                    # 6. ë¸Œë¼ìš°ì € ì¢…ë£Œ (ë¦¬ì†ŒìŠ¤ ì •ë¦¬)
                    browser.close()
                    
                    # ===== ì„±ê³µ =====
                    return CrawlResult(
                        success=True,
                        status_code=200,  # PlaywrightëŠ” í•­ìƒ 200 (ì ‘ì† ì„±ê³µ)
                        html=html
                    )
            
            # ===== ì—ëŸ¬ ì²˜ë¦¬ =====
            except PlaywrightTimeout:
                # íƒ€ì„ì•„ì›ƒ: í˜ì´ì§€ ë¡œë”©ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼
                last_error = f"íƒ€ì„ì•„ì›ƒ ({self.timeout/1000}ì´ˆ ì´ˆê³¼)"
                self.stats.retry_count += 1
            
            except Exception as e:
                # ê¸°íƒ€ ì—ëŸ¬: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, DNS ì‹¤íŒ¨ ë“±
                last_error = str(e)
                self.stats.retry_count += 1
            
            # ===== ì¬ì‹œë„ ëŒ€ê¸° (ì§€ìˆ˜ ë°±ì˜¤í”„) =====
            if attempt < self.max_retries:
                wait_time = 2 ** attempt  # 1, 2, 4, 8ì´ˆ...
                time.sleep(wait_time)
        
        # ===== ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ =====
        return CrawlResult(
            success=False,
            error=f"ìµœëŒ€ ì¬ì‹œë„ ì´ˆê³¼ ({self.max_retries}íšŒ): {last_error}"
        )
    
    def _check_cache(self, url: str) -> Optional[CrawlResult]:
        """
        ìºì‹œ í™•ì¸ - ì´ì „ì— í¬ë¡¤ë§í•œ ë°ì´í„°ê°€ ìˆëŠ”ê°€?
        
        ë§¤ê°œë³€ìˆ˜:
            url (str): í™•ì¸í•  URL
        
        ë°˜í™˜ê°’:
            CrawlResult ë˜ëŠ” None
                - None: ìºì‹œ ì—†ìŒ â†’ ìƒˆë¡œ í¬ë¡¤ë§ í•„ìš”
                - CrawlResult: ìºì‹œ ìˆìŒ â†’ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì•ˆí•¨ (ë¹ ë¦„!)
        
        ìºì‹œ ìœ íš¨ ê¸°ê°„:
            - 7ì¼ ì´ë‚´: ìœ íš¨ (ìºì‹œ ì‚¬ìš©)
            - 7ì¼ ì´ˆê³¼: ë§Œë£Œ (ìƒˆë¡œ í¬ë¡¤ë§)
        
        ì™œ ìºì‹œë¥¼ ì‚¬ìš©í•˜ëŠ”ê°€?:
            1. ì†ë„ í–¥ìƒ: ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì—†ì´ ì¦‰ì‹œ ë°˜í™˜
            2. ì„œë²„ ë¶€ë‹´ ê°ì†Œ: ê°™ì€ í˜ì´ì§€ ë°˜ë³µ ìš”ì²­ ì•ˆí•¨
            3. ì•ˆì •ì„±: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ì— ì˜í–¥ ì•ˆ ë°›ìŒ
        
        ì˜ˆì‹œ:
            # ì²« ë°©ë¬¸: ìºì‹œ ì—†ìŒ
            result = manager.fetch_url("https://example.com")  # 3ì´ˆ ì†Œìš”
            
            # ì¬ë°©ë¬¸: ìºì‹œ ìˆìŒ
            result = manager.fetch_url("https://example.com")  # 0.001ì´ˆ ì†Œìš”!
        """
        # URLì´ ìºì‹œì— ì—†ìœ¼ë©´ None ë°˜í™˜
        if url not in self.http_cache:
            return None
        
        cache_data = self.http_cache[url]
        
        # ===== ìºì‹œ ìœ íš¨ ê¸°ê°„ í™•ì¸ =====
        # timestamp: ìºì‹œ ì €ì¥ ì‹œê°„ (ISO í˜•ì‹ ë¬¸ìì—´)
        cached_time = datetime.fromisoformat(cache_data['timestamp'])
        age = datetime.now() - cached_time  # ìºì‹œ ë‚˜ì´
        
        # 7ì¼ ë„˜ìœ¼ë©´ ë§Œë£Œ
        if age > timedelta(days=7):
            return None  # ë„ˆë¬´ ì˜¤ë˜ë¨ â†’ ìƒˆë¡œ í¬ë¡¤ë§
        
        # ===== ìºì‹œ ìœ íš¨ â†’ ë°˜í™˜ =====
        return CrawlResult(
            success=True,
            status_code=200,
            html=cache_data['html'],  # ì €ì¥ëœ HTML
            cached=True  # ìºì‹œ ì‚¬ìš©í–ˆë‹¤ê³  í‘œì‹œ
        )
    
    def _save_to_cache(self, url: str, result: CrawlResult):
        """
        ìºì‹œì— ì €ì¥ - ë‚˜ì¤‘ì— ì¬ì‚¬ìš©
        
        ë§¤ê°œë³€ìˆ˜:
            url (str): URL
            result (CrawlResult): í¬ë¡¤ë§ ê²°ê³¼
        
        ì €ì¥ ë‚´ìš©:
            - html: JavaScript ë Œë”ë§ëœ ìµœì¢… HTML
            - timestamp: ì €ì¥ ì‹œê°„ (ìœ íš¨ ê¸°ê°„ ê³„ì‚°ìš©)
        
        ë””ìŠ¤í¬ ì €ì¥:
            - 10ê°œë§ˆë‹¤ ìë™ ì €ì¥ (ë©”ëª¨ë¦¬ ì†ì‹¤ ë°©ì§€)
            - JSON íŒŒì¼ë¡œ ì €ì¥ (./crawl_cache/http_cache.json)
        
        ì˜ˆì‹œ:
            ìºì‹œ íŒŒì¼ êµ¬ì¡°:
            {
              "https://example.com": {
                "html": "<html>...</html>",
                "timestamp": "2025-11-04T17:30:00"
              },
              "https://another.com": {
                ...
              }
            }
        """
        # ===== ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥ =====
        self.http_cache[url] = {
            'html': result.html,            # HTML ì½˜í…ì¸ 
            'timestamp': datetime.now().isoformat()  # í˜„ì¬ ì‹œê°„ (ISO í˜•ì‹)
        }
        
        # ===== ì£¼ê¸°ì ìœ¼ë¡œ ë””ìŠ¤í¬ì— ì €ì¥ =====
        # 10ê°œë§ˆë‹¤ ì €ì¥ (ë„ˆë¬´ ìì£¼ ì €ì¥í•˜ë©´ ëŠë ¤ì§)
        if len(self.http_cache) % 10 == 0:
            self._persist_cache()
    
    def _load_cache(self):
        """
        ë””ìŠ¤í¬ì—ì„œ ìºì‹œ ë¡œë“œ - ì´ì „ í¬ë¡¤ë§ ë°ì´í„° ì¬ì‚¬ìš©
        
        ë™ì‘:
            1. ./crawl_cache/http_cache.json íŒŒì¼ ì°¾ê¸°
            2. JSON íŒŒì‹±
            3. self.http_cacheì— ë¡œë“œ
            4. ì‹¤íŒ¨ ì‹œ ë¹ˆ ìºì‹œë¡œ ì‹œì‘
        
        ì–¸ì œ í˜¸ì¶œë˜ëŠ”ê°€?:
            - __init__() ì‹œ ìë™ í˜¸ì¶œ
            - í”„ë¡œê·¸ë¨ ì¬ì‹œì‘í•´ë„ ì´ì „ ìºì‹œ ìœ ì§€
        
        ì´ì :
            - í”„ë¡œê·¸ë¨ ì¬ì‹œì‘í•´ë„ ìºì‹œ ìœ ì§€
            - ê°œë°œ ì¤‘ ë°˜ë³µ í…ŒìŠ¤íŠ¸ ì‹œ ë¹ ë¦„
        """
        cache_file = os.path.join(self.cache_dir, 'http_cache.json')
        
        # íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    self.http_cache = json.load(f)
            except Exception as e:
                # íŒŒì¼ ì†ìƒ ë“± ì—ëŸ¬ ì‹œ ë¹ˆ ìºì‹œë¡œ ì‹œì‘
                print(f"âš ï¸  ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
                self.http_cache = {}
        else:
            # íŒŒì¼ ì—†ìœ¼ë©´ ë¹ˆ ìºì‹œ
            self.http_cache = {}
    
    def _persist_cache(self):
        """
        ìºì‹œë¥¼ ë””ìŠ¤í¬ì— ì €ì¥ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ í›„ì—ë„ ìœ ì§€
        
        ë™ì‘:
            1. self.http_cacheë¥¼ JSONìœ¼ë¡œ ë³€í™˜
            2. ./crawl_cache/http_cache.jsonì— ì €ì¥
            3. ì‹¤íŒ¨í•´ë„ í”„ë¡œê·¸ë¨ ê³„ì† (ì¹˜ëª…ì  ì•„ë‹˜)
        
        ì €ì¥ ì‹œì :
            - 10ê°œë§ˆë‹¤ ìë™ (_save_to_cacheì—ì„œ í˜¸ì¶œ)
            - ìˆ˜ë™ìœ¼ë¡œë„ í˜¸ì¶œ ê°€ëŠ¥
        
        íŒŒì¼ í˜•ì‹:
            - JSON (ì‚¬ëŒì´ ì½ê¸° ì‰¬ì›€)
            - UTF-8 ì¸ì½”ë”© (í•œê¸€ ì§€ì›)
            - ë“¤ì—¬ì“°ê¸° 2ì¹¸ (ê°€ë…ì„±)
        """
        cache_file = os.path.join(self.cache_dir, 'http_cache.json')
        
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(
                    self.http_cache, 
                    f, 
                    ensure_ascii=False,  # í•œê¸€ ê·¸ëŒ€ë¡œ ì €ì¥
                    indent=2             # ë“¤ì—¬ì“°ê¸° (ì˜ˆì˜ê²Œ)
                )
        except Exception as e:
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ë©”ëª¨ë¦¬ì—ëŠ” ìˆìŒ)
            print(f"âš ï¸  ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    
    def get_stats(self) -> CrawlStats:
        """
        í†µê³„ ê°€ì ¸ì˜¤ê¸°
        
        ë°˜í™˜ê°’:
            CrawlStats ê°ì²´
                - total_requests: ì´ ìš”ì²­ ìˆ˜
                - successful: ì„±ê³µ ìˆ˜
                - failed: ì‹¤íŒ¨ ìˆ˜
                - cached: ìºì‹œ ì‚¬ìš© ìˆ˜
                - retry_count: ì¬ì‹œë„ íšŸìˆ˜
                - js_rendered: JavaScript ë Œë”ë§ í˜ì´ì§€ ìˆ˜
        
        ì‚¬ìš© ì˜ˆì‹œ:
            stats = manager.get_stats()
            print(f"ì„±ê³µë¥ : {stats.successful / stats.total_requests * 100}%")
        """
        return self.stats
    
    def print_stats(self):
        """
        í†µê³„ ì¶œë ¥ - í¬ë¡¤ë§ ì„±ê³¼ ìš”ì•½
        
        ì¶œë ¥ ë‚´ìš©:
            - ì´ ìš”ì²­ ìˆ˜
            - ì„±ê³µ/ì‹¤íŒ¨ ìˆ˜
            - ìºì‹œ ì‚¬ìš© ìˆ˜
            - ì¬ì‹œë„ íšŸìˆ˜
            - JavaScript ë Œë”ë§ í˜ì´ì§€ ìˆ˜
            - ì„±ê³µë¥  (ë°±ë¶„ìœ¨)
        
        ì˜ˆì‹œ ì¶œë ¥:
            === Playwright í¬ë¡¤ë§ í†µê³„ ===
            ì´ ìš”ì²­: 27
            ì„±ê³µ: 25
            ì‹¤íŒ¨: 2
            ìºì‹œ ì‚¬ìš©: 5
            ì¬ì‹œë„: 3
            JS ë Œë”ë§: 25
            ì„±ê³µë¥ : 92.6%
        """
        print("=" * 50)
        print("=== Playwright í¬ë¡¤ë§ í†µê³„ ===")
        print("=" * 50)
        print(f"ğŸ“Š ì´ ìš”ì²­: {self.stats.total_requests}")
        print(f"âœ… ì„±ê³µ: {self.stats.successful}")
        print(f"âŒ ì‹¤íŒ¨: {self.stats.failed}")
        print(f"ğŸ’¾ ìºì‹œ ì‚¬ìš©: {self.stats.cached}")
        print(f"ğŸ”„ ì¬ì‹œë„: {self.stats.retry_count}")
        print(f"ğŸ­ JS ë Œë”ë§: {self.stats.js_rendered}")
        
        # ì„±ê³µë¥  ê³„ì‚°
        if self.stats.total_requests > 0:
            success_rate = self.stats.successful / self.stats.total_requests * 100
            print(f"ğŸ“ˆ ì„±ê³µë¥ : {success_rate:.1f}%")
        
        print("=" * 50)


# ============================================================================
# ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
# ============================================================================

if __name__ == "__main__":
    """
    Playwright í¬ë¡¤ë§ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸
    
    í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤:
        1. ì •ì  HTML ì‚¬ì´íŠ¸ (ì¸í•˜ëŒ€ ë©”ì¸)
        2. JavaScript ë Œë”ë§ í•„ìš”í•œ ì‚¬ì´íŠ¸ (ì—°êµ¬ì‹¤ í™ˆí˜ì´ì§€)
        3. Google Sites (ê°€ì¥ ê¹Œë‹¤ë¡œìš´ ì¼€ì´ìŠ¤)
        4. ìºì‹œ í…ŒìŠ¤íŠ¸ (ì¤‘ë³µ ìš”ì²­)
    """
    print("=" * 70)
    print("ğŸš€ Playwright í¬ë¡¤ë§ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 70)
    print()
    
    # ===== í¬ë¡¤ë§ ë§¤ë‹ˆì € ìƒì„± =====
    # headless=Falseë¡œ í•˜ë©´ ë¸Œë¼ìš°ì € ì°½ì´ ë³´ì„ (ë””ë²„ê¹…ìš©)
    manager = CrawlManager(
        delay=1.0,              # 1ì´ˆ ê°„ê²©
        max_retries=3,          # ìµœëŒ€ 3íšŒ ì¬ì‹œë„
        headless=True,          # ë¸Œë¼ìš°ì € ì°½ ì•ˆ ë„ì›€
        wait_for_network_idle=True  # ë„¤íŠ¸ì›Œí¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    )
    
    # ===== í…ŒìŠ¤íŠ¸ URL ëª©ë¡ =====
    test_urls = [
        {
            'url': 'https://www.inha.ac.kr',
            'desc': 'ì¸í•˜ëŒ€ ë©”ì¸ (ì •ì  HTML)'
        },
        {
            'url': 'https://sites.google.com/view/inha-aif-lab',
            'desc': 'ê¸ˆìœµ AI ì—°êµ¬ì‹¤ (Google Sites - JS í•„ìˆ˜)'
        },
        {
            'url': 'https://youngsungkim-ai.github.io/',
            'desc': 'AI ì—°êµ¬ê·¸ë£¹ (GitHub Pages)'
        },
        {
            'url': 'https://sites.google.com/view/inha-aif-lab',
            'desc': 'ê¸ˆìœµ AI ì—°êµ¬ì‹¤ ì¬ë°©ë¬¸ (ìºì‹œ í…ŒìŠ¤íŠ¸)'
        }
    ]
    
    print(f"ğŸ“‹ í…ŒìŠ¤íŠ¸ URL: {len(test_urls)}ê°œ\n")
    
    # ===== í¬ë¡¤ë§ ì‹œì‘ =====
    for i, test in enumerate(test_urls, 1):
        url = test['url']
        desc = test['desc']
        
        print(f"[{i}/{len(test_urls)}] {desc}")
        print(f"ğŸ”— URL: {url}")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        result = manager.fetch_url(url)
        
        # ê²°ê³¼ ì¶œë ¥
        if result.success:
            status = "âœ… ì„±ê³µ"
            if result.cached:
                status += " (ìºì‹œ ì‚¬ìš© - ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ì—†ìŒ)"
            
            print(f"   {status}")
            print(f"   ğŸ“„ HTML ê¸¸ì´: {len(result.html):,} ë¬¸ì")
            
            # JavaScript ë Œë”ë§ í™•ì¸ (Google Sites íŠ¹ì§•)
            if 'google' in url and 'sites-canvas-main-content' in result.html:
                print(f"   ğŸ­ JavaScript ë Œë”ë§ í™•ì¸ë¨!")
        else:
            print(f"   âŒ ì‹¤íŒ¨: {result.error}")
        
        print()
    
    # ===== ìµœì¢… í†µê³„ =====
    print()
    manager.print_stats()
    
    print()
    print("=" * 70)
    print("âœ¨ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 70)
    print()
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print("   1. src/main_pipeline.py ì‹¤í–‰")
    print("   2. 27ê°œ ì—°êµ¬ì‹¤ í¬ë¡¤ë§")
    print("   3. documents.jsonì—ì„œ ê²°ê³¼ í™•ì¸")
    print()


