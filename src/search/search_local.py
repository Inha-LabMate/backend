"""
ë¡œì»¬ ì €ì¥ì†Œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
================================

PostgreSQL ì—†ì´ JSON íŒŒì¼ì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

3ê°€ì§€ ëª¨ë“œ:
    1. interactive (ëŒ€í™”í˜•) - ê³„ì† ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ë©° í…ŒìŠ¤íŠ¸
    2. search (ë‹¨ì¼ ê²€ìƒ‰) - í•œ ë²ˆë§Œ ê²€ìƒ‰í•˜ê³  ì¢…ë£Œ
    3. stats (í†µê³„) - ì €ì¥ëœ ë°ì´í„° í†µê³„ í™•ì¸

ì‚¬ìš© ì˜ˆ:
    # ëŒ€í™”í˜• ëª¨ë“œ (ì¶”ì²œ)
    python search_local.py
    
    # ë‹¨ì¼ ê²€ìƒ‰
    python search_local.py --mode search --query "ì»´í“¨í„° ë¹„ì „"
    
    # í†µê³„ ë³´ê¸°
    python search_local.py --mode stats

ë™ì‘ ì›ë¦¬:
    1. crawl_data/ í´ë”ì—ì„œ JSON íŒŒì¼ ë¡œë“œ
    2. ê²€ìƒ‰ì–´ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
    3. ëª¨ë“  ë¬¸ì„œì™€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
    4. ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ í‘œì‹œ
"""

from storage.local_storage import LocalVectorStore
from core.embedding import EmbeddingPipeline
import sys


def search_local(query: str, limit: int = 5, data_dir: str = './crawl_data'):
    """
    ë¡œì»¬ ì €ì¥ì†Œ ê²€ìƒ‰ í•¨ìˆ˜
    
    Args:
        query: ê²€ìƒ‰ì–´ (ì˜ˆ: "ì»´í“¨í„° ë¹„ì „ê³¼ ë”¥ëŸ¬ë‹")
        limit: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ 5ê°œ)
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ './crawl_data')
    
    ë™ì‘ ê³¼ì •:
        1. JSON íŒŒì¼ì—ì„œ ì €ì¥ëœ ë°ì´í„° ë¡œë“œ
        2. ì„ë² ë”© ëª¨ë¸ ë¡œë“œ (1.1GB, ì²« ì‹¤í–‰ì‹œë§Œ)
        3. ê²€ìƒ‰ì–´ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
        4. ëª¨ë“  ë¬¸ì„œì™€ ìœ ì‚¬ë„ ê³„ì‚°
        5. ìƒìœ„ Nê°œ ê²°ê³¼ ì¶œë ¥
    
    ì˜ˆì‹œ:
        search_local("ì¸ê³µì§€ëŠ¥ ì—°êµ¬", limit=10)
        # â†’ AI ê´€ë ¨ ë¬¸ì„œ 10ê°œ ì¶œë ¥
    """
    
    print("="*80)
    print(f"ë¡œì»¬ ë²¡í„° ê²€ìƒ‰: '{query}'")
    print("="*80)
    
    # 1. ì €ì¥ì†Œ ë¡œë“œ
    print("\n1. ë¡œì»¬ ì €ì¥ì†Œ ë¡œë”©...")
    store = LocalVectorStore(data_dir=data_dir)
    
    stats = store.get_stats()
    print(f"   - ì´ ì—°êµ¬ì‹¤: {stats['total_labs']}")
    print(f"   - ì´ ë¬¸ì„œ: {stats['total_docs']}")
    
    # 2. ì„ë² ë”© íŒŒì´í”„ë¼ì¸
    print("\n2. ì„ë² ë”© ëª¨ë¸ ë¡œë”©...")
    pipeline = EmbeddingPipeline(model_name='multilingual-mpnet', device='cpu')
    
    # 3. ì¿¼ë¦¬ ì„ë² ë”©
    print(f"\n3. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±: '{query}'")
    query_emb = pipeline.embed(query)
    
    # 4. ê²€ìƒ‰
    print(f"\n4. ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (ìƒìœ„ {limit}ê°œ)...")
    results = store.search_vector(
        query_embedding=query_emb.embedding,
        limit=limit,
        min_quality=0
    )
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*80)
    print("ê²€ìƒ‰ ê²°ê³¼")
    print("="*80)
    
    if not results:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return
    
    for i, result in enumerate(results):
        print(f"\n{'='*80}")
        print(f"{i+1}. [{result.lab_name}] {result.section}")
        print(f"{'='*80}")
        print(f"ì œëª©: {result.title or 'ì—†ìŒ'}")
        print(f"ìœ ì‚¬ë„ ì ìˆ˜: {result.score:.4f}")  # 0~1 ì‚¬ì´ ê°’ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
        print(f"í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
        print(f"  {result.text[:200]}...")
    
    print("\n" + "="*80)
    print(f"âœ… ì´ {len(results)}ê°œ ê²°ê³¼")
    print("="*80)


def interactive_search(data_dir: str = './crawl_data'):
    """ëŒ€í™”í˜• ê²€ìƒ‰"""
    print("="*80)
    print("ë¡œì»¬ ë²¡í„° ê²€ìƒ‰ - ëŒ€í™”í˜• ëª¨ë“œ")
    print("="*80)
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”\n")
    
    # ì €ì¥ì†Œ & íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
    store = LocalVectorStore(data_dir=data_dir)
    pipeline = EmbeddingPipeline(model_name='multilingual-mpnet', device='cpu')
    
    stats = store.get_stats()
    print(f"ğŸ“Š ì €ì¥ì†Œ ì •ë³´: ì—°êµ¬ì‹¤ {stats['total_labs']}ê°œ, ë¬¸ì„œ {stats['total_docs']}ê°œ\n")
    
    while True:
        try:
            query = input("ğŸ” ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            
            if query.lower() in ['exit', 'quit', 'q']:
                print("ğŸ‘‹ ê²€ìƒ‰ ì¢…ë£Œ")
                break
            
            if not query:
                continue
            
            # ê²€ìƒ‰
            query_emb = pipeline.embed(query)
            results = store.search_vector(query_emb.embedding, limit=5)
            
            print(f"\n{'='*60}")
            print(f"ê²€ìƒ‰ ê²°ê³¼: '{query}'")
            print(f"{'='*60}")
            
            if not results:
                print("âŒ ê²°ê³¼ ì—†ìŒ\n")
                continue
            
            for i, result in enumerate(results):
                print(f"\n{i+1}. [{result.lab_name}] ì ìˆ˜: {result.score:.3f}")
                print(f"   {result.text[:100]}...")
            
            print()
        
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ê²€ìƒ‰ ì¢…ë£Œ")
            break
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜: {e}\n")


def show_stats(data_dir: str = './crawl_data'):
    """í†µê³„ ì •ë³´ ì¶œë ¥"""
    print("="*80)
    print("ë¡œì»¬ ì €ì¥ì†Œ í†µê³„")
    print("="*80)
    
    store = LocalVectorStore(data_dir=data_dir)
    stats = store.get_stats()
    
    print(f"\nğŸ“Š ê¸°ë³¸ í†µê³„:")
    print(f"  ì´ ì—°êµ¬ì‹¤: {stats['total_labs']}")
    print(f"  ì´ ë¬¸ì„œ: {stats['total_docs']}")
    print(f"  í‰ê·  í’ˆì§ˆ: {stats.get('avg_quality_score', 0):.1f}")
    
    if 'section_distribution' in stats:
        print(f"\nğŸ“‚ ì„¹ì…˜ë³„ ë¬¸ì„œ ìˆ˜:")
        for section, count in sorted(stats['section_distribution'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {section:15s}: {count:4d}")
    
    if 'language_distribution' in stats:
        print(f"\nğŸŒ ì–¸ì–´ë³„ ë¬¸ì„œ ìˆ˜:")
        for lang, count in sorted(stats['language_distribution'].items(), key=lambda x: x[1], reverse=True):
            print(f"  {lang:15s}: {count:4d}")
    
    # ì—°êµ¬ì‹¤ ëª©ë¡
    print(f"\nğŸ« ì—°êµ¬ì‹¤ ëª©ë¡:")
    for lab in store.labs.values():
        doc_count = sum(1 for doc in store.documents.values() if doc.lab_id == lab.lab_id)
        print(f"  [{lab.lab_id:2d}] {lab.kor_name:30s} - ë¬¸ì„œ {doc_count:3d}ê°œ")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='ë¡œì»¬ ë²¡í„° ì €ì¥ì†Œ ê²€ìƒ‰')
    parser.add_argument('--mode', choices=['search', 'interactive', 'stats'], default='interactive',
                        help='ì‹¤í–‰ ëª¨ë“œ: search(ë‹¨ì¼ ê²€ìƒ‰), interactive(ëŒ€í™”í˜•), stats(í†µê³„)')
    parser.add_argument('--query', '-q', type=str, help='ê²€ìƒ‰ì–´ (search ëª¨ë“œ)')
    parser.add_argument('--limit', '-l', type=int, default=5, help='ê²°ê³¼ ê°œìˆ˜')
    parser.add_argument('--data-dir', '-d', type=str, default='./crawl_data', help='ë°ì´í„° ë””ë ‰í† ë¦¬')
    
    args = parser.parse_args()
    
    if args.mode == 'search':
        if not args.query:
            print("âŒ search ëª¨ë“œì—ì„œëŠ” --query ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤")
            print("ì˜ˆ: python search_local.py --mode search --query 'ì»´í“¨í„° ë¹„ì „'")
            sys.exit(1)
        search_local(args.query, args.limit, args.data_dir)
    
    elif args.mode == 'interactive':
        interactive_search(args.data_dir)
    
    elif args.mode == 'stats':
        show_stats(args.data_dir)
