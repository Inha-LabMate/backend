"""
ê³ ê¸‰ ê¸°ëŠ¥ ì¢…í•© í…ŒìŠ¤íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìƒˆë¡œ ì¶”ê°€ëœ ëª¨ë“  ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
    1. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    2. PII ê°ì§€
    3. í¬ë¡¤ë§ ë§¤ë‹ˆì € (ì†ë„ ì œí•œ, ì¬ì‹œë„)
    4. í‘œ ì¶”ì¶œ
    5. PDF ì²˜ë¦¬ (ì„ íƒ)

ì‹¤í–‰:
    python test_advanced_features.py
"""

import sys
import os


def test_quality_scorer():
    """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("1. í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    from quality_guard import QualityScorer
    from chunking import Chunk
    
    scorer = QualityScorer()
    
    # í…ŒìŠ¤íŠ¸ ì²­í¬ë“¤
    test_cases = [
        {
            'name': 'ê³ í’ˆì§ˆ ì—°êµ¬ í…ìŠ¤íŠ¸',
            'chunk': Chunk(
                text="ìš°ë¦¬ ì—°êµ¬ì‹¤ì€ ì»´í“¨í„° ë¹„ì „ê³¼ ë”¥ëŸ¬ë‹ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì—°êµ¬í•©ë‹ˆë‹¤. " * 5,
                section="research",
                char_count=300
            )
        },
        {
            'name': 'ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸',
            'chunk': Chunk(
                text="ì§§ì€ í…ìŠ¤íŠ¸",
                section="general",
                char_count=7
            )
        },
        {
            'name': 'ì„¹ì…˜ ë¶ˆì¼ì¹˜',
            'chunk': Chunk(
                text="ìš°ë¦¬ ì—°êµ¬ì‹¤ì—ì„œëŠ” ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤. " * 5,
                section="publication",  # í”„ë¡œì íŠ¸ ë‚´ìš©ì¸ë° publicationìœ¼ë¡œ ë¶„ë¥˜ë¨
                char_count=270
            )
        },
    ]
    
    for test in test_cases:
        print(f"\ní…ŒìŠ¤íŠ¸: {test['name']}")
        print(f"í…ìŠ¤íŠ¸: {test['chunk'].text[:50]}...")
        
        report = scorer.calculate_quality(test['chunk'])
        
        print(f"  ì „ì²´ ì ìˆ˜: {report.overall_score:.2f}")
        print(f"  - ì„¹ì…˜ ì¼ì¹˜: {report.section_score:.2f}")
        print(f"  - ê¸¸ì´: {report.length_score:.2f}")
        print(f"  - ì–¸ì–´: {report.language_score:.2f}")
        print(f"  - ì¤‘ë³µ: {report.duplicate_score:.2f}")
        
        if report.needs_review:
            print(f"  âš ï¸  ê²€ìˆ˜ í•„ìš”: {report.reason}")
        else:
            print(f"  âœ… í’ˆì§ˆ ì–‘í˜¸")
    
    print("\nâœ… í’ˆì§ˆ ì ìˆ˜ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")


def test_guardrail():
    """ê°€ë“œë ˆì¼ (PII ê°ì§€) í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("2. ê°€ë“œë ˆì¼ (PII ê°ì§€) í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    from quality_guard import GuardRail
    
    guard = GuardRail()
    
    # URL ì°¨ë‹¨ í…ŒìŠ¤íŠ¸
    print("\n[URL ì°¨ë‹¨ í…ŒìŠ¤íŠ¸]")
    test_urls = [
        ("https://example.com/research", False),
        ("https://example.com/login", True),
        ("https://example.com/admin/portal", True),
        ("https://example.com/data?password=123", True),
    ]
    
    for url, expected_block in test_urls:
        should_exclude, reason = guard.should_exclude_url(url)
        status = "âœ… ì •ìƒ" if should_exclude == expected_block else "âŒ ì˜¤ë¥˜"
        action = "ì°¨ë‹¨" if should_exclude else "í—ˆìš©"
        
        print(f"{status} {action}: {url}")
        if should_exclude:
            print(f"   ì´ìœ : {reason}")
    
    # PII í…ìŠ¤íŠ¸ ê°ì§€ í…ŒìŠ¤íŠ¸
    print("\n[PII í…ìŠ¤íŠ¸ ê°ì§€ í…ŒìŠ¤íŠ¸]")
    test_texts = [
        ("ìš°ë¦¬ ì—°êµ¬ì‹¤ì€ AIë¥¼ ì—°êµ¬í•©ë‹ˆë‹¤.", False),
        ("ë¡œê·¸ì¸í•˜ì—¬ ê°œì¸ì •ë³´ë¥¼ ì…ë ¥í•˜ì„¸ìš”.", True),
        ("Please sign in with your password.", True),
    ]
    
    for text, expected_pii in test_texts:
        has_pii, keywords = guard.detect_pii_in_text(text)
        status = "âœ… ì •ìƒ" if has_pii == expected_pii else "âŒ ì˜¤ë¥˜"
        result = "PII ë°œê²¬" if has_pii else "ì•ˆì „"
        
        print(f"{status} {result}: {text}")
        if has_pii:
            print(f"   í‚¤ì›Œë“œ: {', '.join(keywords)}")
    
    print("\nâœ… ê°€ë“œë ˆì¼ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")


def test_crawl_manager():
    """í¬ë¡¤ë§ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("3. í¬ë¡¤ë§ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    from crawl_manager import CrawlManager
    
    manager = CrawlManager(
        delay=0.5,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì§§ê²Œ
        max_retries=2,
        user_agent="TestBot/1.0"
    )
    
    test_urls = [
        "https://httpbin.org/html",  # ì„±ê³µ
        "https://httpbin.org/status/404",  # 404 ì—ëŸ¬
        "https://httpbin.org/delay/2",  # ëŠë¦° ì‘ë‹µ
    ]
    
    print("\n[URL í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸]")
    for url in test_urls:
        print(f"\nìš”ì²­: {url}")
        result = manager.fetch_url(url)
        
        if result.success:
            print(f"  âœ… ì„±ê³µ (ìƒíƒœ: {result.status_code})")
            print(f"  HTML ê¸¸ì´: {len(result.html)} ë¬¸ì")
            if result.cached:
                print(f"  ğŸ“¦ ìºì‹œ ì‚¬ìš©")
        else:
            print(f"  âŒ ì‹¤íŒ¨: {result.error}")
    
    print("\n[í†µê³„]")
    manager.print_stats()
    
    print("\nâœ… í¬ë¡¤ë§ ë§¤ë‹ˆì € í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")


def test_table_extractor():
    """í‘œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸"""
    print("=" * 60)
    print("4. í‘œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    from advanced_extractors import TableExtractor
    
    extractor = TableExtractor()
    
    sample_html = """
    <table>
        <caption>ìµœê·¼ ë…¼ë¬¸ ëª©ë¡</caption>
        <thead>
            <tr>
                <th>Year</th>
                <th>Venue</th>
                <th>Title</th>
                <th>Author</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>2024</td>
                <td>CVPR</td>
                <td>Vision Transformer for Image Recognition</td>
                <td>Kim et al.</td>
            </tr>
            <tr>
                <td>2023</td>
                <td>ICCV</td>
                <td>Object Detection with Deep Learning</td>
                <td>Lee et al.</td>
            </tr>
            <tr>
                <td>2023</td>
                <td>NeurIPS</td>
                <td>Efficient Neural Networks</td>
                <td>Park et al.</td>
            </tr>
        </tbody>
    </table>
    """
    
    print("\n[í‘œ ì¶”ì¶œ]")
    tables = extractor.extract_tables(sample_html)
    
    for i, table in enumerate(tables, 1):
        print(f"\ní‘œ {i}:")
        print(f"ìº¡ì…˜: {table.caption}")
        print(f"í—¤ë”: {table.headers}")
        print(f"í–‰ ìˆ˜: {len(table.rows)}")
        
        print("\ní…ìŠ¤íŠ¸ í˜•ì‹:")
        print(table.to_text())
        
        print("\në©”íƒ€ë°ì´í„°:")
        print(f"  ì»¬ëŸ¼ ë§¤í•‘: {table.metadata.get('column_map', {})}")
        if 'lab_tags' in table.metadata:
            print(f"  ë…¼ë¬¸ íƒœê·¸: {table.metadata['lab_tags']}")
        
        print("\në”•ì…”ë„ˆë¦¬ í˜•ì‹ (ì²« 2ê°œ):")
        for row_dict in table.to_dict_list()[:2]:
            print(f"  {row_dict}")
    
    print("\nâœ… í‘œ ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ\n")


def test_pdf_extractor():
    """PDF ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ì„ íƒ)"""
    print("=" * 60)
    print("5. PDF ì¶”ì¶œ í…ŒìŠ¤íŠ¸ (ì„ íƒ)")
    print("=" * 60)
    
    try:
        from advanced_extractors import PDFExtractor
        
        # PDF íŒŒì¼ì´ ìˆìœ¼ë©´ í…ŒìŠ¤íŠ¸
        test_pdf = "test.pdf"
        if os.path.exists(test_pdf):
            print(f"\nPDF íŒŒì¼ ë°œê²¬: {test_pdf}")
            
            extractor = PDFExtractor(backend='pypdf2')
            
            # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
            metadata = extractor.extract_metadata(test_pdf)
            print(f"ì œëª©: {metadata.get('title', 'N/A')}")
            print(f"ì €ì: {metadata.get('author', 'N/A')}")
            print(f"í˜ì´ì§€ ìˆ˜: {metadata.get('pages', 'N/A')}")
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            text = extractor.extract_text(test_pdf)
            print(f"\nì¶”ì¶œëœ í…ìŠ¤íŠ¸ (ì²˜ìŒ 200ì):")
            print(text[:200])
            
            print("\nâœ… PDF ì¶”ì¶œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        else:
            print(f"\nâš ï¸  PDF íŒŒì¼ì´ ì—†ì–´ ìŠ¤í‚µ: {test_pdf}")
            print("í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´ 'test.pdf' íŒŒì¼ì„ í˜„ì¬ ë””ë ‰í† ë¦¬ì— ë‘ì„¸ìš”.")
    
    except ImportError as e:
        print(f"\nâš ï¸  PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜: {e}")
        print("ì„¤ì¹˜: pip install PyPDF2 pdfplumber")
    
    print()


def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "=" * 60)
    print("ê³ ê¸‰ ê¸°ëŠ¥ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    print("=" * 60 + "\n")
    
    try:
        test_quality_scorer()
        test_guardrail()
        test_crawl_manager()
        test_table_extractor()
        test_pdf_extractor()
        
        print("=" * 60)
        print("âœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    run_all_tests()
